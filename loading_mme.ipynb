{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and creating the mme_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dataframe with only the ExtendedSessionID column from the 71M SharedResponses.csv file\n",
    "\n",
    "reader = pd.read_csv('SharedResponses.csv', usecols=['ResponseID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code that will check if there are two of them in the dataset\n",
    "\n",
    "# Count how many times each ResponseID appears\n",
    "response_counts = reader['ResponseID'].value_counts()\n",
    "\n",
    "# Get the ResponseIDs that appear exactly twice\n",
    "ids_to_keep = response_counts[response_counts == 2].index\n",
    "\n",
    "# Filter the rows where ResponseID is in the list of ids_to_keep\n",
    "complete_responseid = reader[reader['ResponseID'].isin(ids_to_keep)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_responseid.value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67907006, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_responseid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on 'ResponseID' and keep the first occurrence\n",
    "complete_responseid = complete_responseid.drop_duplicates(subset=['ResponseID'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_subset = complete_responseid.sample(n=2000000) # want 4M rows (with accounting for NAn's and deleting rows with 'random' (around 10%)), so 4M / 2 = 2M ResponseID's necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseID    2000000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if they are all unique\n",
    "\n",
    "reader_subset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to a list to feed to the for loop that will extract all the corresponding columns from the SharedResponses.csv file\n",
    "\n",
    "reader_sub_list = reader_subset['ResponseID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n"
     ]
    }
   ],
   "source": [
    "# check if it went okay\n",
    "print(len(reader_sub_list))     # should be 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dataframe to append the rows to\n",
    "\n",
    "subset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1\n",
      "Finished processing chunk 1\n",
      "Processing chunk 2\n",
      "Finished processing chunk 2\n",
      "Processing chunk 3\n",
      "Finished processing chunk 3\n",
      "Processing chunk 4\n",
      "Finished processing chunk 4\n",
      "Processing chunk 5\n",
      "Finished processing chunk 5\n",
      "Processing chunk 6\n",
      "Finished processing chunk 6\n",
      "Processing chunk 7\n",
      "Finished processing chunk 7\n",
      "Processing chunk 8\n",
      "Finished processing chunk 8\n",
      "Processing chunk 9\n",
      "Finished processing chunk 9\n",
      "Processing chunk 10\n",
      "Finished processing chunk 10\n",
      "Processing chunk 11\n",
      "Finished processing chunk 11\n",
      "Processing chunk 12\n",
      "Finished processing chunk 12\n",
      "Processing chunk 13\n",
      "Finished processing chunk 13\n",
      "Processing chunk 14\n",
      "Finished processing chunk 14\n",
      "Processing chunk 15\n",
      "Finished processing chunk 15\n",
      "Processing chunk 16\n",
      "Finished processing chunk 16\n",
      "Processing chunk 17\n",
      "Finished processing chunk 17\n",
      "Processing chunk 18\n",
      "Finished processing chunk 18\n",
      "Processing chunk 19\n",
      "Finished processing chunk 19\n",
      "Processing chunk 20\n",
      "Finished processing chunk 20\n",
      "Processing chunk 21\n",
      "Finished processing chunk 21\n",
      "Processing chunk 22\n",
      "Finished processing chunk 22\n",
      "Processing chunk 23\n",
      "Finished processing chunk 23\n",
      "Processing chunk 24\n",
      "Finished processing chunk 24\n",
      "Processing chunk 25\n",
      "Finished processing chunk 25\n",
      "Processing chunk 26\n",
      "Finished processing chunk 26\n",
      "Processing chunk 27\n",
      "Finished processing chunk 27\n",
      "Processing chunk 28\n",
      "Finished processing chunk 28\n",
      "Processing chunk 29\n",
      "Finished processing chunk 29\n",
      "Processing chunk 30\n",
      "Finished processing chunk 30\n",
      "Processing chunk 31\n",
      "Finished processing chunk 31\n",
      "Processing chunk 32\n",
      "Finished processing chunk 32\n",
      "Processing chunk 33\n",
      "Finished processing chunk 33\n",
      "Processing chunk 34\n",
      "Finished processing chunk 34\n",
      "Processing chunk 35\n",
      "Finished processing chunk 35\n",
      "Processing chunk 36\n",
      "Finished processing chunk 36\n",
      "Processing chunk 37\n",
      "Finished processing chunk 37\n",
      "Processing chunk 38\n",
      "Finished processing chunk 38\n",
      "Processing chunk 39\n",
      "Finished processing chunk 39\n",
      "Processing chunk 40\n",
      "Finished processing chunk 40\n",
      "Processing chunk 41\n",
      "Finished processing chunk 41\n",
      "Processing chunk 42\n",
      "Finished processing chunk 42\n",
      "Processing chunk 43\n",
      "Finished processing chunk 43\n",
      "Processing chunk 44\n",
      "Finished processing chunk 44\n",
      "Processing chunk 45\n",
      "Finished processing chunk 45\n",
      "Processing chunk 46\n",
      "Finished processing chunk 46\n",
      "Processing chunk 47\n",
      "Finished processing chunk 47\n",
      "Processing chunk 48\n",
      "Finished processing chunk 48\n",
      "Processing chunk 49\n",
      "Finished processing chunk 49\n",
      "Processing chunk 50\n",
      "Finished processing chunk 50\n",
      "Processing chunk 51\n",
      "Finished processing chunk 51\n",
      "Processing chunk 52\n",
      "Finished processing chunk 52\n",
      "Processing chunk 53\n",
      "Finished processing chunk 53\n",
      "Processing chunk 54\n",
      "Finished processing chunk 54\n",
      "Processing chunk 55\n",
      "Finished processing chunk 55\n",
      "Processing chunk 56\n",
      "Finished processing chunk 56\n",
      "Processing chunk 57\n",
      "Finished processing chunk 57\n",
      "Processing chunk 58\n",
      "Finished processing chunk 58\n",
      "Processing chunk 59\n",
      "Finished processing chunk 59\n",
      "Processing chunk 60\n",
      "Finished processing chunk 60\n",
      "Processing chunk 61\n",
      "Finished processing chunk 61\n",
      "Processing chunk 62\n",
      "Finished processing chunk 62\n",
      "Processing chunk 63\n",
      "Finished processing chunk 63\n",
      "Processing chunk 64\n",
      "Finished processing chunk 64\n",
      "Processing chunk 65\n",
      "Finished processing chunk 65\n",
      "Processing chunk 66\n",
      "Finished processing chunk 66\n",
      "Processing chunk 67\n",
      "Finished processing chunk 67\n",
      "Processing chunk 68\n",
      "Finished processing chunk 68\n",
      "Processing chunk 69\n",
      "Finished processing chunk 69\n",
      "Processing chunk 70\n",
      "Finished processing chunk 70\n",
      "Processing chunk 71\n",
      "Finished processing chunk 71\n",
      "Processing chunk 72\n",
      "Finished processing chunk 72\n",
      "Processing chunk 73\n",
      "Finished processing chunk 73\n",
      "Processing chunk 74\n",
      "Finished processing chunk 74\n",
      "Processing chunk 75\n",
      "Finished processing chunk 75\n",
      "Processing chunk 76\n",
      "Finished processing chunk 76\n",
      "Processing chunk 77\n",
      "Finished processing chunk 77\n",
      "Processing chunk 78\n",
      "Finished processing chunk 78\n",
      "Processing chunk 79\n",
      "Finished processing chunk 79\n",
      "Processing chunk 80\n",
      "Finished processing chunk 80\n",
      "Processing chunk 81\n",
      "Finished processing chunk 81\n",
      "Processing chunk 82\n",
      "Finished processing chunk 82\n",
      "Processing chunk 83\n",
      "Finished processing chunk 83\n",
      "Processing chunk 84\n",
      "Finished processing chunk 84\n",
      "Processing chunk 85\n",
      "Finished processing chunk 85\n",
      "Processing chunk 86\n",
      "Finished processing chunk 86\n",
      "Processing chunk 87\n",
      "Finished processing chunk 87\n",
      "Processing chunk 88\n",
      "Finished processing chunk 88\n",
      "Processing chunk 89\n",
      "Finished processing chunk 89\n",
      "Processing chunk 90\n",
      "Finished processing chunk 90\n",
      "Processing chunk 91\n",
      "Finished processing chunk 91\n",
      "Processing chunk 92\n",
      "Finished processing chunk 92\n",
      "Processing chunk 93\n",
      "Finished processing chunk 93\n",
      "Processing chunk 94\n",
      "Finished processing chunk 94\n",
      "Processing chunk 95\n",
      "Finished processing chunk 95\n",
      "Processing chunk 96\n",
      "Finished processing chunk 96\n",
      "Processing chunk 97\n",
      "Finished processing chunk 97\n",
      "Processing chunk 98\n",
      "Finished processing chunk 98\n",
      "Processing chunk 99\n",
      "Finished processing chunk 99\n",
      "Processing chunk 100\n",
      "Finished processing chunk 100\n",
      "Processing chunk 101\n",
      "Finished processing chunk 101\n",
      "Processing chunk 102\n",
      "Finished processing chunk 102\n",
      "Processing chunk 103\n",
      "Finished processing chunk 103\n",
      "Processing chunk 104\n",
      "Finished processing chunk 104\n",
      "Processing chunk 105\n",
      "Finished processing chunk 105\n",
      "Processing chunk 106\n",
      "Finished processing chunk 106\n",
      "Processing chunk 107\n",
      "Finished processing chunk 107\n",
      "Processing chunk 108\n",
      "Finished processing chunk 108\n",
      "Processing chunk 109\n",
      "Finished processing chunk 109\n",
      "Processing chunk 110\n",
      "Finished processing chunk 110\n",
      "Processing chunk 111\n",
      "Finished processing chunk 111\n",
      "Processing chunk 112\n",
      "Finished processing chunk 112\n",
      "Processing chunk 113\n",
      "Finished processing chunk 113\n",
      "Processing chunk 114\n",
      "Finished processing chunk 114\n",
      "Processing chunk 115\n",
      "Finished processing chunk 115\n",
      "Processing chunk 116\n",
      "Finished processing chunk 116\n",
      "Processing chunk 117\n",
      "Finished processing chunk 117\n",
      "Processing chunk 118\n",
      "Finished processing chunk 118\n",
      "Processing chunk 119\n",
      "Finished processing chunk 119\n",
      "Processing chunk 120\n",
      "Finished processing chunk 120\n",
      "Processing chunk 121\n",
      "Finished processing chunk 121\n",
      "Processing chunk 122\n",
      "Finished processing chunk 122\n",
      "Processing chunk 123\n",
      "Finished processing chunk 123\n",
      "Processing chunk 124\n",
      "Finished processing chunk 124\n",
      "Processing chunk 125\n",
      "Finished processing chunk 125\n",
      "Processing chunk 126\n",
      "Finished processing chunk 126\n",
      "Processing chunk 127\n",
      "Finished processing chunk 127\n",
      "Processing chunk 128\n",
      "Finished processing chunk 128\n",
      "Processing chunk 129\n",
      "Finished processing chunk 129\n",
      "Processing chunk 130\n",
      "Finished processing chunk 130\n",
      "Processing chunk 131\n",
      "Finished processing chunk 131\n",
      "Processing chunk 132\n",
      "Finished processing chunk 132\n",
      "Processing chunk 133\n",
      "Finished processing chunk 133\n",
      "Processing chunk 134\n",
      "Finished processing chunk 134\n",
      "Processing chunk 135\n",
      "Finished processing chunk 135\n",
      "Processing chunk 136\n",
      "Finished processing chunk 136\n",
      "Processing chunk 137\n",
      "Finished processing chunk 137\n",
      "Processing chunk 138\n",
      "Finished processing chunk 138\n",
      "Processing chunk 139\n",
      "Finished processing chunk 139\n",
      "Processing chunk 140\n",
      "Finished processing chunk 140\n",
      "Processing chunk 141\n",
      "Finished processing chunk 141\n",
      "All chunks have been processed and combined.\n"
     ]
    }
   ],
   "source": [
    "# reading SharedResponses to extract the rows with ResponseID's in reader_sub_list\n",
    "# this will result in a dataframe 'subset' that contains around 4 million rows (2 * 2)\n",
    "\n",
    "chunk_size = 500_000\n",
    "reader = pd.read_csv('SharedResponses.csv', chunksize=chunk_size, dtype=str, low_memory=False)\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    \n",
    "    print(f\"Processing chunk {i+1}\")\n",
    "\n",
    "    # Filter rows where ResponseID is in reader_subset\n",
    "    subset_chunk = chunk[chunk['ResponseID'].isin(reader_sub_list)]\n",
    "\n",
    "    # Append filtered chunk to empty df\n",
    "    subset = pd.concat([subset, subset_chunk], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished processing chunk {i+1}\")\n",
    "\n",
    "print(\"All chunks have been processed and combined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000000, 41)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.shape # should be 4000000, 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_csv = subset.to_csv('subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 98/2 MME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_mme = pd.read_csv('subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000000, 41)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2222bRQqBTZ6dLnPH</td>\n",
       "      <td>32757157_6999801415950060.0</td>\n",
       "      <td>6.999801e+15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fit</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2223jMWDEGNeszivb</td>\n",
       "      <td>-1683127088_785070916172117.0</td>\n",
       "      <td>7.850709e+14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2225s6f4PqRQYeBd4</td>\n",
       "      <td>1153359856_8971439613901464.0</td>\n",
       "      <td>8.971440e+15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fit</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222FeDqdjF7arHsBe</td>\n",
       "      <td>-1196718414_3957475684404117.0</td>\n",
       "      <td>3.957476e+15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Less</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222JBu4KkKjnFQC9P</td>\n",
       "      <td>988708286_2649771417.0</td>\n",
       "      <td>2.649771e+09</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ResponseID               ExtendedSessionID        UserID  \\\n",
       "0  2222bRQqBTZ6dLnPH     32757157_6999801415950060.0  6.999801e+15   \n",
       "1  2223jMWDEGNeszivb   -1683127088_785070916172117.0  7.850709e+14   \n",
       "2  2225s6f4PqRQYeBd4   1153359856_8971439613901464.0  8.971440e+15   \n",
       "3  222FeDqdjF7arHsBe  -1196718414_3957475684404117.0  3.957476e+15   \n",
       "4  222JBu4KkKjnFQC9P          988708286_2649771417.0  2.649771e+09   \n",
       "\n",
       "   ScenarioOrder  Intervention  PedPed  Barrier  CrossingSignal  \\\n",
       "0              7             0       0        0               1   \n",
       "1              8             0       1        0               2   \n",
       "2              4             0       1        0               1   \n",
       "3             13             0       1        0               2   \n",
       "4             12             0       0        0               0   \n",
       "\n",
       "  AttributeLevel ScenarioTypeStrict  ... LargeMan Criminal MaleExecutive  \\\n",
       "0            Fit            Fitness  ...      0.0      0.0           0.0   \n",
       "1           More        Utilitarian  ...      0.0      1.0           1.0   \n",
       "2            Fit            Fitness  ...      0.0      0.0           0.0   \n",
       "3           Less        Utilitarian  ...      0.0      0.0           0.0   \n",
       "4           Male             Gender  ...      0.0      0.0           0.0   \n",
       "\n",
       "   FemaleExecutive  FemaleAthlete  MaleAthlete  FemaleDoctor MaleDoctor  Dog  \\\n",
       "0              0.0            1.0          2.0           0.0        0.0  0.0   \n",
       "1              0.0            1.0          0.0           0.0        0.0  1.0   \n",
       "2              0.0            1.0          1.0           0.0        0.0  0.0   \n",
       "3              0.0            0.0          0.0           0.0        0.0  0.0   \n",
       "4              0.0            0.0          0.0           0.0        0.0  0.0   \n",
       "\n",
       "   Cat  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScenarioTypeStrict\n",
       "Utilitarian      717820\n",
       "Fitness          706192\n",
       "Species          705608\n",
       "Age              705476\n",
       "Gender           703064\n",
       "Random           352412\n",
       "Social Status    109428\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme['ScenarioTypeStrict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all rows with 'random' in the ScenarioTypeStrict column, as LLM's don't have a random scenario\n",
    "\n",
    "df_mme = df_mme[df_mme['ScenarioTypeStrict'] != 'Random']\n",
    "\n",
    "# should be 4000000 - 352412 = 3647588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3647588, 41)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttributeLevel\n",
       "More       358910\n",
       "Less       358910\n",
       "Pets       352804\n",
       "Hoomans    352804\n",
       "Male       351532\n",
       "Female     351532\n",
       "Young      341010\n",
       "Old        341010\n",
       "Fit        318774\n",
       "Fat        318774\n",
       "Rand       115558\n",
       "Low         42985\n",
       "High        42985\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing all rows with 'Rand' in the AttributeLevel column, as LLM's don't have a random scenario\n",
    "df_mme['AttributeLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mme = df_mme[df_mme['AttributeLevel'] != 'Rand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3532030, 41)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.shape # should be 3647588 - 115558 = 3532030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseID                      0\n",
       "ExtendedSessionID               0\n",
       "UserID                        404\n",
       "ScenarioOrder                   0\n",
       "Intervention                    0\n",
       "PedPed                          0\n",
       "Barrier                         0\n",
       "CrossingSignal                  0\n",
       "AttributeLevel                  0\n",
       "ScenarioTypeStrict              0\n",
       "ScenarioType                    0\n",
       "DefaultChoice                   0\n",
       "NonDefaultChoice                0\n",
       "DefaultChoiceIsOmission         0\n",
       "NumberOfCharacters              0\n",
       "DiffNumberOFCharacters          0\n",
       "Saved                           0\n",
       "Template                   461690\n",
       "DescriptionShown           461690\n",
       "LeftHand                   461690\n",
       "UserCountry3                33624\n",
       "Man                             0\n",
       "Woman                           0\n",
       "Pregnant                        0\n",
       "Stroller                        0\n",
       "OldMan                          0\n",
       "OldWoman                        0\n",
       "Boy                             0\n",
       "Girl                            0\n",
       "Homeless                        0\n",
       "LargeWoman                      0\n",
       "LargeMan                        0\n",
       "Criminal                        0\n",
       "MaleExecutive                   0\n",
       "FemaleExecutive                 0\n",
       "FemaleAthlete                   0\n",
       "MaleAthlete                     0\n",
       "FemaleDoctor                    0\n",
       "MaleDoctor                      0\n",
       "Dog                             0\n",
       "Cat                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting rows with NaN's in the UserID column\n",
    "\n",
    "df_mme = df_mme.dropna(subset=['UserID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3531626, 41)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.shape # should be 3532030 - 404 = 3531626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the total dataset has to be 500.000M rows.\n",
    "# 2% of that is LLM's, so 10.000 rows\n",
    "# the other 98% will be humans, so 490.000 rows\n",
    "\n",
    "# need to subset 980.000 rows from the 3531626 rows\n",
    "# need to delete 3531626 - 490.000 = 3041626 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1765813\n"
     ]
    }
   ],
   "source": [
    "# randomly delete 3041626 / 2 = 1520813 unique ResponseID's (is 3041626 rows), to ensure 2% of the dataset is LLMs and 98% humans\n",
    "\n",
    "# Getting unique UserIDs\n",
    "Response_unique = df_mme['ResponseID'].unique()\n",
    "print(len(Response_unique))  # should be 1765813 (3531626 / 2)\n",
    "\n",
    "# Selecting 640075 UserIDs from the unique set\n",
    "Response_delete = pd.Series(Response_unique).sample(n=1520813, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mme_98 = df_mme[~df_mme['ResponseID'].isin(Response_delete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490000, 41)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape of df_filtered\n",
    "\n",
    "df_mme_98.shape   # should be 490000, 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>222jc8QEnpn7JY5xh</td>\n",
       "      <td>-1776519460_4307308900611943.0</td>\n",
       "      <td>4.307309e+15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fat</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>22432qmaF4hm89J2S</td>\n",
       "      <td>1571418278_3796733224.0</td>\n",
       "      <td>3.796733e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fat</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>224hsRiqkMDrfH7oK</td>\n",
       "      <td>475932227_845246661</td>\n",
       "      <td>8.452467e+08</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>225bEAz8oPXRfCZP4</td>\n",
       "      <td>1321247612_3832968457.0</td>\n",
       "      <td>3.832968e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>226W8ti295a7Jo8vQ</td>\n",
       "      <td>1432798382_397954244</td>\n",
       "      <td>3.979542e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fit</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ResponseID               ExtendedSessionID        UserID  \\\n",
       "8   222jc8QEnpn7JY5xh  -1776519460_4307308900611943.0  4.307309e+15   \n",
       "25  22432qmaF4hm89J2S         1571418278_3796733224.0  3.796733e+09   \n",
       "31  224hsRiqkMDrfH7oK             475932227_845246661  8.452467e+08   \n",
       "43  225bEAz8oPXRfCZP4         1321247612_3832968457.0  3.832968e+09   \n",
       "54  226W8ti295a7Jo8vQ            1432798382_397954244  3.979542e+08   \n",
       "\n",
       "    ScenarioOrder  Intervention  PedPed  Barrier  CrossingSignal  \\\n",
       "8              13             0       0        0               0   \n",
       "25              9             0       1        0               2   \n",
       "31             11             0       0        1               0   \n",
       "43              2             0       1        0               0   \n",
       "54              1             0       1        0               2   \n",
       "\n",
       "   AttributeLevel ScenarioTypeStrict  ... LargeMan Criminal MaleExecutive  \\\n",
       "8             Fat            Fitness  ...      0.0      0.0           0.0   \n",
       "25            Fat            Fitness  ...      1.0      0.0           0.0   \n",
       "31        Hoomans            Species  ...      0.0      0.0           0.0   \n",
       "43           Male             Gender  ...      1.0      0.0           0.0   \n",
       "54            Fit            Fitness  ...      0.0      0.0           0.0   \n",
       "\n",
       "    FemaleExecutive  FemaleAthlete  MaleAthlete  FemaleDoctor MaleDoctor  Dog  \\\n",
       "8               0.0            0.0          0.0           0.0        0.0  0.0   \n",
       "25              0.0            0.0          0.0           0.0        0.0  0.0   \n",
       "31              0.0            0.0          0.0           0.0        0.0  0.0   \n",
       "43              0.0            0.0          1.0           0.0        0.0  0.0   \n",
       "54              0.0            1.0          1.0           0.0        0.0  0.0   \n",
       "\n",
       "    Cat  \n",
       "8   0.0  \n",
       "25  0.0  \n",
       "31  0.0  \n",
       "43  0.0  \n",
       "54  0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme_98.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# check what the distribution of RepsonseID's is (kinda)\n",
    "# check if the indices of a responseID here are the same after transforming the ResponseID column\n",
    "# if the indices are the same means ResponseID column is succesfully transformed\n",
    "\n",
    "indices = df_mme_98[df_mme_98[\"ResponseID\"] == '222JBu4KkKjnFQC9P'].index\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esmku\\AppData\\Local\\Temp\\ipykernel_26048\\1257459337.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mme_98['ResponseID'] = df_mme_98['ResponseID'].map(response_id_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Changing the responseID\n",
    "\n",
    "# Define the starting point for the new ResponseID\n",
    "starting_id = 773566\n",
    "\n",
    "# Step 1: Get the unique ResponseIDs\n",
    "unique_response_ids = df_mme_98['ResponseID'].unique()\n",
    "\n",
    "# Step 2: Create a mapping from old ResponseID to new 'res_' formatted ID\n",
    "response_id_mapping = {old_id: f'res_{i:08d}' for i, old_id in enumerate(unique_response_ids, starting_id)}\n",
    "\n",
    "# Step 3: Replace the original ResponseID with the new mapped IDs\n",
    "df_mme_98['ResponseID'] = df_mme_98['ResponseID'].map(response_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>res_00773566</td>\n",
       "      <td>-1776519460_4307308900611943.0</td>\n",
       "      <td>4.307309e+15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fat</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>res_00773567</td>\n",
       "      <td>1571418278_3796733224.0</td>\n",
       "      <td>3.796733e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fat</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>res_00773568</td>\n",
       "      <td>475932227_845246661</td>\n",
       "      <td>8.452467e+08</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>res_00773569</td>\n",
       "      <td>1321247612_3832968457.0</td>\n",
       "      <td>3.832968e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>res_00773570</td>\n",
       "      <td>1432798382_397954244</td>\n",
       "      <td>3.979542e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fit</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ResponseID               ExtendedSessionID        UserID  ScenarioOrder  \\\n",
       "8   res_00773566  -1776519460_4307308900611943.0  4.307309e+15             13   \n",
       "25  res_00773567         1571418278_3796733224.0  3.796733e+09              9   \n",
       "31  res_00773568             475932227_845246661  8.452467e+08             11   \n",
       "43  res_00773569         1321247612_3832968457.0  3.832968e+09              2   \n",
       "54  res_00773570            1432798382_397954244  3.979542e+08              1   \n",
       "\n",
       "    Intervention  PedPed  Barrier  CrossingSignal AttributeLevel  \\\n",
       "8              0       0        0               0            Fat   \n",
       "25             0       1        0               2            Fat   \n",
       "31             0       0        1               0        Hoomans   \n",
       "43             0       1        0               0           Male   \n",
       "54             0       1        0               2            Fit   \n",
       "\n",
       "   ScenarioTypeStrict  ... LargeMan Criminal MaleExecutive  FemaleExecutive  \\\n",
       "8             Fitness  ...      0.0      0.0           0.0              0.0   \n",
       "25            Fitness  ...      1.0      0.0           0.0              0.0   \n",
       "31            Species  ...      0.0      0.0           0.0              0.0   \n",
       "43             Gender  ...      1.0      0.0           0.0              0.0   \n",
       "54            Fitness  ...      0.0      0.0           0.0              0.0   \n",
       "\n",
       "    FemaleAthlete  MaleAthlete  FemaleDoctor MaleDoctor  Dog  Cat  \n",
       "8             0.0          0.0           0.0        0.0  0.0  0.0  \n",
       "25            0.0          0.0           0.0        0.0  0.0  0.0  \n",
       "31            0.0          0.0           0.0        0.0  0.0  0.0  \n",
       "43            0.0          1.0           0.0        0.0  0.0  0.0  \n",
       "54            1.0          1.0           0.0        0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResponseID starts with res_00627163\n",
    "df_mme_98.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([8, 504824], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "indices = df_mme_98[df_mme_98[\"ResponseID\"] == 'res_00773566'].index\n",
    "print(indices)\n",
    "\n",
    "# checking if the indices are the same after transforming the ResponseID column\n",
    "# compared to the indices of the ResponseID before transforming the column - they are!\n",
    "# both are [0, 504816]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3999968</th>\n",
       "      <td>res_01018561</td>\n",
       "      <td>987818427_761202927</td>\n",
       "      <td>7.612029e+08</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999978</th>\n",
       "      <td>res_01018562</td>\n",
       "      <td>1591577424_5650557499136071.0</td>\n",
       "      <td>5.650557e+15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Young</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999993</th>\n",
       "      <td>res_01018563</td>\n",
       "      <td>-1252544665_7351695836887306.0</td>\n",
       "      <td>7.351696e+15</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999994</th>\n",
       "      <td>res_01018564</td>\n",
       "      <td>1936263400_1837170696</td>\n",
       "      <td>1.837171e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Old</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999996</th>\n",
       "      <td>res_01018565</td>\n",
       "      <td>1617866231_4402803830519695.0</td>\n",
       "      <td>4.402804e+15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Less</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ResponseID               ExtendedSessionID        UserID  \\\n",
       "3999968  res_01018561             987818427_761202927  7.612029e+08   \n",
       "3999978  res_01018562   1591577424_5650557499136071.0  5.650557e+15   \n",
       "3999993  res_01018563  -1252544665_7351695836887306.0  7.351696e+15   \n",
       "3999994  res_01018564           1936263400_1837170696  1.837171e+09   \n",
       "3999996  res_01018565   1617866231_4402803830519695.0  4.402804e+15   \n",
       "\n",
       "         ScenarioOrder  Intervention  PedPed  Barrier  CrossingSignal  \\\n",
       "3999968              3             1       1        0               0   \n",
       "3999978             13             1       1        0               0   \n",
       "3999993              6             1       1        0               1   \n",
       "3999994              2             1       0        1               0   \n",
       "3999996              3             1       0        1               0   \n",
       "\n",
       "        AttributeLevel ScenarioTypeStrict  ... LargeMan Criminal  \\\n",
       "3999968           More        Utilitarian  ...      0.0      0.0   \n",
       "3999978          Young                Age  ...      0.0      0.0   \n",
       "3999993         Female             Gender  ...      0.0      0.0   \n",
       "3999994            Old                Age  ...      0.0      0.0   \n",
       "3999996           Less        Utilitarian  ...      0.0      0.0   \n",
       "\n",
       "        MaleExecutive  FemaleExecutive  FemaleAthlete  MaleAthlete  \\\n",
       "3999968           0.0              0.0            0.0          0.0   \n",
       "3999978           0.0              0.0            0.0          0.0   \n",
       "3999993           0.0              1.0            0.0          0.0   \n",
       "3999994           0.0              0.0            0.0          0.0   \n",
       "3999996           0.0              0.0            0.0          0.0   \n",
       "\n",
       "         FemaleDoctor MaleDoctor  Dog  Cat  \n",
       "3999968           1.0        0.0  0.0  0.0  \n",
       "3999978           0.0        0.0  0.0  0.0  \n",
       "3999993           0.0        0.0  0.0  0.0  \n",
       "3999994           0.0        0.0  0.0  0.0  \n",
       "3999996           1.0        2.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme_98.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index\n",
    "\n",
    "df_mme_98.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ResponseID', 'ExtendedSessionID', 'UserID', 'ScenarioOrder',\n",
       "       'Intervention', 'PedPed', 'Barrier', 'CrossingSignal', 'AttributeLevel',\n",
       "       'ScenarioTypeStrict', 'ScenarioType', 'DefaultChoice',\n",
       "       'NonDefaultChoice', 'DefaultChoiceIsOmission', 'NumberOfCharacters',\n",
       "       'DiffNumberOFCharacters', 'Saved', 'Template', 'DescriptionShown',\n",
       "       'LeftHand', 'UserCountry3', 'Man', 'Woman', 'Pregnant', 'Stroller',\n",
       "       'OldMan', 'OldWoman', 'Boy', 'Girl', 'Homeless', 'LargeWoman',\n",
       "       'LargeMan', 'Criminal', 'MaleExecutive', 'FemaleExecutive',\n",
       "       'FemaleAthlete', 'MaleAthlete', 'FemaleDoctor', 'MaleDoctor', 'Dog',\n",
       "       'Cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme_98.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserCountry3\n",
      "USA    124342\n",
      "DEU     31838\n",
      "BRA     27834\n",
      "FRA     27732\n",
      "GBR     25720\n",
      "        ...  \n",
      "VGB         2\n",
      "ATG         2\n",
      "MNP         2\n",
      "KNA         2\n",
      "MWI         2\n",
      "Name: count, Length: 198, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# some EDA on the country column to assess the distribution of the user ethnicity/culture\n",
    "# Can't do this later as then the column will be removed because of identifyable information - the LLM dataset does not have country information\n",
    "\n",
    "# checking which countries are in the dataset, and what their frequency is\n",
    "# need this for the comparison with the non_western_dataset\n",
    "\n",
    "print(df_mme_98['UserCountry3'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of countries considered 'Western' from the UN\n",
    "\n",
    "countries = [\"AND\",  \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DNK\", \"DEU\", \"ESP\", \"FIN\",  \"FRA\",  \"GBR\",  \"GRC\",  \"IRL\", \n",
    "            \"ISR\", \"ISL\", \"ITA\", \"LIE\", \"LUX\", \"MLT\", \"MCO\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SMR\", \"SWE\", \"TUR\", \"USA\" ]\n",
    "\n",
    "# Andorra, Australia, Austria, Belgium, Canada, Switzerland, Denmark, Germany, Spain, Finland, France, United Kingdom, Greece, Ireland, \n",
    "# Israel, Iceland, Italy, Liechtenstein, Luxembourg, Malta, Monaco, Netherlands, Norway, New Zealand, Portugal, San Marino, Sweden, Turkey, USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows Western: 338140\n",
      "Rounded % Western: 69\n",
      "Unrounded % Western: 69.00816326530612\n"
     ]
    }
   ],
   "source": [
    "# what number of rows that is from western countries?\n",
    "\n",
    "total_western = df_mme_98['UserCountry3'].isin(countries).sum()\n",
    "print(f\"Number of rows Western: {total_western}\")\n",
    "\n",
    "# this is % of the dataset that is from Western countries\n",
    "print(f\"Rounded % Western: {round(total_western /len(df_mme_98)*100)}\")     # rounded percentage\n",
    "print(f\"Unrounded % Western: {total_western /len(df_mme_98)*100}\")          # exact percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA of countries is now over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already deleting some columns to ensure it fits in memory\n",
    "# deleting the columns that are not necessary for the modelling\n",
    "\n",
    "df_mme_clean = df_mme_98.drop(columns=['ExtendedSessionID', 'DefaultChoice', 'NonDefaultChoice', 'DefaultChoiceIsOmission', 'Template', 'ScenarioType', 'ScenarioOrder', 'DescriptionShown', 'LeftHand', 'UserCountry3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490000, 31)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme_clean.shape # should be 2450000 rows and 31 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n\\n# List of columns for which to plot the frequency plots\\ncolumn_list = df_mme_clean.columns.drop(\\'ResponseID\\').tolist()\\n\\n# Set up the figure and subplots (adjust the number of rows/columns depending on the number of plots)\\nfig, axes = plt.subplots(6, 5, figsize=(30, 20))  # 2 rows, 3 columns, adjust as needed\\naxes = axes.flatten()  # Flatten the axes array for easy iteration\\n\\n# Loop through the columns and create subplots\\nfor i, column in enumerate(column_list):\\n    # Count the occurrences of each category\\n    category_counts = df_mme_clean[column].value_counts()\\n\\n    # Create a bar plot in the corresponding subplot axis\\n    axes[i].bar(category_counts.index, category_counts.values, width=0.75)\\n\\n    # Add labels and title for each subplot\\n    axes[i].set_xlabel(str(column))\\n    axes[i].set_ylabel(\\'Frequency\\')\\n    axes[i].set_title(f\"Frequency Plot of {column}\")\\n\\n    # If the plot has only 2 categories, adjust the x-ticks to show 0 and 1\\n    if len(category_counts.index) == 2:\\n        axes[i].set_xticks([0, 1])\\n\\n# Automatically adjust the layout for better spacing\\nplt.tight_layout()\\n\\n# Show the entire figure with all subplots\\nplt.show()'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# List of columns for which to plot the frequency plots\n",
    "column_list = df_mme_clean.columns.drop('ResponseID').tolist()\n",
    "\n",
    "# Set up the figure and subplots (adjust the number of rows/columns depending on the number of plots)\n",
    "fig, axes = plt.subplots(6, 5, figsize=(30, 20))  # 2 rows, 3 columns, adjust as needed\n",
    "axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "# Loop through the columns and create subplots\n",
    "for i, column in enumerate(column_list):\n",
    "    # Count the occurrences of each category\n",
    "    category_counts = df_mme_clean[column].value_counts()\n",
    "\n",
    "    # Create a bar plot in the corresponding subplot axis\n",
    "    axes[i].bar(category_counts.index, category_counts.values, width=0.75)\n",
    "\n",
    "    # Add labels and title for each subplot\n",
    "    axes[i].set_xlabel(str(column))\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].set_title(f\"Frequency Plot of {column}\")\n",
    "\n",
    "    # If the plot has only 2 categories, adjust the x-ticks to show 0 and 1\n",
    "    if len(category_counts.index) == 2:\n",
    "        axes[i].set_xticks([0, 1])\n",
    "\n",
    "# Automatically adjust the layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the entire figure with all subplots\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarizing UserID - making all into 0\n",
    "df_mme_clean['UserID'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving this pre-preprocessed mme dataset to a csv file\n",
    "\n",
    "df_mme_clean.to_csv('mme_98_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50/50 MME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want a dataset of 1M rows, .5M LLM, .5M human\n",
    "\n",
    "# creating the .5M rows of the human part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'ResponseID': 'category',\n",
    "    'UserID': 'int8',\n",
    "    'Intervention': 'int8',\n",
    "    'PedPed': 'int8',\n",
    "    'Barrier': 'int8',\n",
    "    'CrossingSignal': 'int8',\n",
    "    'AttributeLevel': 'category',\n",
    "    'ScenarioTypeStrict': 'category',\n",
    "    'NumberOfCharacters': 'int8',\n",
    "    'DiffNumberOFCharacters': 'int8',\n",
    "    'Saved': 'int8',\n",
    "    'Man': 'int8',\n",
    "    'Woman': 'int8',\n",
    "    'Pregnant': 'int8',\n",
    "    'Stroller': 'int8',\n",
    "    'OldMan': 'int8',\n",
    "    'OldWoman': 'int8',\n",
    "    'Boy': 'int8',\n",
    "    'Girl': 'int8',\n",
    "    'Homeless': 'int8',\n",
    "    'LargeWoman': 'int8',\n",
    "    'LargeMan': 'int8',\n",
    "    'Criminal': 'int8',\n",
    "    'MaleExecutive': 'int8',\n",
    "    'FemaleExecutive': 'int8',\n",
    "    'FemaleAthlete': 'int8',\n",
    "    'MaleAthlete': 'int8',\n",
    "    'FemaleDoctor': 'int8',\n",
    "    'MaleDoctor': 'int8',\n",
    "    'Dog': 'int8',\n",
    "    'Cat': 'int8'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function make_subset\n",
    "\n",
    "def make_subset(data, sample_size, filter_value, types):\n",
    "\n",
    "    \"\"\" \n",
    "    Function to create a subset of the original dataset based on the ResponseID's of the original dataset.\n",
    "    It will create a subset based on a value of the UserID column\n",
    "    The function will return a new dataframe with the same columns as the original dataset, where the ResponseID's are kept together.\n",
    "\n",
    "    Input:\n",
    "    - Data: a string with the path to the dataset that a subset has to be taken of\n",
    "    - Sample_size: the size of the subset that has to be taken\n",
    "    - Filter_value: the value of the UserID column that has to be filtered on (either 1 or 0). The subset will then only be of the either LLM's or humans\n",
    "    - Types: a dictionary with the column names as keys and the data types as values\n",
    "    \n",
    "    Output:\n",
    "    - A new dataframe with the subset of the original dataset\n",
    "    \n",
    "    Using chunks to ensure fast processing\n",
    "    \"\"\"\n",
    "\n",
    "    df_tot = pd.read_csv(data, dtype=dtype)\n",
    "    sample = int(sample_size/2)\n",
    "\n",
    "    df_tot = df_tot[df_tot['UserID'] == filter_value]                                           # getting a subset of either only LLM's or MME's (1 or 0)\n",
    "    unique_ids = df_tot.drop_duplicates(subset=['ResponseID'], keep='first')                    # only keeping unique ResponseID's (not their duplicate)\n",
    "    RID_list = unique_ids['ResponseID'].sample(n=sample, random_state=41).to_list()             # to a list the ResponseID's to be kept\n",
    "\n",
    "    print(f'Expected nr of rows in output df: {len(RID_list)*2}')                               # expected size of output df\n",
    "\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    chunk_size = 500_000\n",
    "    reader = pd.read_csv(data, chunksize=chunk_size, low_memory=False)\n",
    "\n",
    "    for i, chunk in enumerate(reader):\n",
    "    \n",
    "        print(f\"Processing chunk {i+1}\")\n",
    "\n",
    "        # Filter rows where ResponseID is in reader_subset\n",
    "        subset_chunk = chunk[chunk['ResponseID'].isin(RID_list)]\n",
    "\n",
    "        # Append filtered chunk to empty df\n",
    "        new_df = pd.concat([new_df, subset_chunk], ignore_index=True)\n",
    "\n",
    "        print(f\"Finished processing chunk {i+1}\")\n",
    "\n",
    "    print(\"All chunks have been processed and combined.\")\n",
    "\n",
    "    print(new_df.shape)\n",
    "\n",
    "    # check if each ResponseID is present twice\n",
    "    print(new_df['ResponseID'].nunique() == (new_df.shape[0]/2))   # should be True\n",
    "\n",
    "    new_df = new_df.astype(dtype=types)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "\n",
    "# will use the resulting dataframes from this function combined to create a final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of \n",
    "# 0 = 500000\n",
    "# 1 = 500000\n",
    "# to get a total dataset of 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting 1250000 rows with ResponseID = 0 from the original dataset\n",
    "import pandas as pd\n",
    "df_original = pd.read_csv('mme_98_dataset.csv', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490000, 31)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected nr of rows in output df: 250000\n",
      "Processing chunk 1\n",
      "Finished processing chunk 1\n",
      "All chunks have been processed and combined.\n",
      "(250000, 31)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# making subset of 1.25M of class 0, using the make_subset function from above\n",
    "df50_sub_0 = make_subset('mme_98_dataset.csv', 250000, 0, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 31)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df50_sub_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df50_sub_0['ResponseID'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving this pre-preprocessed mme dataset to a csv file\n",
    "\n",
    "df50_sub_0.to_csv('mme_50_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
