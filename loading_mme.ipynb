{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and creating the mme_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dataframe with only the ExtendedSessionID column from the 71M SharedResponses.csv file\n",
    "\n",
    "reader2 = pd.read_csv('SharedResponses.csv', usecols=['ResponseID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code that will check if there are two of them in the dataset\n",
    "\n",
    "# Count how many times each ResponseID appears\n",
    "response_counts = reader2['ResponseID'].value_counts()\n",
    "\n",
    "# Get the ResponseIDs that appear exactly twice\n",
    "ids_to_keep = response_counts[response_counts == 2].index\n",
    "\n",
    "# Filter the rows where ResponseID is in the list of ids_to_keep\n",
    "complete_responseid = reader2[reader2['ResponseID'].isin(ids_to_keep)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_responseid.value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67907006, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_responseid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on 'ResponseID' and keep the first occurrence\n",
    "complete_responseid = complete_responseid.drop_duplicates(subset=['ResponseID'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_subset = complete_responseid.sample(n=3500000) # want 7M rows (with accounting for NAn's and deleting rows with 'random' (around 10%)), so 7M / 2 = 3.5M ResponseID's necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseID    3500000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if they are all unique\n",
    "\n",
    "reader_subset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to a list to feed to the for loop that will extract all the corresponding columns from the SharedResponses.csv file\n",
    "\n",
    "reader_sub_list = reader_subset['ResponseID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500000\n"
     ]
    }
   ],
   "source": [
    "# check if it went okay\n",
    "print(len(reader_sub_list))     # should be 8500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dataframe to append the rows of the sessions with 24 rows to\n",
    "\n",
    "subset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1\n",
      "Finished processing chunk 1\n",
      "Processing chunk 2\n",
      "Finished processing chunk 2\n",
      "Processing chunk 3\n",
      "Finished processing chunk 3\n",
      "Processing chunk 4\n",
      "Finished processing chunk 4\n",
      "Processing chunk 5\n",
      "Finished processing chunk 5\n",
      "Processing chunk 6\n",
      "Finished processing chunk 6\n",
      "Processing chunk 7\n",
      "Finished processing chunk 7\n",
      "Processing chunk 8\n",
      "Finished processing chunk 8\n",
      "Processing chunk 9\n",
      "Finished processing chunk 9\n",
      "Processing chunk 10\n",
      "Finished processing chunk 10\n",
      "Processing chunk 11\n",
      "Finished processing chunk 11\n",
      "Processing chunk 12\n",
      "Finished processing chunk 12\n",
      "Processing chunk 13\n",
      "Finished processing chunk 13\n",
      "Processing chunk 14\n",
      "Finished processing chunk 14\n",
      "Processing chunk 15\n",
      "Finished processing chunk 15\n",
      "Processing chunk 16\n",
      "Finished processing chunk 16\n",
      "Processing chunk 17\n",
      "Finished processing chunk 17\n",
      "Processing chunk 18\n",
      "Finished processing chunk 18\n",
      "Processing chunk 19\n",
      "Finished processing chunk 19\n",
      "Processing chunk 20\n",
      "Finished processing chunk 20\n",
      "Processing chunk 21\n",
      "Finished processing chunk 21\n",
      "Processing chunk 22\n",
      "Finished processing chunk 22\n",
      "Processing chunk 23\n",
      "Finished processing chunk 23\n",
      "Processing chunk 24\n",
      "Finished processing chunk 24\n",
      "Processing chunk 25\n",
      "Finished processing chunk 25\n",
      "Processing chunk 26\n",
      "Finished processing chunk 26\n",
      "Processing chunk 27\n",
      "Finished processing chunk 27\n",
      "Processing chunk 28\n",
      "Finished processing chunk 28\n",
      "Processing chunk 29\n",
      "Finished processing chunk 29\n",
      "Processing chunk 30\n",
      "Finished processing chunk 30\n",
      "Processing chunk 31\n",
      "Finished processing chunk 31\n",
      "Processing chunk 32\n",
      "Finished processing chunk 32\n",
      "Processing chunk 33\n",
      "Finished processing chunk 33\n",
      "Processing chunk 34\n",
      "Finished processing chunk 34\n",
      "Processing chunk 35\n",
      "Finished processing chunk 35\n",
      "Processing chunk 36\n",
      "Finished processing chunk 36\n",
      "Processing chunk 37\n",
      "Finished processing chunk 37\n",
      "Processing chunk 38\n",
      "Finished processing chunk 38\n",
      "Processing chunk 39\n",
      "Finished processing chunk 39\n",
      "Processing chunk 40\n",
      "Finished processing chunk 40\n",
      "Processing chunk 41\n",
      "Finished processing chunk 41\n",
      "Processing chunk 42\n",
      "Finished processing chunk 42\n",
      "Processing chunk 43\n",
      "Finished processing chunk 43\n",
      "Processing chunk 44\n",
      "Finished processing chunk 44\n",
      "Processing chunk 45\n",
      "Finished processing chunk 45\n",
      "Processing chunk 46\n",
      "Finished processing chunk 46\n",
      "Processing chunk 47\n",
      "Finished processing chunk 47\n",
      "Processing chunk 48\n",
      "Finished processing chunk 48\n",
      "Processing chunk 49\n",
      "Finished processing chunk 49\n",
      "Processing chunk 50\n",
      "Finished processing chunk 50\n",
      "Processing chunk 51\n",
      "Finished processing chunk 51\n",
      "Processing chunk 52\n",
      "Finished processing chunk 52\n",
      "Processing chunk 53\n",
      "Finished processing chunk 53\n",
      "Processing chunk 54\n",
      "Finished processing chunk 54\n",
      "Processing chunk 55\n",
      "Finished processing chunk 55\n",
      "Processing chunk 56\n",
      "Finished processing chunk 56\n",
      "Processing chunk 57\n",
      "Finished processing chunk 57\n",
      "Processing chunk 58\n",
      "Finished processing chunk 58\n",
      "Processing chunk 59\n",
      "Finished processing chunk 59\n",
      "Processing chunk 60\n",
      "Finished processing chunk 60\n",
      "Processing chunk 61\n",
      "Finished processing chunk 61\n",
      "Processing chunk 62\n",
      "Finished processing chunk 62\n",
      "Processing chunk 63\n",
      "Finished processing chunk 63\n",
      "Processing chunk 64\n",
      "Finished processing chunk 64\n",
      "Processing chunk 65\n",
      "Finished processing chunk 65\n",
      "Processing chunk 66\n",
      "Finished processing chunk 66\n",
      "Processing chunk 67\n",
      "Finished processing chunk 67\n",
      "Processing chunk 68\n",
      "Finished processing chunk 68\n",
      "Processing chunk 69\n",
      "Finished processing chunk 69\n",
      "Processing chunk 70\n",
      "Finished processing chunk 70\n",
      "Processing chunk 71\n",
      "Finished processing chunk 71\n",
      "Processing chunk 72\n",
      "Finished processing chunk 72\n",
      "Processing chunk 73\n",
      "Finished processing chunk 73\n",
      "Processing chunk 74\n",
      "Finished processing chunk 74\n",
      "Processing chunk 75\n",
      "Finished processing chunk 75\n",
      "Processing chunk 76\n",
      "Finished processing chunk 76\n",
      "Processing chunk 77\n",
      "Finished processing chunk 77\n",
      "Processing chunk 78\n",
      "Finished processing chunk 78\n",
      "Processing chunk 79\n",
      "Finished processing chunk 79\n",
      "Processing chunk 80\n",
      "Finished processing chunk 80\n",
      "Processing chunk 81\n",
      "Finished processing chunk 81\n",
      "Processing chunk 82\n",
      "Finished processing chunk 82\n",
      "Processing chunk 83\n",
      "Finished processing chunk 83\n",
      "Processing chunk 84\n",
      "Finished processing chunk 84\n",
      "Processing chunk 85\n",
      "Finished processing chunk 85\n",
      "Processing chunk 86\n",
      "Finished processing chunk 86\n",
      "Processing chunk 87\n",
      "Finished processing chunk 87\n",
      "Processing chunk 88\n",
      "Finished processing chunk 88\n",
      "Processing chunk 89\n",
      "Finished processing chunk 89\n",
      "Processing chunk 90\n",
      "Finished processing chunk 90\n",
      "Processing chunk 91\n",
      "Finished processing chunk 91\n",
      "Processing chunk 92\n",
      "Finished processing chunk 92\n",
      "Processing chunk 93\n",
      "Finished processing chunk 93\n",
      "Processing chunk 94\n",
      "Finished processing chunk 94\n",
      "Processing chunk 95\n",
      "Finished processing chunk 95\n",
      "Processing chunk 96\n",
      "Finished processing chunk 96\n",
      "Processing chunk 97\n",
      "Finished processing chunk 97\n",
      "Processing chunk 98\n",
      "Finished processing chunk 98\n",
      "Processing chunk 99\n",
      "Finished processing chunk 99\n",
      "Processing chunk 100\n",
      "Finished processing chunk 100\n",
      "Processing chunk 101\n",
      "Finished processing chunk 101\n",
      "Processing chunk 102\n",
      "Finished processing chunk 102\n",
      "Processing chunk 103\n",
      "Finished processing chunk 103\n",
      "Processing chunk 104\n",
      "Finished processing chunk 104\n",
      "Processing chunk 105\n",
      "Finished processing chunk 105\n",
      "Processing chunk 106\n",
      "Finished processing chunk 106\n",
      "Processing chunk 107\n",
      "Finished processing chunk 107\n",
      "Processing chunk 108\n",
      "Finished processing chunk 108\n",
      "Processing chunk 109\n",
      "Finished processing chunk 109\n",
      "Processing chunk 110\n",
      "Finished processing chunk 110\n",
      "Processing chunk 111\n",
      "Finished processing chunk 111\n",
      "Processing chunk 112\n",
      "Finished processing chunk 112\n",
      "Processing chunk 113\n",
      "Finished processing chunk 113\n",
      "Processing chunk 114\n",
      "Finished processing chunk 114\n",
      "Processing chunk 115\n",
      "Finished processing chunk 115\n",
      "Processing chunk 116\n",
      "Finished processing chunk 116\n",
      "Processing chunk 117\n",
      "Finished processing chunk 117\n",
      "Processing chunk 118\n",
      "Finished processing chunk 118\n",
      "Processing chunk 119\n",
      "Finished processing chunk 119\n",
      "Processing chunk 120\n",
      "Finished processing chunk 120\n",
      "Processing chunk 121\n",
      "Finished processing chunk 121\n",
      "Processing chunk 122\n",
      "Finished processing chunk 122\n",
      "Processing chunk 123\n",
      "Finished processing chunk 123\n",
      "Processing chunk 124\n",
      "Finished processing chunk 124\n",
      "Processing chunk 125\n",
      "Finished processing chunk 125\n",
      "Processing chunk 126\n",
      "Finished processing chunk 126\n",
      "Processing chunk 127\n",
      "Finished processing chunk 127\n",
      "Processing chunk 128\n",
      "Finished processing chunk 128\n",
      "Processing chunk 129\n",
      "Finished processing chunk 129\n",
      "Processing chunk 130\n",
      "Finished processing chunk 130\n",
      "Processing chunk 131\n",
      "Finished processing chunk 131\n",
      "Processing chunk 132\n",
      "Finished processing chunk 132\n",
      "Processing chunk 133\n",
      "Finished processing chunk 133\n",
      "Processing chunk 134\n",
      "Finished processing chunk 134\n",
      "Processing chunk 135\n",
      "Finished processing chunk 135\n",
      "Processing chunk 136\n",
      "Finished processing chunk 136\n",
      "Processing chunk 137\n",
      "Finished processing chunk 137\n",
      "Processing chunk 138\n",
      "Finished processing chunk 138\n",
      "Processing chunk 139\n",
      "Finished processing chunk 139\n",
      "Processing chunk 140\n",
      "Finished processing chunk 140\n",
      "Processing chunk 141\n",
      "Finished processing chunk 141\n",
      "All chunks have been processed and combined.\n"
     ]
    }
   ],
   "source": [
    "# reading SharedResponses to extract the rows with ResponseID's in reader_sub_list\n",
    "# this will result in a dataframe 'subset' that contains around 7 million rows (3,5 * 2)\n",
    "\n",
    "chunk_size = 500_000\n",
    "reader = pd.read_csv('SharedResponses.csv', chunksize=chunk_size, dtype=str, low_memory=False)\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    \n",
    "    print(f\"Processing chunk {i+1}\")\n",
    "\n",
    "    # Filter rows where ResponseID is in reader_subset\n",
    "    subset_chunk = chunk[chunk['ResponseID'].isin(reader_sub_list)]\n",
    "\n",
    "    # Append filtered chunk to empty df\n",
    "    subset = pd.concat([subset, subset_chunk], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished processing chunk {i+1}\")\n",
    "\n",
    "print(\"All chunks have been processed and combined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000000, 41)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_csv = subset.to_csv('subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esmku\\AppData\\Local\\Temp\\ipykernel_21064\\2060601064.py:2: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_mme = pd.read_csv('subset.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_mme = pd.read_csv('subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000000, 41)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2222sJk4DcoqXXi98</td>\n",
       "      <td>1043988516_3525281295.0</td>\n",
       "      <td>3.525281e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rand</td>\n",
       "      <td>Random</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2223jMWDEGNeszivb</td>\n",
       "      <td>-1683127088_785070916172117.0</td>\n",
       "      <td>7.850709e+14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2225gNWJcAeE92LXd</td>\n",
       "      <td>2069688900_9887644874714294.0</td>\n",
       "      <td>9.887645e+15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222BhQ87fGnAC4FWY</td>\n",
       "      <td>-2134337540_4570487844678215.0</td>\n",
       "      <td>4.570488e+15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222Bih22xMQR5brhF</td>\n",
       "      <td>-841718081_3084184331213722.0</td>\n",
       "      <td>3.084184e+15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ResponseID               ExtendedSessionID        UserID  \\\n",
       "0  2222sJk4DcoqXXi98         1043988516_3525281295.0  3.525281e+09   \n",
       "1  2223jMWDEGNeszivb   -1683127088_785070916172117.0  7.850709e+14   \n",
       "2  2225gNWJcAeE92LXd   2069688900_9887644874714294.0  9.887645e+15   \n",
       "3  222BhQ87fGnAC4FWY  -2134337540_4570487844678215.0  4.570488e+15   \n",
       "4  222Bih22xMQR5brhF   -841718081_3084184331213722.0  3.084184e+15   \n",
       "\n",
       "   ScenarioOrder  Intervention  PedPed  Barrier  CrossingSignal  \\\n",
       "0              2             0       0        0               0   \n",
       "1              8             0       1        0               2   \n",
       "2              3             0       0        1               0   \n",
       "3              6             0       0        1               0   \n",
       "4             11             0       0        0               2   \n",
       "\n",
       "  AttributeLevel ScenarioTypeStrict  ... LargeMan Criminal MaleExecutive  \\\n",
       "0           Rand             Random  ...      0.0      0.0           1.0   \n",
       "1           More        Utilitarian  ...      0.0      1.0           1.0   \n",
       "2           More        Utilitarian  ...      0.0      0.0           0.0   \n",
       "3           Male             Gender  ...      0.0      0.0           0.0   \n",
       "4           Pets            Species  ...      0.0      0.0           0.0   \n",
       "\n",
       "   FemaleExecutive  FemaleAthlete  MaleAthlete  FemaleDoctor MaleDoctor  Dog  \\\n",
       "0              0.0            0.0          0.0           0.0        0.0  0.0   \n",
       "1              0.0            1.0          0.0           0.0        0.0  1.0   \n",
       "2              0.0            0.0          1.0           0.0        0.0  1.0   \n",
       "3              0.0            0.0          0.0           0.0        0.0  0.0   \n",
       "4              0.0            0.0          0.0           0.0        0.0  2.0   \n",
       "\n",
       "   Cat  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  1.0  \n",
       "3  0.0  \n",
       "4  2.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScenarioTypeStrict\n",
       "Utilitarian      1256212\n",
       "Species          1235954\n",
       "Age              1234418\n",
       "Fitness          1233222\n",
       "Gender           1232558\n",
       "Random            615844\n",
       "Social Status     191792\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme['ScenarioTypeStrict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all rows with 'random' in the ScenarioTypeStrict column, as LLM's don't have a random scenario\n",
    "\n",
    "df_mme = df_mme[df_mme['ScenarioTypeStrict'] != 'Random']\n",
    "\n",
    "# should be 7000000 - 615844 = 6384156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6384156, 41)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttributeLevel\n",
       "More       628106\n",
       "Less       628106\n",
       "Pets       617977\n",
       "Hoomans    617977\n",
       "Male       616279\n",
       "Female     616279\n",
       "Young      596653\n",
       "Old        596653\n",
       "Fat        556350\n",
       "Fit        556350\n",
       "Rand       203250\n",
       "Low         75088\n",
       "High        75088\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing all rows with 'Rand' in the AttributeLevel column, as LLM's don't have a random scenario\n",
    "df_mme['AttributeLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mme = df_mme[df_mme['AttributeLevel'] != 'Rand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6180906, 41)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.shape # should be 6384156 - 203250 = 6180906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseID                      0\n",
       "ExtendedSessionID               0\n",
       "UserID                        756\n",
       "ScenarioOrder                   0\n",
       "Intervention                    0\n",
       "PedPed                          0\n",
       "Barrier                         0\n",
       "CrossingSignal                  0\n",
       "AttributeLevel                  0\n",
       "ScenarioTypeStrict              0\n",
       "ScenarioType                    0\n",
       "DefaultChoice                   0\n",
       "NonDefaultChoice                0\n",
       "DefaultChoiceIsOmission         0\n",
       "NumberOfCharacters              0\n",
       "DiffNumberOFCharacters          0\n",
       "Saved                           0\n",
       "Template                   804942\n",
       "DescriptionShown           804942\n",
       "LeftHand                   804942\n",
       "UserCountry3                58372\n",
       "Man                             0\n",
       "Woman                           0\n",
       "Pregnant                        0\n",
       "Stroller                        0\n",
       "OldMan                          0\n",
       "OldWoman                        0\n",
       "Boy                             0\n",
       "Girl                            0\n",
       "Homeless                        0\n",
       "LargeWoman                      0\n",
       "LargeMan                        0\n",
       "Criminal                        0\n",
       "MaleExecutive                   0\n",
       "FemaleExecutive                 0\n",
       "FemaleAthlete                   0\n",
       "MaleAthlete                     0\n",
       "FemaleDoctor                    0\n",
       "MaleDoctor                      0\n",
       "Dog                             0\n",
       "Cat                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting rows with NaN's in the UserID column\n",
    "\n",
    "df_mme = df_mme.dropna(subset=['UserID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6180150, 41)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme.shape # should be 6180906 - 756 = 6180150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the total dataset has to be 5M rows.\n",
    "# 2% of that is LLM's, so 100.000 rows\n",
    "# the other 98% will be humans, so 4.900.000 rows\n",
    "\n",
    "# need to subset 4900000 rows from the 6180150 rows\n",
    "# need to delete 6180150 - 4900000 = 1280150 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3090075\n"
     ]
    }
   ],
   "source": [
    "# randomly delete 1280150 / 2 = 640075 unique ResponseID's (is 1280150 rows), to ensure 2% of the dataset is LLMs and 98% humans\n",
    "\n",
    "# Getting unique UserIDs\n",
    "Response_unique = df_mme['ResponseID'].unique()\n",
    "print(len(Response_unique))  # should be 3090075\n",
    "\n",
    "# Selecting 640075 UserIDs from the unique set\n",
    "Response_delete = pd.Series(Response_unique).sample(n=640075, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mme_98 = df_mme[~df_mme['ResponseID'].isin(Response_delete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4900000, 41)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape of df_filtered\n",
    "\n",
    "df_mme_98.shape   # should be 6180150 - 1280150 = 4900000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2223jMWDEGNeszivb</td>\n",
       "      <td>-1683127088_785070916172117.0</td>\n",
       "      <td>7.850709e+14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222BhQ87fGnAC4FWY</td>\n",
       "      <td>-2134337540_4570487844678215.0</td>\n",
       "      <td>4.570488e+15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222Bih22xMQR5brhF</td>\n",
       "      <td>-841718081_3084184331213722.0</td>\n",
       "      <td>3.084184e+15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>222KuWty7pNeiv77a</td>\n",
       "      <td>1654911454_3639764894860440.0</td>\n",
       "      <td>3.639765e+15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social Status</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>222PL8SYdZnhNnSGp</td>\n",
       "      <td>-2091429432_6630077581817493.0</td>\n",
       "      <td>6.630078e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ResponseID               ExtendedSessionID        UserID  \\\n",
       "1  2223jMWDEGNeszivb   -1683127088_785070916172117.0  7.850709e+14   \n",
       "3  222BhQ87fGnAC4FWY  -2134337540_4570487844678215.0  4.570488e+15   \n",
       "4  222Bih22xMQR5brhF   -841718081_3084184331213722.0  3.084184e+15   \n",
       "5  222KuWty7pNeiv77a   1654911454_3639764894860440.0  3.639765e+15   \n",
       "7  222PL8SYdZnhNnSGp  -2091429432_6630077581817493.0  6.630078e+15   \n",
       "\n",
       "   ScenarioOrder  Intervention  PedPed  Barrier  CrossingSignal  \\\n",
       "1              8             0       1        0               2   \n",
       "3              6             0       0        1               0   \n",
       "4             11             0       0        0               2   \n",
       "5              8             0       1        0               0   \n",
       "7              1             0       1        0               1   \n",
       "\n",
       "  AttributeLevel ScenarioTypeStrict  ... LargeMan Criminal MaleExecutive  \\\n",
       "1           More        Utilitarian  ...      0.0      1.0           1.0   \n",
       "3           Male             Gender  ...      0.0      0.0           0.0   \n",
       "4           Pets            Species  ...      0.0      0.0           0.0   \n",
       "5            Low      Social Status  ...      0.0      0.0           0.0   \n",
       "7        Hoomans            Species  ...      0.0      0.0           0.0   \n",
       "\n",
       "   FemaleExecutive  FemaleAthlete  MaleAthlete  FemaleDoctor MaleDoctor  Dog  \\\n",
       "1              0.0            1.0          0.0           0.0        0.0  1.0   \n",
       "3              0.0            0.0          0.0           0.0        0.0  0.0   \n",
       "4              0.0            0.0          0.0           0.0        0.0  2.0   \n",
       "5              0.0            0.0          0.0           0.0        0.0  0.0   \n",
       "7              0.0            0.0          0.0           0.0        0.0  0.0   \n",
       "\n",
       "   Cat  \n",
       "1  0.0  \n",
       "3  0.0  \n",
       "4  2.0  \n",
       "5  0.0  \n",
       "7  0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme_98.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([1, 882974], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# check what the distribution of RepsonseID's is (kinda)\n",
    "# check if the indices of a responseID here are the same after transforming the ResponseID column\n",
    "# if the indices are the same means ResponseID column is succesfully transformed\n",
    "\n",
    "indices = df_mme_98[df_mme_98[\"ResponseID\"] == '2223jMWDEGNeszivb'].index\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esmku\\AppData\\Local\\Temp\\ipykernel_21064\\3824585436.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mme_98['ResponseID'] = df_mme_98['ResponseID'].map(response_id_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Changing the responseID\n",
    "\n",
    "# Define the starting point for the new ResponseID\n",
    "starting_id = 146784\n",
    "\n",
    "# Step 1: Get the unique ResponseIDs\n",
    "unique_response_ids = df_mme_98['ResponseID'].unique()\n",
    "\n",
    "# Step 2: Create a mapping from old ResponseID to new 'res_' formatted ID\n",
    "response_id_mapping = {old_id: f'res_{i:08d}' for i, old_id in enumerate(unique_response_ids, starting_id)}\n",
    "\n",
    "# Step 3: Replace the original ResponseID with the new mapped IDs\n",
    "df_mme_98['ResponseID'] = df_mme_98['ResponseID'].map(response_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>res_00146784</td>\n",
       "      <td>-1683127088_785070916172117.0</td>\n",
       "      <td>7.850709e+14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res_00146785</td>\n",
       "      <td>-2134337540_4570487844678215.0</td>\n",
       "      <td>4.570488e+15</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>res_00146786</td>\n",
       "      <td>-841718081_3084184331213722.0</td>\n",
       "      <td>3.084184e+15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>res_00146787</td>\n",
       "      <td>1654911454_3639764894860440.0</td>\n",
       "      <td>3.639765e+15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social Status</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>res_00146788</td>\n",
       "      <td>-2091429432_6630077581817493.0</td>\n",
       "      <td>6.630078e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ResponseID               ExtendedSessionID        UserID  ScenarioOrder  \\\n",
       "1  res_00146784   -1683127088_785070916172117.0  7.850709e+14              8   \n",
       "3  res_00146785  -2134337540_4570487844678215.0  4.570488e+15              6   \n",
       "4  res_00146786   -841718081_3084184331213722.0  3.084184e+15             11   \n",
       "5  res_00146787   1654911454_3639764894860440.0  3.639765e+15              8   \n",
       "7  res_00146788  -2091429432_6630077581817493.0  6.630078e+15              1   \n",
       "\n",
       "   Intervention  PedPed  Barrier  CrossingSignal AttributeLevel  \\\n",
       "1             0       1        0               2           More   \n",
       "3             0       0        1               0           Male   \n",
       "4             0       0        0               2           Pets   \n",
       "5             0       1        0               0            Low   \n",
       "7             0       1        0               1        Hoomans   \n",
       "\n",
       "  ScenarioTypeStrict  ... LargeMan Criminal MaleExecutive  FemaleExecutive  \\\n",
       "1        Utilitarian  ...      0.0      1.0           1.0              0.0   \n",
       "3             Gender  ...      0.0      0.0           0.0              0.0   \n",
       "4            Species  ...      0.0      0.0           0.0              0.0   \n",
       "5      Social Status  ...      0.0      0.0           0.0              0.0   \n",
       "7            Species  ...      0.0      0.0           0.0              0.0   \n",
       "\n",
       "   FemaleAthlete  MaleAthlete  FemaleDoctor MaleDoctor  Dog  Cat  \n",
       "1            1.0          0.0           0.0        0.0  1.0  0.0  \n",
       "3            0.0          0.0           0.0        0.0  0.0  0.0  \n",
       "4            0.0          0.0           0.0        0.0  2.0  2.0  \n",
       "5            0.0          0.0           0.0        0.0  0.0  0.0  \n",
       "7            0.0          0.0           0.0        0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResponseID starts with res_00146784\n",
    "df_mme_98.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([1, 882974], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "indices = df_mme_98[df_mme_98[\"ResponseID\"] == 'res_00146784'].index\n",
    "print(indices)\n",
    "\n",
    "# checking if the indices are the same after transforming the ResponseID column\n",
    "# compared to the indices of the ResponseID before transforming the column - they are!\n",
    "# both are [2, 882974]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6999990</th>\n",
       "      <td>res_02596779</td>\n",
       "      <td>-1536551642_3428762455.0</td>\n",
       "      <td>3.428762e+09</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Less</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999991</th>\n",
       "      <td>res_02596780</td>\n",
       "      <td>-1409806035_678401095</td>\n",
       "      <td>6.784011e+08</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999992</th>\n",
       "      <td>res_02596781</td>\n",
       "      <td>-1222087996_908819923</td>\n",
       "      <td>9.088199e+08</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999995</th>\n",
       "      <td>res_02596782</td>\n",
       "      <td>59083021_6350949440772371.0</td>\n",
       "      <td>6.350949e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fit</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999997</th>\n",
       "      <td>res_02596783</td>\n",
       "      <td>-1845235964_3077453412676796.0</td>\n",
       "      <td>3.077453e+15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ResponseID               ExtendedSessionID        UserID  \\\n",
       "6999990  res_02596779        -1536551642_3428762455.0  3.428762e+09   \n",
       "6999991  res_02596780           -1409806035_678401095  6.784011e+08   \n",
       "6999992  res_02596781           -1222087996_908819923  9.088199e+08   \n",
       "6999995  res_02596782     59083021_6350949440772371.0  6.350949e+15   \n",
       "6999997  res_02596783  -1845235964_3077453412676796.0  3.077453e+15   \n",
       "\n",
       "         ScenarioOrder  Intervention  PedPed  Barrier  CrossingSignal  \\\n",
       "6999990              8             1       1        0               0   \n",
       "6999991              6             1       0        1               0   \n",
       "6999992             13             1       1        0               0   \n",
       "6999995              1             1       1        0               0   \n",
       "6999997              4             1       1        0               0   \n",
       "\n",
       "        AttributeLevel ScenarioTypeStrict  ... LargeMan Criminal  \\\n",
       "6999990           Less        Utilitarian  ...      0.0      0.0   \n",
       "6999991           Male             Gender  ...      0.0      0.0   \n",
       "6999992           Male             Gender  ...      1.0      0.0   \n",
       "6999995            Fit            Fitness  ...      0.0      0.0   \n",
       "6999997           More        Utilitarian  ...      0.0      0.0   \n",
       "\n",
       "        MaleExecutive  FemaleExecutive  FemaleAthlete  MaleAthlete  \\\n",
       "6999990           0.0              0.0            0.0          0.0   \n",
       "6999991           0.0              0.0            0.0          0.0   \n",
       "6999992           0.0              0.0            0.0          0.0   \n",
       "6999995           0.0              0.0            3.0          2.0   \n",
       "6999997           0.0              0.0            1.0          0.0   \n",
       "\n",
       "         FemaleDoctor MaleDoctor  Dog  Cat  \n",
       "6999990           0.0        0.0  1.0  0.0  \n",
       "6999991           0.0        1.0  0.0  0.0  \n",
       "6999992           0.0        0.0  0.0  0.0  \n",
       "6999995           0.0        0.0  0.0  0.0  \n",
       "6999997           0.0        1.0  1.0  1.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme_98.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index\n",
    "\n",
    "df_mme_98.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ResponseID', 'ExtendedSessionID', 'UserID', 'ScenarioOrder',\n",
       "       'Intervention', 'PedPed', 'Barrier', 'CrossingSignal', 'AttributeLevel',\n",
       "       'ScenarioTypeStrict', 'ScenarioType', 'DefaultChoice',\n",
       "       'NonDefaultChoice', 'DefaultChoiceIsOmission', 'NumberOfCharacters',\n",
       "       'DiffNumberOFCharacters', 'Saved', 'Template', 'DescriptionShown',\n",
       "       'LeftHand', 'UserCountry3', 'Man', 'Woman', 'Pregnant', 'Stroller',\n",
       "       'OldMan', 'OldWoman', 'Boy', 'Girl', 'Homeless', 'LargeWoman',\n",
       "       'LargeMan', 'Criminal', 'MaleExecutive', 'FemaleExecutive',\n",
       "       'FemaleAthlete', 'MaleAthlete', 'FemaleDoctor', 'MaleDoctor', 'Dog',\n",
       "       'Cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme_98.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserCountry3\n",
      "USA    1244280\n",
      "DEU     321040\n",
      "BRA     279090\n",
      "FRA     275218\n",
      "GBR     258982\n",
      "        ...   \n",
      "NFK          2\n",
      "LSO          2\n",
      "MHL          2\n",
      "GNQ          2\n",
      "CAF          2\n",
      "Name: count, Length: 226, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# some EDA on the country column to assess the distribution of the user ethnicity/culture\n",
    "# Can't do this later as then the column will be removed because of identifyable information - the LLM dataset does not have country information\n",
    "\n",
    "# checking which countries are in the dataset, and what their frequency is\n",
    "# need this for the comparison with the non_western_dataset\n",
    "\n",
    "print(df_mme_98['UserCountry3'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of countries considered 'Western' from the UN\n",
    "\n",
    "countries = [\"AND\",  \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHE\", \"DNK\", \"DEU\", \"ESP\", \"FIN\",  \"FRA\",  \"GBR\",  \"GRC\",  \"IRL\", \n",
    "            \"ISR\", \"ISL\", \"ITA\", \"LIE\", \"LUX\", \"MLT\", \"MCO\", \"NLD\", \"NOR\", \"NZL\", \"PRT\", \"SMR\", \"SWE\", \"TUR\", \"USA\" ]\n",
    "\n",
    "# Andorra, Australia, Austria, Belgium, Canada, Switzerland, Denmark, Germany, Spain, Finland, France, United Kingdom, Greece, Ireland, \n",
    "# Israel, Iceland, Italy, Liechtenstein, Luxembourg, Malta, Monaco, Netherlands, Norway, New Zealand, Portugal, San Marino, Sweden, Turkey, USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows Western: 3377172\n",
      "Rounded % Western: 69\n",
      "Unrounded % Western: 68.9218775510204\n"
     ]
    }
   ],
   "source": [
    "# what number of rows that is from western countries?\n",
    "\n",
    "total_western = df_mme_98['UserCountry3'].isin(countries).sum()\n",
    "print(f\"Number of rows Western: {total_western}\")\n",
    "\n",
    "# this is % of the dataset that is from Western countries\n",
    "print(f\"Rounded % Western: {round(total_western /len(df_mme_98)*100)}\")     # rounded percentage\n",
    "print(f\"Unrounded % Western: {total_western /len(df_mme_98)*100}\")          # exact percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA of countries is now over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already deleting some columns to ensure it fits in memory\n",
    "# deleting the columns that are not necessary for the modelling: ExtendedSessionID, DefaultChoice, NonDefaultChoice, DefaultChoiceIsOmission, Template\n",
    "\n",
    "df_mme_clean = df_mme_98.drop(columns=['ExtendedSessionID', 'DefaultChoice', 'NonDefaultChoice', 'DefaultChoiceIsOmission', 'Template', 'ScenarioType', 'ScenarioOrder', 'DescriptionShown', 'LeftHand', 'UserCountry3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4900000, 31)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mme_clean.shape # should be 4900000 rows and 31 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarizing UserID - making all into 0\n",
    "df_mme_clean['UserID'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving this pre-preprocessed mme dataset to a csv file\n",
    "\n",
    "df_mme_clean.to_csv('mme_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
