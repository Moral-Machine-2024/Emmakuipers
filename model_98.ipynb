{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n",
      "1.26.4\n",
      "3.7.2\n",
      "0.12.2\n"
     ]
    }
   ],
   "source": [
    "print(pd. __version__)\n",
    "print(np. __version__)\n",
    "print(mpl. __version__)\n",
    "print(sns. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'ResponseID': 'category',\n",
    "    'UserID': 'int8',\n",
    "    'Intervention': 'int8',\n",
    "    'PedPed': 'int8',\n",
    "    'Barrier': 'int8',\n",
    "    'CrossingSignal': 'int8',\n",
    "    'AttributeLevel': 'category',\n",
    "    'ScenarioTypeStrict': 'category',\n",
    "    'NumberOfCharacters': 'int8',\n",
    "    'DiffNumberOFCharacters': 'int8',\n",
    "    'Saved': 'int8',\n",
    "    'Man': 'int8',\n",
    "    'Woman': 'int8',\n",
    "    'Pregnant': 'int8',\n",
    "    'Stroller': 'int8',\n",
    "    'OldMan': 'int8',\n",
    "    'OldWoman': 'int8',\n",
    "    'Boy': 'int8',\n",
    "    'Girl': 'int8',\n",
    "    'Homeless': 'int8',\n",
    "    'LargeWoman': 'int8',\n",
    "    'LargeMan': 'int8',\n",
    "    'Criminal': 'int8',\n",
    "    'MaleExecutive': 'int8',\n",
    "    'FemaleExecutive': 'int8',\n",
    "    'FemaleAthlete': 'int8',\n",
    "    'MaleAthlete': 'int8',\n",
    "    'FemaleDoctor': 'int8',\n",
    "    'MaleDoctor': 'int8',\n",
    "    'Dog': 'int8',\n",
    "    'Cat': 'int8'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df98 = pd.read_csv('total_98_dataset.csv', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df98.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ResponseID', 'UserID', 'Intervention', 'PedPed', 'Barrier',\n",
      "       'CrossingSignal', 'NumberOfCharacters', 'DiffNumberOFCharacters',\n",
      "       'Saved', 'Man', 'Woman', 'Pregnant', 'Stroller', 'OldMan', 'OldWoman',\n",
      "       'Boy', 'Girl', 'Homeless', 'LargeWoman', 'LargeMan', 'Criminal',\n",
      "       'MaleExecutive', 'FemaleExecutive', 'FemaleAthlete', 'MaleAthlete',\n",
      "       'FemaleDoctor', 'MaleDoctor', 'Dog', 'Cat', 'AttributeLevel_Fat',\n",
      "       'AttributeLevel_Female', 'AttributeLevel_Fit', 'AttributeLevel_High',\n",
      "       'AttributeLevel_Hoomans', 'AttributeLevel_Less', 'AttributeLevel_Low',\n",
      "       'AttributeLevel_Male', 'AttributeLevel_More', 'AttributeLevel_Old',\n",
      "       'AttributeLevel_Pets', 'AttributeLevel_Young', 'ScenarioTypeStrict_Age',\n",
      "       'ScenarioTypeStrict_Fitness', 'ScenarioTypeStrict_Gender',\n",
      "       'ScenarioTypeStrict_Social Status', 'ScenarioTypeStrict_Species',\n",
      "       'ScenarioTypeStrict_Utilitarian'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# one-hot encode the AttributeLevel and ScenarioTypeStrict\n",
    "df98 = pd.get_dummies(df98, columns=['AttributeLevel', 'ScenarioTypeStrict'])\n",
    "\n",
    "print(df98.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 47)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df98.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df98.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now also dropping ResponseID\n",
    "# kept this on and pre-processed it thus far to keep track of if everything went right with the complete sessions being in the dataset (so each ResponseID has to be present twice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variable\n",
    "X = df98.drop(['UserID', 'ResponseID'], axis=1)     # Features\n",
    "y = df98['UserID']                                  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation and test sets\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2125000, 45)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting K for K-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing fold 1\n",
      "Done processing fold 2\n",
      "Done processing fold 3\n"
     ]
    }
   ],
   "source": [
    "# Initialize logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_lr = []\n",
    "classification_reports_lr = []\n",
    "count = 0\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    # Split data into train and test for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_lr = lr_model.predict(X_val)\n",
    "    \n",
    "    # Generate confusion matrix and classification report\n",
    "    conf_matrices_lr.append(confusion_matrix(y_val, y_pred_lr))\n",
    "    classification_reports_lr.append(classification_report(y_val, y_pred_lr, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[694231      0]\n",
      " [ 14060     43]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.9801494018701353, 'recall': 1.0, 'f1-score': 0.9899752018150161, 'support': 694231.0}\n",
      "1: {'precision': 1.0, 'recall': 0.003048996667375736, 'f1-score': 0.00607945709034356, 'support': 14103.0}\n",
      "accuracy: 0.9801506069170759\n",
      "macro avg: {'precision': 0.9900747009350677, 'recall': 0.5015244983336878, 'f1-score': 0.4980273294526798, 'support': 708334.0}\n",
      "weighted avg: {'precision': 0.9805446292422868, 'recall': 0.9801506069170759, 'f1-score': 0.9703857402222476, 'support': 708334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[694182      0]\n",
      " [ 14119     32]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.9800663842067143, 'recall': 1.0, 'f1-score': 0.989932854801092, 'support': 694182.0}\n",
      "1: {'precision': 1.0, 'recall': 0.002261324288036181, 'f1-score': 0.004512444475780864, 'support': 14151.0}\n",
      "accuracy: 0.9800672847375458\n",
      "macro avg: {'precision': 0.9900331921033572, 'recall': 0.5011306621440181, 'f1-score': 0.4972226496384365, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.9804646158253044, 'recall': 0.9800672847375458, 'f1-score': 0.9702462325111331, 'support': 708333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[694038      0]\n",
      " [ 14260     35]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.9798672310242299, 'recall': 1.0, 'f1-score': 0.9898312529950026, 'support': 694038.0}\n",
      "1: {'precision': 1.0, 'recall': 0.002448408534452606, 'f1-score': 0.004884856943475227, 'support': 14295.0}\n",
      "accuracy: 0.9798682258203416\n",
      "macro avg: {'precision': 0.989933615512115, 'recall': 0.5012242042672262, 'f1-score': 0.4973580549692389, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.980273534178973, 'recall': 0.9798682258203416, 'f1-score': 0.9699538666081527, 'support': 708333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_lr[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_lr[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy LR: 0.9800287058249878\n",
      "Standard Deviation: 0.00011846524193150243\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_lr = [report['accuracy'] for report in classification_reports_lr]\n",
    "average_accuracy_lr = np.mean(accuracies_lr)\n",
    "print(f\"\\nAverage Accuracy LR: {average_accuracy_lr}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_lr = np.std(accuracies_lr)\n",
    "print(f\"Standard Deviation: {std_dev_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1: 0.0025862431632881744\n"
     ]
    }
   ],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_lr = [report['1']['recall'] for report in classification_reports_lr]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_lr = np.mean(recall_class_1_lr)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing fold1\n",
      "Done processing fold2\n",
      "Done processing fold3\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_rf = []\n",
    "classification_reports_rf = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "    # Split the data for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_rf = rf_model.predict(X_val)\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_rf.append(confusion_matrix(y_val, y_pred_rf))\n",
    "    classification_reports_rf.append(classification_report(y_val, y_pred_rf, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold\" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[693701    530]\n",
      " [ 10941   3162]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.9844729664141507, 'recall': 0.9992365653507262, 'f1-score': 0.9917998274325117, 'support': 694231.0}\n",
      "1: {'precision': 0.8564463705308776, 'recall': 0.22420761540097853, 'f1-score': 0.3553807249227311, 'support': 14103.0}\n",
      "accuracy: 0.9838056623005531\n",
      "macro avg: {'precision': 0.9204596684725141, 'recall': 0.6117220903758523, 'f1-score': 0.6735902761776213, 'support': 708334.0}\n",
      "weighted avg: {'precision': 0.9819239442272419, 'recall': 0.9838056623005531, 'f1-score': 0.979128660154511, 'support': 708334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[693662    520]\n",
      " [ 10919   3232]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.9845028463725249, 'recall': 0.9992509169065174, 'f1-score': 0.9918220599200865, 'support': 694182.0}\n",
      "1: {'precision': 0.8614072494669509, 'recall': 0.2283937530916543, 'f1-score': 0.361056806121879, 'support': 14151.0}\n",
      "accuracy: 0.9838508159297957\n",
      "macro avg: {'precision': 0.9229550479197379, 'recall': 0.6138223349990858, 'f1-score': 0.6764394330209827, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.9820436558621143, 'recall': 0.9838508159297957, 'f1-score': 0.9792206999573311, 'support': 708333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[693485    553]\n",
      " [ 11118   3177]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.9842209016992548, 'recall': 0.9992032136568891, 'f1-score': 0.9916554712753308, 'support': 694038.0}\n",
      "1: {'precision': 0.8517426273458445, 'recall': 0.2222455403987408, 'f1-score': 0.3525104022191401, 'support': 14295.0}\n",
      "accuracy: 0.9835232863638995\n",
      "macro avg: {'precision': 0.9179817645225496, 'recall': 0.610724377027815, 'f1-score': 0.6720829367472354, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.9815473330078598, 'recall': 0.9835232863638995, 'f1-score': 0.9787567657764226, 'support': 708333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results for each fold\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_rf[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_rf[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy RF: 0.9837265881980829\n",
      "Standard Deviation: 0.00014493317861496383\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_rf = [report['accuracy'] for report in classification_reports_rf]\n",
    "average_accuracy_rf = np.mean(accuracies_rf)\n",
    "print(f\"\\nAverage Accuracy RF: {average_accuracy_rf}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_rf = np.std(accuracies_rf)\n",
    "print(f\"Standard Deviation: {std_dev_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1: 0.22494896963045788\n"
     ]
    }
   ],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_rf = [report['1']['recall'] for report in classification_reports_rf]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_rf = np.mean(recall_class_1_rf)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=45)\n",
    "\n",
    "# choosing rbf cause not linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n",
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n",
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n"
     ]
    }
   ],
   "source": [
    "# Lists to store results\n",
    "conf_matrices_svm = []\n",
    "classification_reports_svm = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    print(\"Starting fold \" + str(count))\n",
    "    # Split the data for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    svc.fit(X_train, y_train)\n",
    "    print(\"Model fitted\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_svm = svc.predict(X_val)\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_svm.append(confusion_matrix(y_val, y_pred_svm))\n",
    "    classification_reports_svm.append(classification_report(y_val, y_pred_svm, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[33869  7839]\n",
      " [19892 21734]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6299920016368743, 'recall': 0.81205044595761, 'f1-score': 0.7095287475515613, 'support': 41708.0}\n",
      "1: {'precision': 0.7349271294762114, 'recall': 0.5221255945803104, 'f1-score': 0.6105141926150648, 'support': 41626.0}\n",
      "accuracy: 0.6672306621547027\n",
      "macro avg: {'precision': 0.6824595655565429, 'recall': 0.6670880202689602, 'f1-score': 0.660021470083313, 'support': 83334.0}\n",
      "weighted avg: {'precision': 0.6824079378866673, 'recall': 0.6672306621547027, 'f1-score': 0.6600701848546235, 'support': 83334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[33671  8098]\n",
      " [19928 21636]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6282020186943786, 'recall': 0.8061241590653355, 'f1-score': 0.7061278416240249, 'support': 41769.0}\n",
      "1: {'precision': 0.7276518463711577, 'recall': 0.5205466268886536, 'f1-score': 0.6069174450896239, 'support': 41564.0}\n",
      "accuracy: 0.663686654746619\n",
      "macro avg: {'precision': 0.6779269325327681, 'recall': 0.6633353929769945, 'f1-score': 0.6565226433568243, 'support': 83333.0}\n",
      "weighted avg: {'precision': 0.6778046087554306, 'recall': 0.663686654746619, 'f1-score': 0.6566446726326788, 'support': 83333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[33681  8025]\n",
      " [19790 21837]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6298928391090498, 'recall': 0.807581642929075, 'f1-score': 0.7077550248484403, 'support': 41706.0}\n",
      "1: {'precision': 0.7312638135422945, 'recall': 0.5245874072116655, 'f1-score': 0.6109191623886192, 'support': 41627.0}\n",
      "accuracy: 0.6662186648746595\n",
      "macro avg: {'precision': 0.6805783263256722, 'recall': 0.6660845250703702, 'f1-score': 0.6593370936185298, 'support': 83333.0}\n",
      "weighted avg: {'precision': 0.6805302762915907, 'recall': 0.6662186648746595, 'f1-score': 0.6593829940009373, 'support': 83333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results for each fold\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_svm[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_svm[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy RF: 0.6657119939253271\n",
      "Standard Deviation: 0.0014905331742503187\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_svm = [report['accuracy'] for report in classification_reports_svm]\n",
    "average_accuracy_svm = np.mean(accuracies_svm)\n",
    "print(f\"\\nAverage Accuracy SVM: {average_accuracy_svm}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_svm = np.std(accuracies_svm)\n",
    "print(f\"Standard Deviation: {std_dev_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_svm = [report['1']['recall'] for report in classification_reports_svm]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_svm = np.mean(recall_class_1_svm)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, optimizers, models, callbacks\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "initial_learning_rate = 5e-4\n",
    "decay_rate = 0.1  # Decay rate per step (you can adjust this)\n",
    "\n",
    "# Define the learning rate schedule\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=decay_rate)\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='accuracy',                 # Watch validation loss\n",
    "    patience=3,                         # Stop after 3 epochs with no improvement\n",
    "    restore_best_weights=True,          # Restore weights from the best epoch\n",
    "    min_delta=0.0005                     # Minimum change in accuracy to qualify as an improvement\n",
    ")\n",
    "\n",
    "# Function to build the model\n",
    "def build_model():\n",
    "    model_mlp = models.Sequential()\n",
    "    model_mlp.add(layers.Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model_mlp.add(layers.BatchNormalization())\n",
    "    model_mlp.add(layers.Dense(64, activation='relu'))\n",
    "    model_mlp.add(layers.BatchNormalization())\n",
    "    model_mlp.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model_mlp.compile(optimizer=optimizers.Adam(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=[keras.metrics.Recall()])\n",
    "    return model_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1ms/step - accuracy: 0.9751 - loss: 0.1066\n",
      "Epoch 2/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1ms/step - accuracy: 0.9824 - loss: 0.0849\n",
      "Epoch 3/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1ms/step - accuracy: 0.9820 - loss: 0.0864\n",
      "Epoch 4/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1ms/step - accuracy: 0.9821 - loss: 0.0860\n",
      "Epoch 5/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.0856\n",
      "\u001b[1m22136/22136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 796us/step\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1ms/step - accuracy: 0.9751 - loss: 0.1067\n",
      "Epoch 2/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.0856\n",
      "Epoch 3/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.0856\n",
      "\u001b[1m22136/22136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 839us/step\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1ms/step - accuracy: 0.9747 - loss: 0.1069\n",
      "Epoch 2/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1ms/step - accuracy: 0.9824 - loss: 0.0848\n",
      "Epoch 3/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1ms/step - accuracy: 0.9824 - loss: 0.0850\n",
      "\u001b[1m22136/22136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 815us/step\n"
     ]
    }
   ],
   "source": [
    "# Convert data to float32 (required by TensorFlow)\n",
    "X_trainval = np.array(X_trainval, dtype=np.float32)\n",
    "y_trainval = np.array(y_trainval, dtype=np.float32)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_mlp = []\n",
    "classification_reports_mlp = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop over each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "    print(f\"\\nFold {count}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    X_train, X_val = X_trainval[train_index], X_trainval[test_index]\n",
    "    y_train, y_val = y_trainval[train_index], y_trainval[test_index]\n",
    "    \n",
    "    # Build and train the model\n",
    "    model_mlp = build_model()\n",
    "    model_mlp.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_mlp = model_mlp.predict(X_val)\n",
    "    y_pred_mlp = (y_pred_mlp > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_mlp.append(confusion_matrix(y_val, y_pred_mlp))\n",
    "    classification_reports_mlp.append(classification_report(y_val, y_pred_mlp, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy: 0.9823148234569888\n",
      "Standard Deviation: 0.00015727053978937898\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_mlp = [report['accuracy'] for report in classification_reports_mlp]\n",
    "average_accuracy_mlp = np.mean(accuracies_mlp)\n",
    "print(f\"\\nAverage Accuracy: {average_accuracy_mlp}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_mlp= np.std(accuracies_mlp)\n",
    "print(f\"Standard Deviation: {std_dev_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1.0: 0.11888943077654968\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Collect the recall for the '1.0' class from each fold\n",
    "recall_class_1_mlp = [report_mlp['1.0']['recall'] for report_mlp in classification_reports_mlp]\n",
    "\n",
    "# Calculate the average recall for the '1.0' class across all folds\n",
    "average_recall_class_1_mlp = np.mean(recall_class_1_mlp)\n",
    "print(f\"\\nAverage Recall for class 1.0: {average_recall_class_1_mlp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of model names\n",
    "model_names = ['Logistic Regression', 'Random Forest', 'MLP']\n",
    "\n",
    "# Collect the accuracy and recall values by calling the variables\n",
    "accuracies = [average_accuracy_lr, average_accuracy_rf, average_accuracy_mlp]\n",
    "recalls = [average_recall_class_1_lr, average_recall_class_1_rf, average_recall_class_1_mlp]\n",
    "\n",
    "# Create a dictionary for the DataFrame\n",
    "data = {\n",
    "    'Model': model_names,\n",
    "    'Accuracy': accuracies,\n",
    "    'Recall': recalls\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df_results = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.980029</td>\n",
       "      <td>0.002586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.983727</td>\n",
       "      <td>0.224949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.982315</td>\n",
       "      <td>0.118889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy    Recall\n",
       "0  Logistic Regression  0.980029  0.002586\n",
       "1        Random Forest  0.983727  0.224949\n",
       "2                  MLP  0.982315  0.118889"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search on best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the df of above, it can be seen that the best model is the Random Forest model. I therefore will perform random search on this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further splitting trainval into train and validation set to tune hyperparameters on the validation set\n",
    "# Training set: 70%, Validation set: 15%, Test set: 15% (still the same test set)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=(15/85), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750000, 45)\n",
      "The percentage of the original dataset that is used for training is: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(f\"The percentage of the original dataset that is used for training is: {X_train.shape[0]/df98.shape[0]*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint  # For defining distributions for random search\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),  # Number of trees in the forest (uniform distribution between 50 and 200)\n",
    "    'max_depth': [None] + list(randint(1, 30).rvs(10)),  # Random depth values including None\n",
    "    'min_samples_split': randint(2, 10),  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 4)  # Minimum samples required to be at a leaf node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_model_search = RandomForestClassifier(random_state=42)  # Random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 160}\n",
      "Best Cross-Validation Score: 0.20553744064984844\n"
     ]
    }
   ],
   "source": [
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf_model_search,\n",
    "                           param_distributions=param_dist,\n",
    "                           n_iter=20,          # Number of parameter settings that are sampled\n",
    "                           scoring='recall',   # Use recall as the evaluation metric\n",
    "                           cv=k,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)          # Use all available cores\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Set: 0.98396\n",
      "[[367390     23]\n",
      " [  5992   1595]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    367413\n",
      "           1       0.99      0.21      0.35      7587\n",
      "\n",
      "    accuracy                           0.98    375000\n",
      "   macro avg       0.98      0.61      0.67    375000\n",
      "weighted avg       0.98      0.98      0.98    375000\n",
      "\n",
      "Recall on Validation Set: 0.21022802161592197\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf_random = random_search.predict(X_val)\n",
    "\n",
    "print(\"Accuracy on Validation Set:\", accuracy_score(y_val, y_pred_rf_random))\n",
    "print(confusion_matrix(y_val, y_pred_rf_random))\n",
    "print(classification_report(y_val, y_pred_rf_random))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall on Validation Set:\", recall_score(y_val, y_pred_rf_random))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
