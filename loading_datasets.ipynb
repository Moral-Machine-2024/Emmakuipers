{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the 5 different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading all the LLM datafiles into dataframes\n",
    "\n",
    "df_gpt35 = pd.read_csv('shared_responses_gpt-3.5-turbo-0613.csv')\n",
    "df_gpt40 = pd.read_csv('shared_responses_gpt-4-0613.csv')\n",
    "df_llama = pd.read_csv('shared_responses_llama-2-7b-chat.csv')\n",
    "df_palm2 = pd.read_csv('shared_responses_palm2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94914, 41)\n",
      "(19004, 41)\n",
      "(79672, 41)\n",
      "(99978, 41)\n"
     ]
    }
   ],
   "source": [
    "# Cheking their shapes\n",
    "print(df_gpt35.shape)\n",
    "print(df_gpt40.shape)\n",
    "print(df_llama.shape)\n",
    "print(df_palm2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94909</th>\n",
       "      <td>res_00047454_2</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>Social Value</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94910</th>\n",
       "      <td>res_00047455_1</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94911</th>\n",
       "      <td>res_00047455_2</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94912</th>\n",
       "      <td>res_00047456_1</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Young</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94913</th>\n",
       "      <td>res_00047456_2</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Old</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ResponseID ExtendedSessionID   UserID  ScenarioOrder  Intervention  \\\n",
       "94909  res_00047454_2  chatbot_extended  chatbot              0             1   \n",
       "94910  res_00047455_1  chatbot_extended  chatbot              0             0   \n",
       "94911  res_00047455_2  chatbot_extended  chatbot              0             1   \n",
       "94912  res_00047456_1  chatbot_extended  chatbot              0             0   \n",
       "94913  res_00047456_2  chatbot_extended  chatbot              0             1   \n",
       "\n",
       "       PedPed  Barrier  CrossingSignal AttributeLevel ScenarioTypeStrict  ...  \\\n",
       "94909       1        0               0           High       Social Value  ...   \n",
       "94910       1        0               0        Hoomans            Species  ...   \n",
       "94911       1        0               0           Pets            Species  ...   \n",
       "94912       0        1               0          Young                Age  ...   \n",
       "94913       0        0               1            Old                Age  ...   \n",
       "\n",
       "      LargeMan  Criminal  MaleExecutive  FemaleExecutive  FemaleAthlete  \\\n",
       "94909        0         0              1                0              0   \n",
       "94910        0         1              0                0              0   \n",
       "94911        0         0              0                0              0   \n",
       "94912        0         0              0                0              0   \n",
       "94913        0         0              0                0              0   \n",
       "\n",
       "       MaleAthlete  FemaleDoctor MaleDoctor  Dog  Cat  \n",
       "94909            0             0          0    0    0  \n",
       "94910            0             0          0    0    0  \n",
       "94911            0             0          0    2    3  \n",
       "94912            0             0          0    0    0  \n",
       "94913            0             0          0    0    0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt35.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the '_1' and '_2' from the 'ResponseID' column, so each scenario has two rows with the same response ID (instead of one with _1 and one with _2)\n",
    "df_gpt35['ResponseID'] = df_gpt35['ResponseID'].str.replace(r'_\\d+$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94909</th>\n",
       "      <td>res_00047454</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>Social Value</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94910</th>\n",
       "      <td>res_00047455</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94911</th>\n",
       "      <td>res_00047455</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94912</th>\n",
       "      <td>res_00047456</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Young</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94913</th>\n",
       "      <td>res_00047456</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Old</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ResponseID ExtendedSessionID   UserID  ScenarioOrder  Intervention  \\\n",
       "94909  res_00047454  chatbot_extended  chatbot              0             1   \n",
       "94910  res_00047455  chatbot_extended  chatbot              0             0   \n",
       "94911  res_00047455  chatbot_extended  chatbot              0             1   \n",
       "94912  res_00047456  chatbot_extended  chatbot              0             0   \n",
       "94913  res_00047456  chatbot_extended  chatbot              0             1   \n",
       "\n",
       "       PedPed  Barrier  CrossingSignal AttributeLevel ScenarioTypeStrict  ...  \\\n",
       "94909       1        0               0           High       Social Value  ...   \n",
       "94910       1        0               0        Hoomans            Species  ...   \n",
       "94911       1        0               0           Pets            Species  ...   \n",
       "94912       0        1               0          Young                Age  ...   \n",
       "94913       0        0               1            Old                Age  ...   \n",
       "\n",
       "      LargeMan  Criminal  MaleExecutive  FemaleExecutive  FemaleAthlete  \\\n",
       "94909        0         0              1                0              0   \n",
       "94910        0         1              0                0              0   \n",
       "94911        0         0              0                0              0   \n",
       "94912        0         0              0                0              0   \n",
       "94913        0         0              0                0              0   \n",
       "\n",
       "       MaleAthlete  FemaleDoctor MaleDoctor  Dog  Cat  \n",
       "94909            0             0          0    0    0  \n",
       "94910            0             0          0    0    0  \n",
       "94911            0             0          0    2    3  \n",
       "94912            0             0          0    0    0  \n",
       "94913            0             0          0    0    0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt35.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the starting point for the new ResponseID\n",
    "starting_id = 47457\n",
    "\n",
    "# Get the total number of rows\n",
    "num_rows = len(df_gpt40)\n",
    "\n",
    "# Create a new column where every two rows have the same ResponseID\n",
    "df_gpt40['ResponseID'] = [f'res_{starting_id + i // 2:08d}' for i in range(num_rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>res_00047457</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>res_00047457</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>res_00047458</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res_00047458</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>res_00047459</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Young</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18999</th>\n",
       "      <td>res_00056956</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fat</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19000</th>\n",
       "      <td>res_00056957</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19001</th>\n",
       "      <td>res_00056957</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19002</th>\n",
       "      <td>res_00056958</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fat</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19003</th>\n",
       "      <td>res_00056958</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fit</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19004 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ResponseID ExtendedSessionID   UserID  ScenarioOrder  Intervention  \\\n",
       "0      res_00047457  chatbot_extended  chatbot              0             0   \n",
       "1      res_00047457  chatbot_extended  chatbot              0             1   \n",
       "2      res_00047458  chatbot_extended  chatbot              0             0   \n",
       "3      res_00047458  chatbot_extended  chatbot              0             1   \n",
       "4      res_00047459  chatbot_extended  chatbot              0             1   \n",
       "...             ...               ...      ...            ...           ...   \n",
       "18999  res_00056956  chatbot_extended  chatbot              0             0   \n",
       "19000  res_00056957  chatbot_extended  chatbot              0             1   \n",
       "19001  res_00056957  chatbot_extended  chatbot              0             0   \n",
       "19002  res_00056958  chatbot_extended  chatbot              0             0   \n",
       "19003  res_00056958  chatbot_extended  chatbot              0             1   \n",
       "\n",
       "       PedPed  Barrier  CrossingSignal AttributeLevel ScenarioTypeStrict  ...  \\\n",
       "0           0        1               0        Hoomans            Species  ...   \n",
       "1           0        0               0           Pets            Species  ...   \n",
       "2           0        1               0           Male             Gender  ...   \n",
       "3           0        0               2         Female             Gender  ...   \n",
       "4           1        0               2          Young                Age  ...   \n",
       "...       ...      ...             ...            ...                ...  ...   \n",
       "18999       0        0               0            Fat            Fitness  ...   \n",
       "19000       1        0               2        Hoomans            Species  ...   \n",
       "19001       1        0               1           Pets            Species  ...   \n",
       "19002       1        0               0            Fat            Fitness  ...   \n",
       "19003       1        0               0            Fit            Fitness  ...   \n",
       "\n",
       "      LargeMan  Criminal  MaleExecutive  FemaleExecutive  FemaleAthlete  \\\n",
       "0            0         0              0                0              0   \n",
       "1            0         0              0                0              0   \n",
       "2            0         0              0                0              0   \n",
       "3            0         0              0                0              0   \n",
       "4            0         0              0                0              0   \n",
       "...        ...       ...            ...              ...            ...   \n",
       "18999        0         0              0                0              0   \n",
       "19000        1         0              0                1              0   \n",
       "19001        0         0              0                0              0   \n",
       "19002        1         0              0                0              0   \n",
       "19003        0         0              0                0              2   \n",
       "\n",
       "       MaleAthlete  FemaleDoctor MaleDoctor  Dog  Cat  \n",
       "0                0             1          0    0    0  \n",
       "1                0             0          0    1    2  \n",
       "2                0             0          0    0    0  \n",
       "3                0             0          0    0    0  \n",
       "4                0             0          0    0    0  \n",
       "...            ...           ...        ...  ...  ...  \n",
       "18999            0             0          0    0    0  \n",
       "19000            0             0          0    0    0  \n",
       "19001            0             0          0    3    2  \n",
       "19002            0             0          0    0    0  \n",
       "19003            0             0          0    0    0  \n",
       "\n",
       "[19004 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the starting point for the new ResponseID\n",
    "starting_id = 56959\n",
    "\n",
    "# Get the total number of rows\n",
    "num_rows = len(df_llama)\n",
    "\n",
    "# Create a new column where every two rows have the same ResponseID\n",
    "df_llama['ResponseID'] = [f'res_{starting_id + i // 2:08d}' for i in range(num_rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>res_00056959</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>res_00056959</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>res_00056960</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res_00056960</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>res_00056961</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Young</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79667</th>\n",
       "      <td>res_00096792</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79668</th>\n",
       "      <td>res_00096793</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Less</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79669</th>\n",
       "      <td>res_00096793</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79670</th>\n",
       "      <td>res_00096794</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Young</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79671</th>\n",
       "      <td>res_00096794</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Old</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79672 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ResponseID ExtendedSessionID   UserID  ScenarioOrder  Intervention  \\\n",
       "0      res_00056959  chatbot_extended  chatbot              0             0   \n",
       "1      res_00056959  chatbot_extended  chatbot              0             1   \n",
       "2      res_00056960  chatbot_extended  chatbot              0             0   \n",
       "3      res_00056960  chatbot_extended  chatbot              0             1   \n",
       "4      res_00056961  chatbot_extended  chatbot              0             1   \n",
       "...             ...               ...      ...            ...           ...   \n",
       "79667  res_00096792  chatbot_extended  chatbot              0             1   \n",
       "79668  res_00096793  chatbot_extended  chatbot              0             1   \n",
       "79669  res_00096793  chatbot_extended  chatbot              0             0   \n",
       "79670  res_00096794  chatbot_extended  chatbot              0             0   \n",
       "79671  res_00096794  chatbot_extended  chatbot              0             1   \n",
       "\n",
       "       PedPed  Barrier  CrossingSignal AttributeLevel ScenarioTypeStrict  ...  \\\n",
       "0           0        1               0        Hoomans            Species  ...   \n",
       "1           0        0               0           Pets            Species  ...   \n",
       "2           0        1               0           Male             Gender  ...   \n",
       "3           0        0               2         Female             Gender  ...   \n",
       "4           1        0               2          Young                Age  ...   \n",
       "...       ...      ...             ...            ...                ...  ...   \n",
       "79667       0        0               0         Female             Gender  ...   \n",
       "79668       0        1               0           Less        Utilitarian  ...   \n",
       "79669       0        0               0           More        Utilitarian  ...   \n",
       "79670       0        1               0          Young                Age  ...   \n",
       "79671       0        0               1            Old                Age  ...   \n",
       "\n",
       "      LargeMan  Criminal  MaleExecutive  FemaleExecutive  FemaleAthlete  \\\n",
       "0            0         0              0                0              0   \n",
       "1            0         0              0                0              0   \n",
       "2            0         0              0                0              0   \n",
       "3            0         0              0                0              0   \n",
       "4            0         0              0                0              0   \n",
       "...        ...       ...            ...              ...            ...   \n",
       "79667        0         0              0                0              0   \n",
       "79668        0         0              0                0              0   \n",
       "79669        0         0              0                0              0   \n",
       "79670        0         0              0                0              0   \n",
       "79671        0         0              0                0              0   \n",
       "\n",
       "       MaleAthlete  FemaleDoctor MaleDoctor  Dog  Cat  \n",
       "0                0             1          0    0    0  \n",
       "1                0             0          0    1    2  \n",
       "2                0             0          0    0    0  \n",
       "3                0             0          0    0    0  \n",
       "4                0             0          0    0    0  \n",
       "...            ...           ...        ...  ...  ...  \n",
       "79667            0             0          0    0    0  \n",
       "79668            0             0          0    0    0  \n",
       "79669            0             0          0    0    1  \n",
       "79670            0             0          0    0    0  \n",
       "79671            0             0          0    0    0  \n",
       "\n",
       "[79672 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the starting point for the new ResponseID\n",
    "starting_id = 96795\n",
    "\n",
    "# Get the total number of rows\n",
    "num_rows = len(df_palm2)\n",
    "\n",
    "# Create a new column where every two rows have the same ResponseID\n",
    "df_palm2['ResponseID'] = [f'res_{starting_id + i // 2:08d}' for i in range(num_rows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>res_00096795</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>res_00096795</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>res_00096796</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res_00096796</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>res_00096797</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Young</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <td>res_00146781</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>Social Value</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>res_00146782</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>res_00146782</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99976</th>\n",
       "      <td>res_00146783</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Young</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99977</th>\n",
       "      <td>res_00146783</td>\n",
       "      <td>chatbot_extended</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Old</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99978 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ResponseID ExtendedSessionID   UserID  ScenarioOrder  Intervention  \\\n",
       "0      res_00096795  chatbot_extended  chatbot              0             0   \n",
       "1      res_00096795  chatbot_extended  chatbot              0             1   \n",
       "2      res_00096796  chatbot_extended  chatbot              0             0   \n",
       "3      res_00096796  chatbot_extended  chatbot              0             1   \n",
       "4      res_00096797  chatbot_extended  chatbot              0             1   \n",
       "...             ...               ...      ...            ...           ...   \n",
       "99973  res_00146781  chatbot_extended  chatbot              0             1   \n",
       "99974  res_00146782  chatbot_extended  chatbot              0             0   \n",
       "99975  res_00146782  chatbot_extended  chatbot              0             1   \n",
       "99976  res_00146783  chatbot_extended  chatbot              0             0   \n",
       "99977  res_00146783  chatbot_extended  chatbot              0             1   \n",
       "\n",
       "       PedPed  Barrier  CrossingSignal AttributeLevel ScenarioTypeStrict  ...  \\\n",
       "0           0        1               0        Hoomans            Species  ...   \n",
       "1           0        0               0           Pets            Species  ...   \n",
       "2           0        1               0           Male             Gender  ...   \n",
       "3           0        0               2         Female             Gender  ...   \n",
       "4           1        0               2          Young                Age  ...   \n",
       "...       ...      ...             ...            ...                ...  ...   \n",
       "99973       1        0               0           High       Social Value  ...   \n",
       "99974       1        0               0        Hoomans            Species  ...   \n",
       "99975       1        0               0           Pets            Species  ...   \n",
       "99976       0        1               0          Young                Age  ...   \n",
       "99977       0        0               1            Old                Age  ...   \n",
       "\n",
       "      LargeMan  Criminal  MaleExecutive  FemaleExecutive  FemaleAthlete  \\\n",
       "0            0         0              0                0              0   \n",
       "1            0         0              0                0              0   \n",
       "2            0         0              0                0              0   \n",
       "3            0         0              0                0              0   \n",
       "4            0         0              0                0              0   \n",
       "...        ...       ...            ...              ...            ...   \n",
       "99973        0         0              1                1              0   \n",
       "99974        0         1              0                0              0   \n",
       "99975        0         0              0                0              0   \n",
       "99976        0         0              0                0              0   \n",
       "99977        0         0              0                0              0   \n",
       "\n",
       "       MaleAthlete  FemaleDoctor MaleDoctor  Dog  Cat  \n",
       "0                0             1          0    0    0  \n",
       "1                0             0          0    1    2  \n",
       "2                0             0          0    0    0  \n",
       "3                0             0          0    0    0  \n",
       "4                0             0          0    0    0  \n",
       "...            ...           ...        ...  ...  ...  \n",
       "99973            0             1          0    0    0  \n",
       "99974            0             0          0    0    0  \n",
       "99975            0             0          0    2    3  \n",
       "99976            0             0          0    0    0  \n",
       "99977            0             0          0    0    0  \n",
       "\n",
       "[99978 rows x 41 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_palm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the dataframes into one dataframe with all the LLM responses\n",
    "# this dataframe now has for ResponseID values starting from res_00000000 to res_00146783, where every ResponseID has two rows\n",
    "\n",
    "df_llm = pd.concat([df_gpt35, df_gpt40, df_llama, df_palm2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID\n",
       "chatbot    293568\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llm['UserID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(293568, 41)\n"
     ]
    }
   ],
   "source": [
    "# check shape of the dataframe\n",
    "print(df_llm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Species', 'Gender', 'Age', 'Fitness', 'Utilitarian',\n",
       "       'Social Value'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llm['ScenarioType'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Species', 'Gender', 'Age', 'Fitness', 'Utilitarian',\n",
       "       'Social Value'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llm['ScenarioTypeStrict'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hoomans', 'Pets', 'Male', 'Female', 'Young', 'Old', 'Fat', 'Fit',\n",
       "       'Less', 'More', 'High', 'Low'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llm['AttributeLevel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llm_clean = df_llm.drop(columns=['ExtendedSessionID', 'DefaultChoice', 'NonDefaultChoice', 'DefaultChoiceIsOmission', 'Template'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293568, 36)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llm_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llm_clean.to_csv('llm_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on not important anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows written: 17000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set chunk size\n",
    "chunk_size = 100000\n",
    "rows_needed = 17000000  # 17 million rows\n",
    "rows_collected = 0\n",
    "\n",
    "# Initialize write mode for the output file\n",
    "output_file = 'mme_sample.csv'\n",
    "first_chunk = True\n",
    "\n",
    "# Read CSV in chunks and save in batches\n",
    "for chunk in pd.read_csv('SharedResponses.csv', chunksize=chunk_size, dtype=str, low_memory=False):\n",
    "    if rows_collected >= rows_needed:\n",
    "        break\n",
    "    else:\n",
    "        # Calculate remaining rows needed\n",
    "        rows_to_add = min(rows_needed - rows_collected, len(chunk))\n",
    "        chunk = chunk.iloc[:rows_to_add]  # Take only the required number of rows from the chunk\n",
    "        \n",
    "        # Append chunk to the CSV file\n",
    "        chunk.to_csv(output_file, mode='a', index=False, header=first_chunk)\n",
    "        \n",
    "        # After first chunk is written, switch to append mode\n",
    "        first_chunk = False\n",
    "        rows_collected += rows_to_add\n",
    "\n",
    "print(f\"Total rows written: {rows_collected}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esmku\\AppData\\Local\\Temp\\ipykernel_35860\\2941456918.py:1: DtypeWarning: Columns (2,3,4,5,6,7,13,14,15,16,18,19,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mme_sample = pd.read_csv('mme_sample.csv')\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.45 GiB for an array with shape (41, 24372312) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mme_sample \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmme_sample.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1721\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1719\u001b[0m         new_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index)\n\u001b[1;32m-> 1721\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(col_dict, columns\u001b[38;5;241m=\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mindex)\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:153\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    150\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    154\u001b[0m         arrays, axes, consolidate\u001b[38;5;241m=\u001b[39mconsolidate, refs\u001b[38;5;241m=\u001b[39mrefs\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2137\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2120\u001b[0m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2121\u001b[0m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2133\u001b[0m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2134\u001b[0m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2137\u001b[0m         blocks \u001b[38;5;241m=\u001b[39m _form_blocks(arrays, consolidate, refs)\n\u001b[0;32m   2138\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2139\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2215\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[0;32m   2212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mtype, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m   2213\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m-> 2215\u001b[0m values, placement \u001b[38;5;241m=\u001b[39m _stack_arrays(\u001b[38;5;28mlist\u001b[39m(tup_block), dtype)\n\u001b[0;32m   2216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2217\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2255\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2252\u001b[0m first \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2253\u001b[0m shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(arrays),) \u001b[38;5;241m+\u001b[39m first\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m-> 2255\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   2256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m   2257\u001b[0m     stacked[i] \u001b[38;5;241m=\u001b[39m arr\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.45 GiB for an array with shape (41, 24372312) and data type object"
     ]
    }
   ],
   "source": [
    "mme_sample = pd.read_csv('mme_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows written: 7000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set chunk size\n",
    "chunk_size = 10000\n",
    "rows_needed = 7000000  # 7 million rows\n",
    "rows_collected = 0\n",
    "\n",
    "# Initialize write mode for the output file\n",
    "output_file = 'mme_12sample.csv'\n",
    "first_chunk = True\n",
    "\n",
    "# Read CSV in chunks and save in batches\n",
    "for chunk in pd.read_csv('SharedResponses.csv', chunksize=chunk_size, dtype=str, low_memory=False):\n",
    "    if rows_collected >= rows_needed:\n",
    "        break\n",
    "    else:\n",
    "        # Calculate remaining rows needed\n",
    "        rows_to_add = min(rows_needed - rows_collected, len(chunk))\n",
    "        chunk = chunk.iloc[:rows_to_add]  # Take only the required number of rows from the chunk\n",
    "        \n",
    "        # Append chunk to the CSV file\n",
    "        chunk.to_csv(output_file, mode='a', index=False, header=first_chunk)\n",
    "        \n",
    "        # After first chunk is written, switch to append mode\n",
    "        first_chunk = False\n",
    "        rows_collected += rows_to_add\n",
    "\n",
    "print(f\"Total rows written: {rows_collected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esmku\\AppData\\Local\\Temp\\ipykernel_35260\\3188898542.py:1: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mme_sample = pd.read_csv('mme_12sample.csv')\n"
     ]
    }
   ],
   "source": [
    "mme_sample = pd.read_csv('mme_12sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000000, 41)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mme_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esmku\\AppData\\Local\\Temp\\ipykernel_25188\\952449469.py:1: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  survey_data = pd.read_csv('SharedResponsesSurvey.csv')\n"
     ]
    }
   ],
   "source": [
    "survey_data = pd.read_csv('SharedResponsesSurvey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11286141, 27)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>ScenarioOrder</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>...</th>\n",
       "      <th>Template</th>\n",
       "      <th>DescriptionShown</th>\n",
       "      <th>LeftHand</th>\n",
       "      <th>UserCountry3</th>\n",
       "      <th>Review_age</th>\n",
       "      <th>Review_education</th>\n",
       "      <th>Review_gender</th>\n",
       "      <th>Review_income</th>\n",
       "      <th>Review_political</th>\n",
       "      <th>Review_religious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3ubu5Minm7ygqK3oa</td>\n",
       "      <td>-2147481563_6968366610050747.0</td>\n",
       "      <td>6.968367e+15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gender</td>\n",
       "      <td>...</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RUS</td>\n",
       "      <td>32.0</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>male</td>\n",
       "      <td>35000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FKd9Fje2tWt2sHi6v</td>\n",
       "      <td>-2147481563_6968366610050747.0</td>\n",
       "      <td>6.968367e+15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fat</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RUS</td>\n",
       "      <td>32.0</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>male</td>\n",
       "      <td>35000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J6WRHLj8exr4bNwTm</td>\n",
       "      <td>-2147481563_6968366610050747.0</td>\n",
       "      <td>6.968367e+15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Young</td>\n",
       "      <td>Age</td>\n",
       "      <td>...</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RUS</td>\n",
       "      <td>32.0</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>male</td>\n",
       "      <td>35000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KcYXwqS3rTrbqdTY2</td>\n",
       "      <td>-2147481563_6968366610050747.0</td>\n",
       "      <td>6.968367e+15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pets</td>\n",
       "      <td>Species</td>\n",
       "      <td>...</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RUS</td>\n",
       "      <td>32.0</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>male</td>\n",
       "      <td>35000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZQsAWst58jK9HcKvx</td>\n",
       "      <td>-2147481563_6968366610050747.0</td>\n",
       "      <td>6.968367e+15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fit</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>...</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RUS</td>\n",
       "      <td>32.0</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>male</td>\n",
       "      <td>35000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ResponseID               ExtendedSessionID        UserID  \\\n",
       "0  3ubu5Minm7ygqK3oa  -2147481563_6968366610050747.0  6.968367e+15   \n",
       "1  FKd9Fje2tWt2sHi6v  -2147481563_6968366610050747.0  6.968367e+15   \n",
       "2  J6WRHLj8exr4bNwTm  -2147481563_6968366610050747.0  6.968367e+15   \n",
       "3  KcYXwqS3rTrbqdTY2  -2147481563_6968366610050747.0  6.968367e+15   \n",
       "4  ZQsAWst58jK9HcKvx  -2147481563_6968366610050747.0  6.968367e+15   \n",
       "\n",
       "   ScenarioOrder  Intervention  PedPed  Barrier  CrossingSignal  \\\n",
       "0             13             0       0        0               0   \n",
       "1              8             0       1        0               0   \n",
       "2              2             0       0        0               2   \n",
       "3              1             0       1        0               2   \n",
       "4              5             0       1        0               0   \n",
       "\n",
       "  AttributeLevel ScenarioTypeStrict  ... Template DescriptionShown LeftHand  \\\n",
       "0         Female             Gender  ...  Desktop              0.0      0.0   \n",
       "1            Fat            Fitness  ...  Desktop              0.0      0.0   \n",
       "2          Young                Age  ...  Desktop              0.0      1.0   \n",
       "3           Pets            Species  ...  Desktop              0.0      1.0   \n",
       "4            Fit            Fitness  ...  Desktop              0.0      1.0   \n",
       "\n",
       "   UserCountry3  Review_age  Review_education  Review_gender Review_income  \\\n",
       "0           RUS        32.0          bachelor           male         35000   \n",
       "1           RUS        32.0          bachelor           male         35000   \n",
       "2           RUS        32.0          bachelor           male         35000   \n",
       "3           RUS        32.0          bachelor           male         35000   \n",
       "4           RUS        32.0          bachelor           male         35000   \n",
       "\n",
       "   Review_political  Review_religious  \n",
       "0               0.5              0.61  \n",
       "1               0.5              0.61  \n",
       "2               0.5              0.61  \n",
       "3               0.5              0.61  \n",
       "4               0.5              0.61  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Desktop', 'Mobile', nan], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data['Template'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ResponseID', 'ExtendedSessionID', 'UserID', 'ScenarioOrder',\n",
       "       'Intervention', 'PedPed', 'Barrier', 'CrossingSignal', 'AttributeLevel',\n",
       "       'ScenarioTypeStrict', 'ScenarioType', 'DefaultChoice',\n",
       "       'NonDefaultChoice', 'DefaultChoiceIsOmission', 'NumberOfCharacters',\n",
       "       'DiffNumberOFCharacters', 'Saved', 'Template', 'DescriptionShown',\n",
       "       'LeftHand', 'UserCountry3', 'Review_age', 'Review_education',\n",
       "       'Review_gender', 'Review_income', 'Review_political',\n",
       "       'Review_religious'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., nan])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data['DescriptionShown'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data['ResponseID'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScenarioType\n",
       "Utilitarian      2033776\n",
       "Species          1926824\n",
       "Gender           1918818\n",
       "Age              1854740\n",
       "Fitness          1730828\n",
       "Random           1201814\n",
       "Social Status     619341\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data['ScenarioType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScenarioTypeStrict\n",
       "Utilitarian      1977056\n",
       "Species          1919396\n",
       "Gender           1917456\n",
       "Age              1917290\n",
       "Fitness          1916408\n",
       "Random            957497\n",
       "Social Status     681038\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_data['ScenarioTypeStrict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseID                       0\n",
       "ExtendedSessionID                0\n",
       "UserID                           0\n",
       "ScenarioOrder                    0\n",
       "Intervention                     0\n",
       "PedPed                           0\n",
       "Barrier                          0\n",
       "CrossingSignal                   0\n",
       "AttributeLevel                   0\n",
       "ScenarioTypeStrict               0\n",
       "ScenarioType                     0\n",
       "DefaultChoice              1201814\n",
       "NonDefaultChoice           1201814\n",
       "DefaultChoiceIsOmission    1201814\n",
       "NumberOfCharacters               0\n",
       "DiffNumberOFCharacters           0\n",
       "Saved                            0\n",
       "Template                       398\n",
       "DescriptionShown               398\n",
       "LeftHand                       398\n",
       "UserCountry3                 41641\n",
       "Review_age                 1351805\n",
       "Review_education                 0\n",
       "Review_gender                   90\n",
       "Review_income                    0\n",
       "Review_political                 0\n",
       "Review_religious                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the nr of NA values in the survey data\n",
    "survey_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 483383 incomplete sessions:\n",
      "ExtendedSessionID\n",
      "-100000048_6278203951150712.0     22\n",
      "-1000001217_94943415137418.0      22\n",
      "-1000019949_2701113154493029.0    22\n",
      "-1000035560_1361434247562778.0    22\n",
      "-1000039975_4167536741855688.0    23\n",
      "                                  ..\n",
      "999943908_1050677847894423.0      23\n",
      "999956005_5574342995681670.0      21\n",
      "999959444_7715031490545359.0      20\n",
      "999986692_4940530096463241.0      23\n",
      "999997176_4292206840516579.0      24\n",
      "Length: 483383, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named `df`\n",
    "# Group by 'ExtendedSessionID' and count the number of rows per session\n",
    "session_counts = survey_data.groupby('ExtendedSessionID').size()\n",
    "\n",
    "# Identify sessions that do not have exactly 26 rows\n",
    "incomplete_sessions = session_counts[session_counts != 26]\n",
    "\n",
    "# If there are incomplete sessions, display their counts\n",
    "if not incomplete_sessions.empty:\n",
    "    print(f\"Found {len(incomplete_sessions)} incomplete sessions:\")\n",
    "    print(incomplete_sessions)\n",
    "else:\n",
    "    print(\"All sessions are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100000048_6278203951150712.0 999997176_4292206840516579.0\n"
     ]
    }
   ],
   "source": [
    "min = survey_data['ExtendedSessionID'].min()\n",
    "max = survey_data['ExtendedSessionID'].max()\n",
    "\n",
    "print(min, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '(nan, nan, nan, nan)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1131\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot cast array data from dtype('O') to dtype('float64') according to the rule 'safe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 41\u001b[0m\n\u001b[0;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mread_csv(input_file, blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m16MB\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescriptionShown\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLeftHand\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUserID\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStroller\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     37\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWoman\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m})  \u001b[38;5;66;03m# You can adjust blocksize according to your RAM\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Step 3: Sort the DataFrame by 'ExtendedSessionID'\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Dask will manage the sorting in parallel\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m sorted_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtendedSessionID\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Step 4: Write the sorted DataFrame to a new CSV file\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Writing to CSV in a single output file\u001b[39;00m\n\u001b[0;32m     45\u001b[0m sorted_df\u001b[38;5;241m.\u001b[39mto_csv(output_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, single_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\dataframe\\core.py:5057\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[1;34m(self, by, npartitions, ascending, na_position, sort_function, sort_function_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   5025\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sort the dataset by a single column.\u001b[39;00m\n\u001b[0;32m   5026\u001b[0m \n\u001b[0;32m   5027\u001b[0m \u001b[38;5;124;03mSorting a parallel dataset requires expensive shuffles and is generally\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5053\u001b[0m \u001b[38;5;124;03m>>> df2 = df.sort_values('x')  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m   5054\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5055\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshuffle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sort_values\n\u001b[1;32m-> 5057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sort_values(\n\u001b[0;32m   5058\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5059\u001b[0m     by,\n\u001b[0;32m   5060\u001b[0m     ascending\u001b[38;5;241m=\u001b[39mascending,\n\u001b[0;32m   5061\u001b[0m     npartitions\u001b[38;5;241m=\u001b[39mnpartitions,\n\u001b[0;32m   5062\u001b[0m     na_position\u001b[38;5;241m=\u001b[39mna_position,\n\u001b[0;32m   5063\u001b[0m     sort_function\u001b[38;5;241m=\u001b[39msort_function,\n\u001b[0;32m   5064\u001b[0m     sort_function_kwargs\u001b[38;5;241m=\u001b[39msort_function_kwargs,\n\u001b[0;32m   5065\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   5066\u001b[0m )\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\dataframe\\shuffle.py:179\u001b[0m, in \u001b[0;36msort_values\u001b[1;34m(df, by, npartitions, ascending, na_position, upsample, partition_size, sort_function, sort_function_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    176\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDask currently only supports a single boolean for ascending. You passed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(ascending)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m         )\n\u001b[1;32m--> 179\u001b[0m divisions, mins, maxes, presorted \u001b[38;5;241m=\u001b[39m _calculate_divisions(\n\u001b[0;32m    180\u001b[0m     df, sort_by_col, repartition, npartitions, upsample, partition_size, ascending\n\u001b[0;32m    181\u001b[0m )\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(divisions) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmap_partitions(\n\u001b[0;32m    185\u001b[0m         sort_function, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msort_kwargs\n\u001b[0;32m    186\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\dataframe\\shuffle.py:50\u001b[0m, in \u001b[0;36m_calculate_divisions\u001b[1;34m(df, partition_col, repartition, npartitions, upsample, partition_size, ascending)\u001b[0m\n\u001b[0;32m     47\u001b[0m maxes \u001b[38;5;241m=\u001b[39m partition_col\u001b[38;5;241m.\u001b[39mmap_partitions(M\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     divisions, sizes, mins, maxes \u001b[38;5;241m=\u001b[39m compute(divisions, sizes, mins, maxes)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# When there are nulls and a column is non-numeric, a TypeError is sometimes raised as a result of\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# 1) computing mins/maxes above, 2) every null being switched to NaN, and 3) NaN being a float.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# Also, Pandas ExtensionDtypes may cause TypeErrors when dealing with special nulls such as pd.NaT or pd.NA.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# If this happens, we hint the user about eliminating nulls beforehand.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_numeric_dtype(partition_col\u001b[38;5;241m.\u001b[39mdtype):\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\base.py:595\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[0;32m    593\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 595\u001b[0m results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[38;5;241m.\u001b[39m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[38;5;241m=\u001b[39m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[38;5;241m=\u001b[39mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         raise_exception(exc, tb)\n\u001b[0;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[0;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[1;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m _execute_task(task, data)\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[0;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\core.py:121\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    117\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(_execute_task(a, cache) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\optimization.py:992\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys):\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m args, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys), \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[1;32m--> 992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m core\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdsk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutkey, \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys, args)))\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\core.py:151\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, out, cache)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m toposort(dsk):\n\u001b[0;32m    150\u001b[0m     task \u001b[38;5;241m=\u001b[39m dsk[key]\n\u001b[1;32m--> 151\u001b[0m     result \u001b[38;5;241m=\u001b[39m _execute_task(task, cache)\n\u001b[0;32m    152\u001b[0m     cache[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    153\u001b[0m result \u001b[38;5;241m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\core.py:121\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    117\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(_execute_task(a, cache) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\core.py:121\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    117\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(_execute_task(a, cache) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\core.py:121\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    117\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(_execute_task(a, cache) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:142\u001b[0m, in \u001b[0;36mCSVFunctionWrapper.__call__\u001b[1;34m(self, part)\u001b[0m\n\u001b[0;32m    139\u001b[0m         rest_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m columns\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Call `pandas_read_text`\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m df \u001b[38;5;241m=\u001b[39m pandas_read_text(\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader,\n\u001b[0;32m    144\u001b[0m     block,\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader,\n\u001b[0;32m    146\u001b[0m     rest_kwargs,\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes,\n\u001b[0;32m    148\u001b[0m     columns,\n\u001b[0;32m    149\u001b[0m     write_header,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menforce,\n\u001b[0;32m    151\u001b[0m     path_info,\n\u001b[0;32m    152\u001b[0m )\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project_after_read:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:195\u001b[0m, in \u001b[0;36mpandas_read_text\u001b[1;34m(reader, b, header, kwargs, dtypes, columns, write_header, enforce, path)\u001b[0m\n\u001b[0;32m    193\u001b[0m bio\u001b[38;5;241m.\u001b[39mwrite(b)\n\u001b[0;32m    194\u001b[0m bio\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 195\u001b[0m df \u001b[38;5;241m=\u001b[39m reader(bio, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtypes:\n\u001b[0;32m    197\u001b[0m     coerce_dtypes(df, dtypes)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m         nrows\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1036\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1137\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '(nan, nan, nan, nan)'"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Step 1: Define the path to your input file and output file\n",
    "input_file = 'SharedResponses.csv'  # Replace with your file path\n",
    "output_file = 'sorted.csv'  # Path for the output CSV file\n",
    "\n",
    "dtype={'DescriptionShown': 'float64',\n",
    "       'LeftHand': 'float64',\n",
    "       'UserID': 'float64'}\n",
    "\n",
    "# Step 2: Read the dataset using Dask\n",
    "# Adjust the blocksize parameter as needed to optimize chunk size\n",
    "df = dd.read_csv(input_file, blocksize='16MB', dtype={'DescriptionShown': 'float64',\n",
    "       'LeftHand': 'float64',\n",
    "       'UserID': 'float64',\n",
    "       'Boy': 'float64',\n",
    "       'Cat': 'float64',\n",
    "       'Criminal': 'float64',\n",
    "       'DiffNumberOFCharacters': 'float64',\n",
    "       'Dog': 'float64',\n",
    "       'FemaleAthlete': 'float64',\n",
    "       'FemaleDoctor': 'float64',\n",
    "       'FemaleExecutive': 'float64',\n",
    "       'Girl': 'float64',\n",
    "       'Homeless': 'float64',\n",
    "       'LargeMan': 'float64',\n",
    "       'LargeWoman': 'float64',\n",
    "       'MaleAthlete': 'float64',\n",
    "       'MaleDoctor': 'float64',\n",
    "       'MaleExecutive': 'float64',\n",
    "       'Man': 'float64',\n",
    "       'NumberOfCharacters': 'float64',\n",
    "       'OldMan': 'float64',\n",
    "       'OldWoman': 'float64',\n",
    "       'Pregnant': 'float64',\n",
    "       'Stroller': 'float64',\n",
    "       'Woman': 'float64'})  # You can adjust blocksize according to your RAM\n",
    "\n",
    "# Step 3: Sort the DataFrame by 'ExtendedSessionID'\n",
    "# Dask will manage the sorting in parallel\n",
    "sorted_df = df.sort_values(by='ExtendedSessionID', ascending=True)\n",
    "\n",
    "# Step 4: Write the sorted DataFrame to a new CSV file\n",
    "# Writing to CSV in a single output file\n",
    "sorted_df.to_csv(output_file, index=False, single_file=True)\n",
    "\n",
    "print(f\"Sorted dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.68 MiB for an array with shape (5, 96557) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m sorted_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtendedSessionID\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Step 6: Write the sorted DataFrame to a new CSV file\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m sorted_df\u001b[38;5;241m.\u001b[39mto_csv(output_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, single_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorted dataset saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\dataframe\\core.py:1840\u001b[0m, in \u001b[0;36m_Frame.to_csv\u001b[1;34m(self, filename, **kwargs)\u001b[0m\n\u001b[0;32m   1837\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See dd.to_csv docstring for more information\"\"\"\u001b[39;00m\n\u001b[0;32m   1838\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_csv\n\u001b[1;32m-> 1840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_csv(\u001b[38;5;28mself\u001b[39m, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py:993\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(df, filename, single_file, encoding, mode, name_function, compression, compute, scheduler, storage_options, header_first_partition_only, compute_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    989\u001b[0m         compute_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m scheduler\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n\u001b[1;32m--> 993\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(dask\u001b[38;5;241m.\u001b[39mcompute(\u001b[38;5;241m*\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompute_kwargs))\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\base.py:595\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[0;32m    593\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 595\u001b[0m results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[38;5;241m.\u001b[39m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[38;5;241m=\u001b[39m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[38;5;241m=\u001b[39mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         raise_exception(exc, tb)\n\u001b[0;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[0;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[1;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m _execute_task(task, data)\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[0;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\core.py:121\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    117\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(_execute_task(a, cache) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\dataframe\\dispatch.py:66\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(dfs, axis, join, uniform, filter_warning, ignore_index, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     func \u001b[38;5;241m=\u001b[39m concat_dispatch\u001b[38;5;241m.\u001b[39mdispatch(\u001b[38;5;28mtype\u001b[39m(dfs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[0;32m     67\u001b[0m         dfs,\n\u001b[0;32m     68\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m     69\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m     70\u001b[0m         uniform\u001b[38;5;241m=\u001b[39muniform,\n\u001b[0;32m     71\u001b[0m         filter_warning\u001b[38;5;241m=\u001b[39mfilter_warning,\n\u001b[0;32m     72\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     74\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\dask\\dataframe\\backends.py:651\u001b[0m, in \u001b[0;36mconcat_pandas\u001b[1;34m(dfs, axis, join, uniform, filter_warning, ignore_index, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m filter_warning:\n\u001b[0;32m    650\u001b[0m                 warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 651\u001b[0m             out \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs3, join\u001b[38;5;241m=\u001b[39mjoin, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dfs2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, pd\u001b[38;5;241m.\u001b[39mCategoricalDtype):\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:385\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    372\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    373\u001b[0m     objs,\n\u001b[0;32m    374\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    383\u001b[0m )\n\u001b[1;32m--> 385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    617\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    618\u001b[0m )\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:242\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    240\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m values\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     values \u001b[38;5;241m=\u001b[39m _concatenate_join_units(join_units, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    243\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:581\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, copy)\u001b[0m\n\u001b[0;32m    578\u001b[0m has_none_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(unit\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[0;32m    579\u001b[0m upcasted_na \u001b[38;5;241m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[1;32m--> 581\u001b[0m to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    582\u001b[0m     ju\u001b[38;5;241m.\u001b[39mget_reindexed_values(empty_dtype\u001b[38;5;241m=\u001b[39mempty_dtype, upcasted_na\u001b[38;5;241m=\u001b[39mupcasted_na)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[0;32m    584\u001b[0m ]\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(to_concat) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;66;03m# Only one block, nothing to concatenate.\u001b[39;00m\n\u001b[0;32m    588\u001b[0m     concat_values \u001b[38;5;241m=\u001b[39m to_concat[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:582\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    578\u001b[0m has_none_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(unit\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[0;32m    579\u001b[0m upcasted_na \u001b[38;5;241m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[0;32m    581\u001b[0m to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 582\u001b[0m     ju\u001b[38;5;241m.\u001b[39mget_reindexed_values(empty_dtype\u001b[38;5;241m=\u001b[39mempty_dtype, upcasted_na\u001b[38;5;241m=\u001b[39mupcasted_na)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[0;32m    584\u001b[0m ]\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(to_concat) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;66;03m# Only one block, nothing to concatenate.\u001b[39;00m\n\u001b[0;32m    588\u001b[0m     concat_values \u001b[38;5;241m=\u001b[39m to_concat[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:567\u001b[0m, in \u001b[0;36mJoinUnit.get_reindexed_values\u001b[1;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax, indexer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 567\u001b[0m         values \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(values, indexer, axis\u001b[38;5;241m=\u001b[39max)\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.68 MiB for an array with shape (5, 96557) and data type int64"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Step 1: Define the path to your input file and output file\n",
    "input_file = 'SharedResponses.csv'  # Replace with your file path\n",
    "output_file = 'sorted.csv'  # Path for the output CSV file\n",
    "\n",
    "# Step 2: Define dtypes, using 'object' for potentially mixed columns\n",
    "dtype = {\n",
    "    'DescriptionShown': 'float64',\n",
    "    'LeftHand': 'float64',\n",
    "    'UserID': 'float64',\n",
    "    'Boy': 'object',  # Changed to 'object' to handle mixed types\n",
    "    'Cat': 'object', \n",
    "    'Criminal': 'object',\n",
    "    'DiffNumberOFCharacters': 'object',\n",
    "    'Dog': 'object',\n",
    "    'FemaleAthlete': 'object',\n",
    "    'FemaleDoctor': 'object',\n",
    "    'FemaleExecutive': 'object',\n",
    "    'Girl': 'object',\n",
    "    'Homeless': 'object',\n",
    "    'LargeMan': 'object',\n",
    "    'LargeWoman': 'object',\n",
    "    'MaleAthlete': 'object',\n",
    "    'MaleDoctor': 'object',\n",
    "    'MaleExecutive': 'object',\n",
    "    'Man': 'object',\n",
    "    'NumberOfCharacters': 'object',\n",
    "    'OldMan': 'object',\n",
    "    'OldWoman': 'object',\n",
    "    'Pregnant': 'object',\n",
    "    'Stroller': 'object',\n",
    "    'Woman': 'object',\n",
    "    'ExtendedSessionID': 'object'  # Change to 'object' if this column contains mixed types\n",
    "}\n",
    "\n",
    "# Step 3: Read the dataset using Dask\n",
    "df = dd.read_csv(input_file, blocksize='16MB', dtype=dtype)\n",
    "\n",
    "# Step 4: Convert numeric columns to float where possible (handle errors gracefully)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        # Convert columns that should be numeric\n",
    "        df[col] = dd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Step 5: Sort the DataFrame by 'ExtendedSessionID'\n",
    "sorted_df = df.sort_values(by='ExtendedSessionID', ascending=True)\n",
    "\n",
    "# Step 6: Write the sorted DataFrame to a new CSV file\n",
    "sorted_df.to_csv(output_file, index=False, single_file=True)\n",
    "\n",
    "print(f\"Sorted dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reader = pd.read_csv('SharedResponses.csv', usecols=['ExtendedSessionID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TextFileReader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m session_counts \u001b[38;5;241m=\u001b[39m reader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtendedSessionID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m      3\u001b[0m ids_to_keep \u001b[38;5;241m=\u001b[39m session_counts[session_counts \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m26\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m      5\u001b[0m reader_26 \u001b[38;5;241m=\u001b[39m reader[reader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtendedSessionID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(ids_to_keep)]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TextFileReader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "session_counts = reader['ExtendedSessionID'].value_counts()\n",
    "\n",
    "ids_to_keep = session_counts[session_counts == 26].index\n",
    "\n",
    "reader_26 = reader[reader['ExtendedSessionID'].isin(ids_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_subset = reader.head(10_000_000)\n",
    "reader_subset = reader_subset['ExtendedSessionID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1\n",
      "Finished processing chunk 1\n",
      "Processing chunk 2\n",
      "Finished processing chunk 2\n",
      "Processing chunk 3\n",
      "Finished processing chunk 3\n",
      "Processing chunk 4\n",
      "Finished processing chunk 4\n",
      "Processing chunk 5\n",
      "Finished processing chunk 5\n",
      "Processing chunk 6\n",
      "Finished processing chunk 6\n",
      "Processing chunk 7\n",
      "Finished processing chunk 7\n",
      "Processing chunk 8\n",
      "Finished processing chunk 8\n",
      "Processing chunk 9\n",
      "Finished processing chunk 9\n",
      "Processing chunk 10\n",
      "Finished processing chunk 10\n",
      "Processing chunk 11\n",
      "Finished processing chunk 11\n",
      "Processing chunk 12\n",
      "Finished processing chunk 12\n",
      "Processing chunk 13\n",
      "Finished processing chunk 13\n",
      "Processing chunk 14\n",
      "Finished processing chunk 14\n",
      "Processing chunk 15\n",
      "Finished processing chunk 15\n",
      "Processing chunk 16\n",
      "Finished processing chunk 16\n",
      "Processing chunk 17\n",
      "Finished processing chunk 17\n",
      "Processing chunk 18\n",
      "Finished processing chunk 18\n",
      "Processing chunk 19\n",
      "Finished processing chunk 19\n",
      "Processing chunk 20\n",
      "Finished processing chunk 20\n",
      "Processing chunk 21\n",
      "Finished processing chunk 21\n",
      "Processing chunk 22\n",
      "Finished processing chunk 22\n",
      "Processing chunk 23\n",
      "Finished processing chunk 23\n",
      "Processing chunk 24\n",
      "Finished processing chunk 24\n",
      "Processing chunk 25\n",
      "Finished processing chunk 25\n",
      "Processing chunk 26\n",
      "Finished processing chunk 26\n",
      "Processing chunk 27\n",
      "Finished processing chunk 27\n",
      "Processing chunk 28\n",
      "Finished processing chunk 28\n",
      "Processing chunk 29\n",
      "Finished processing chunk 29\n",
      "Processing chunk 30\n",
      "Finished processing chunk 30\n",
      "Processing chunk 31\n",
      "Finished processing chunk 31\n",
      "Processing chunk 32\n",
      "Finished processing chunk 32\n",
      "Processing chunk 33\n",
      "Finished processing chunk 33\n",
      "Processing chunk 34\n",
      "Finished processing chunk 34\n",
      "Processing chunk 35\n",
      "Finished processing chunk 35\n",
      "Processing chunk 36\n",
      "Finished processing chunk 36\n",
      "Processing chunk 37\n",
      "Finished processing chunk 37\n",
      "Processing chunk 38\n",
      "Finished processing chunk 38\n",
      "Processing chunk 39\n",
      "Finished processing chunk 39\n",
      "Processing chunk 40\n",
      "Finished processing chunk 40\n",
      "Processing chunk 41\n",
      "Finished processing chunk 41\n",
      "Processing chunk 42\n",
      "Finished processing chunk 42\n",
      "Processing chunk 43\n",
      "Finished processing chunk 43\n",
      "Processing chunk 44\n",
      "Finished processing chunk 44\n",
      "Processing chunk 45\n",
      "Finished processing chunk 45\n",
      "Processing chunk 46\n",
      "Finished processing chunk 46\n",
      "Processing chunk 47\n",
      "Finished processing chunk 47\n",
      "Processing chunk 48\n",
      "Finished processing chunk 48\n",
      "Processing chunk 49\n",
      "Finished processing chunk 49\n",
      "Processing chunk 50\n",
      "Finished processing chunk 50\n",
      "Processing chunk 51\n",
      "Finished processing chunk 51\n",
      "Processing chunk 52\n",
      "Finished processing chunk 52\n",
      "Processing chunk 53\n",
      "Finished processing chunk 53\n",
      "Processing chunk 54\n",
      "Finished processing chunk 54\n",
      "Processing chunk 55\n",
      "Finished processing chunk 55\n",
      "Processing chunk 56\n",
      "Finished processing chunk 56\n",
      "Processing chunk 57\n",
      "Finished processing chunk 57\n",
      "Processing chunk 58\n",
      "Finished processing chunk 58\n",
      "Processing chunk 59\n",
      "Finished processing chunk 59\n",
      "Processing chunk 60\n",
      "Finished processing chunk 60\n",
      "Processing chunk 61\n",
      "Finished processing chunk 61\n",
      "Processing chunk 62\n",
      "Finished processing chunk 62\n",
      "Processing chunk 63\n",
      "Finished processing chunk 63\n",
      "Processing chunk 64\n",
      "Finished processing chunk 64\n",
      "Processing chunk 65\n",
      "Finished processing chunk 65\n",
      "Processing chunk 66\n",
      "Finished processing chunk 66\n",
      "Processing chunk 67\n",
      "Finished processing chunk 67\n",
      "Processing chunk 68\n",
      "Finished processing chunk 68\n",
      "Processing chunk 69\n",
      "Finished processing chunk 69\n",
      "Processing chunk 70\n",
      "Finished processing chunk 70\n",
      "Processing chunk 71\n",
      "Finished processing chunk 71\n",
      "Processing chunk 72\n",
      "Finished processing chunk 72\n",
      "Processing chunk 73\n",
      "Finished processing chunk 73\n",
      "Processing chunk 74\n",
      "Finished processing chunk 74\n",
      "Processing chunk 75\n",
      "Finished processing chunk 75\n",
      "Processing chunk 76\n",
      "Finished processing chunk 76\n",
      "Processing chunk 77\n",
      "Finished processing chunk 77\n",
      "Processing chunk 78\n",
      "Finished processing chunk 78\n",
      "Processing chunk 79\n",
      "Finished processing chunk 79\n",
      "Processing chunk 80\n",
      "Finished processing chunk 80\n",
      "Processing chunk 81\n",
      "Finished processing chunk 81\n",
      "Processing chunk 82\n",
      "Finished processing chunk 82\n",
      "Processing chunk 83\n",
      "Finished processing chunk 83\n",
      "Processing chunk 84\n",
      "Finished processing chunk 84\n",
      "Processing chunk 85\n",
      "Finished processing chunk 85\n",
      "Processing chunk 86\n",
      "Finished processing chunk 86\n",
      "Processing chunk 87\n",
      "Finished processing chunk 87\n",
      "Processing chunk 88\n",
      "Finished processing chunk 88\n",
      "Processing chunk 89\n",
      "Finished processing chunk 89\n",
      "Processing chunk 90\n",
      "Finished processing chunk 90\n",
      "Processing chunk 91\n",
      "Finished processing chunk 91\n",
      "Processing chunk 92\n",
      "Finished processing chunk 92\n",
      "Processing chunk 93\n",
      "Finished processing chunk 93\n",
      "Processing chunk 94\n",
      "Finished processing chunk 94\n",
      "Processing chunk 95\n",
      "Finished processing chunk 95\n",
      "Processing chunk 96\n",
      "Finished processing chunk 96\n",
      "Processing chunk 97\n",
      "Finished processing chunk 97\n",
      "Processing chunk 98\n",
      "Finished processing chunk 98\n",
      "Processing chunk 99\n",
      "Finished processing chunk 99\n",
      "Processing chunk 100\n",
      "Finished processing chunk 100\n",
      "Processing chunk 101\n",
      "Finished processing chunk 101\n",
      "Processing chunk 102\n",
      "Finished processing chunk 102\n",
      "Processing chunk 103\n",
      "Finished processing chunk 103\n",
      "Processing chunk 104\n",
      "Finished processing chunk 104\n",
      "Processing chunk 105\n",
      "Finished processing chunk 105\n",
      "Processing chunk 106\n",
      "Finished processing chunk 106\n",
      "Processing chunk 107\n",
      "Finished processing chunk 107\n",
      "Processing chunk 108\n",
      "Finished processing chunk 108\n",
      "Processing chunk 109\n",
      "Finished processing chunk 109\n",
      "Processing chunk 110\n",
      "Finished processing chunk 110\n",
      "Processing chunk 111\n",
      "Finished processing chunk 111\n",
      "Processing chunk 112\n",
      "Finished processing chunk 112\n",
      "Processing chunk 113\n",
      "Finished processing chunk 113\n",
      "Processing chunk 114\n",
      "Finished processing chunk 114\n",
      "Processing chunk 115\n",
      "Finished processing chunk 115\n",
      "Processing chunk 116\n",
      "Finished processing chunk 116\n",
      "Processing chunk 117\n",
      "Finished processing chunk 117\n",
      "Processing chunk 118\n",
      "Finished processing chunk 118\n",
      "Processing chunk 119\n",
      "Finished processing chunk 119\n",
      "Processing chunk 120\n",
      "Finished processing chunk 120\n",
      "Processing chunk 121\n",
      "Finished processing chunk 121\n",
      "Processing chunk 122\n",
      "Finished processing chunk 122\n",
      "Processing chunk 123\n",
      "Finished processing chunk 123\n",
      "Processing chunk 124\n",
      "Finished processing chunk 124\n",
      "Processing chunk 125\n",
      "Finished processing chunk 125\n",
      "Processing chunk 126\n",
      "Finished processing chunk 126\n",
      "Processing chunk 127\n",
      "Finished processing chunk 127\n",
      "Processing chunk 128\n",
      "Finished processing chunk 128\n",
      "Processing chunk 129\n",
      "Finished processing chunk 129\n",
      "Processing chunk 130\n",
      "Finished processing chunk 130\n",
      "Processing chunk 131\n",
      "Finished processing chunk 131\n",
      "Processing chunk 132\n",
      "Finished processing chunk 132\n",
      "Processing chunk 133\n",
      "Finished processing chunk 133\n",
      "Processing chunk 134\n",
      "Finished processing chunk 134\n",
      "Processing chunk 135\n",
      "Finished processing chunk 135\n",
      "Processing chunk 136\n",
      "Finished processing chunk 136\n",
      "Processing chunk 137\n",
      "Finished processing chunk 137\n",
      "Processing chunk 138\n",
      "Finished processing chunk 138\n",
      "Processing chunk 139\n",
      "Finished processing chunk 139\n",
      "Processing chunk 140\n",
      "Finished processing chunk 140\n",
      "Processing chunk 141\n",
      "Finished processing chunk 141\n",
      "Processing chunk 142\n",
      "Finished processing chunk 142\n",
      "Processing chunk 143\n",
      "Finished processing chunk 143\n",
      "Processing chunk 144\n",
      "Finished processing chunk 144\n",
      "Processing chunk 145\n",
      "Finished processing chunk 145\n",
      "Processing chunk 146\n",
      "Finished processing chunk 146\n",
      "Processing chunk 147\n",
      "Finished processing chunk 147\n",
      "Processing chunk 148\n",
      "Finished processing chunk 148\n",
      "Processing chunk 149\n",
      "Finished processing chunk 149\n",
      "Processing chunk 150\n",
      "Finished processing chunk 150\n",
      "Processing chunk 151\n",
      "Finished processing chunk 151\n",
      "Processing chunk 152\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24284\\2041477983.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Filter rows where ExtendedSessionID is in reader_subset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msubset_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ExtendedSessionID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Append filtered chunk to empty df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset_chunk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Finished processing chunk {i+1}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     )\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    619\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0mcons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcons\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"concat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[0;32m   5959\u001b[0m                 \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5961\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"concat\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5962\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5963\u001b[1;33m             \u001b[0mcheck_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mattrs\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobjs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5964\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck_attrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5965\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5966\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m-> 5963\u001b[1;33m     def __finalize__(\n\u001b[0m\u001b[0;32m   5964\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNDFrameT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5965\u001b[0m     ) -> NDFrameT:\n\u001b[0;32m   5966\u001b[0m         \"\"\"\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subset = pd.DataFrame()\n",
    "chunk_size = 100_000\n",
    "reader = pd.read_csv('SharedResponses.csv', chunksize=chunk_size, dtype=str, low_memory=False)\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    \n",
    "    print(f\"Processing chunk {i+1}\")\n",
    "\n",
    "    # Filter rows where ExtendedSessionID is in reader_subset\n",
    "    subset_chunk = chunk[chunk['ExtendedSessionID'].isin(reader_subset)]\n",
    "\n",
    "    # Append filtered chunk to empty df\n",
    "    subset = pd.concat([subset, subset_chunk], ignore_index=True)\n",
    "\n",
    "    print(f\"Finished processing chunk {i+1}\")\n",
    "\n",
    "print(\"All chunks have been processed and combined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset.head())\n",
    "print(subset.size)\n",
    "print(subset.shape)\n",
    "print(subset.nunique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
