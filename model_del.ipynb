{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'ResponseID': 'category',\n",
    "    'UserID': 'int8',\n",
    "    'Intervention': 'int8',\n",
    "    'PedPed': 'int8',\n",
    "    'Barrier': 'int8',\n",
    "    'CrossingSignal': 'int8',\n",
    "    'AttributeLevel': 'category',\n",
    "    'ScenarioTypeStrict': 'category',\n",
    "    'NumberOfCharacters': 'int8',\n",
    "    'DiffNumberOFCharacters': 'int8',\n",
    "    'Saved': 'int8',\n",
    "    'Man': 'int8',\n",
    "    'Woman': 'int8',\n",
    "    'Pregnant': 'int8',\n",
    "    'Stroller': 'int8',\n",
    "    'OldMan': 'int8',+\n",
    "    'OldWoman': 'int8',\n",
    "    'Boy': 'int8',\n",
    "    'Girl': 'int8',\n",
    "    'Homeless': 'int8',\n",
    "    'LargeWoman': 'int8',\n",
    "    'LargeMan': 'int8',\n",
    "    'Criminal': 'int8',\n",
    "    'MaleExecutive': 'int8',\n",
    "    'FemaleExecutive': 'int8',\n",
    "    'FemaleAthlete': 'int8',\n",
    "    'MaleAthlete': 'int8',\n",
    "    'FemaleDoctor': 'int8',\n",
    "    'MaleDoctor': 'int8',\n",
    "    'Dog': 'int8',\n",
    "    'Cat': 'int8'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_del = pd.read_csv('total_deleted_50_dataset.csv', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_del.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ResponseID', 'UserID', 'Intervention', 'PedPed', 'Barrier',\n",
      "       'CrossingSignal', 'NumberOfCharacters', 'DiffNumberOFCharacters',\n",
      "       'Saved', 'Man', 'Woman', 'Pregnant', 'Stroller', 'OldMan', 'OldWoman',\n",
      "       'Boy', 'Girl', 'Homeless', 'LargeWoman', 'LargeMan', 'Criminal',\n",
      "       'MaleExecutive', 'FemaleExecutive', 'FemaleAthlete', 'MaleAthlete',\n",
      "       'FemaleDoctor', 'MaleDoctor', 'Dog', 'Cat', 'AttributeLevel_Fat',\n",
      "       'AttributeLevel_Female', 'AttributeLevel_Fit', 'AttributeLevel_Hoomans',\n",
      "       'AttributeLevel_Less', 'AttributeLevel_Male', 'AttributeLevel_More',\n",
      "       'AttributeLevel_Old', 'AttributeLevel_Pets', 'AttributeLevel_Young',\n",
      "       'ScenarioTypeStrict_Age', 'ScenarioTypeStrict_Fitness',\n",
      "       'ScenarioTypeStrict_Gender', 'ScenarioTypeStrict_Species',\n",
      "       'ScenarioTypeStrict_Utilitarian'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# one-hot encode the AttributeLevel and ScenarioTypeStrict\n",
    "df_del = pd.get_dummies(df_del, columns=['AttributeLevel', 'ScenarioTypeStrict'])\n",
    "\n",
    "print(df_del.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 44)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_del.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_del.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now also dropping ResponseID\n",
    "# kept this on and pre-processed it thus far to keep track of if everything went right with the complete sessions being in the dataset (so each ResponseID has to be present twice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variable\n",
    "X = df_del.drop(['UserID', 'ResponseID'], axis=1)     # Features\n",
    "y = df_del['UserID']                                  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation and test sets\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2125000, 42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting K for K-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Split data into train and test for this fold\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m X_train, X_val \u001b[38;5;241m=\u001b[39m X_trainval\u001b[38;5;241m.\u001b[39miloc[train_index], X_trainval\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     15\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y_trainval\u001b[38;5;241m.\u001b[39miloc[train_index], y_trainval\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "# Initialize logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_lr = []\n",
    "classification_reports_lr = []\n",
    "count = 0\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    # Split data into train and test for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_lr = lr_model.predict(X_val)\n",
    "    \n",
    "    # Generate confusion matrix and classification report\n",
    "    conf_matrices_lr.append(confusion_matrix(y_val, y_pred_lr))\n",
    "    classification_reports_lr.append(classification_report(y_val, y_pred_lr, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[185800 168022]\n",
      " [141240 213272]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5681262230919765, 'recall': 0.5251228018608227, 'f1-score': 0.5457787334290943, 'support': 353822.0}\n",
      "1: {'precision': 0.5593374141738396, 'recall': 0.6015931759714763, 'f1-score': 0.5796962786386629, 'support': 354512.0}\n",
      "accuracy: 0.563395234451544\n",
      "macro avg: {'precision': 0.5637318186329081, 'recall': 0.5633579889161495, 'f1-score': 0.5627375060338786, 'support': 708334.0}\n",
      "weighted avg: {'precision': 0.563727537970005, 'recall': 0.563395234451544, 'f1-score': 0.5627540258579973, 'support': 708334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[185544 168907]\n",
      " [141047 212835]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5681234326726701, 'recall': 0.523468688196676, 'f1-score': 0.5448826944593725, 'support': 354451.0}\n",
      "1: {'precision': 0.5575362417549026, 'recall': 0.6014292899893184, 'f1-score': 0.5786515937489805, 'support': 353882.0}\n",
      "accuracy: 0.5624176764318477\n",
      "macro avg: {'precision': 0.5628298372137863, 'recall': 0.5624489890929972, 'f1-score': 0.5617671441041765, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.5628340895298808, 'recall': 0.5624176764318477, 'f1-score': 0.5617535809187144, 'support': 708333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[185695 168132]\n",
      " [140892 213614]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5685927486397193, 'recall': 0.5248186260517146, 'f1-score': 0.5458294508931327, 'support': 353827.0}\n",
      "1: {'precision': 0.55957102366495, 'recall': 0.6025680806530778, 'f1-score': 0.5802741452654797, 'support': 354506.0}\n",
      "accuracy: 0.5637306182261733\n",
      "macro avg: {'precision': 0.5640818861523347, 'recall': 0.5636933533523962, 'f1-score': 0.5630517980793062, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.5640775620905883, 'recall': 0.5637306182261733, 'f1-score': 0.563068307226472, 'support': 708333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_lr[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_lr[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy LR: 0.563181176369855\n",
      "Standard Deviation: 0.0005569677941461436\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_lr = [report['accuracy'] for report in classification_reports_lr]\n",
    "average_accuracy_lr = np.mean(accuracies_lr)\n",
    "print(f\"\\nAverage Accuracy LR: {average_accuracy_lr}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_lr = np.std(accuracies_lr)\n",
    "print(f\"Standard Deviation: {std_dev_lr}\")\n",
    "\n",
    "# Calculate average f1-score\n",
    "f1s_lr_0 = [report['0']['f1-score'] for report in classification_reports_lr]\n",
    "f1s_lr_1 = [report['1']['f1-score'] for report in classification_reports_lr]\n",
    "total_f1s_lr = [f1s_lr_0[i] + f1s_lr_1[i] for i in range(k)]\n",
    "total_f1s_lr = [f1 / 2 for f1 in total_f1s_lr]\n",
    "average_f1_lr = np.mean(total_f1s_lr)\n",
    "print(f\"\\nAverage f1-score LR: {average_f1_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1: 0.6018635155379575\n"
     ]
    }
   ],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_lr = [report['1']['recall'] for report in classification_reports_lr]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_lr = np.mean(recall_class_1_lr)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing fold1\n",
      "Done processing fold2\n",
      "Done processing fold3\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_rf = []\n",
    "classification_reports_rf = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "    # Split the data for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_rf = rf_model.predict(X_val)\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_rf.append(confusion_matrix(y_val, y_pred_rf))\n",
    "    classification_reports_rf.append(classification_report(y_val, y_pred_rf, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold\" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[256226  97596]\n",
      " [ 93809 260703]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7320010856057252, 'recall': 0.7241663887491451, 'f1-score': 0.7280626604551776, 'support': 353822.0}\n",
      "1: {'precision': 0.7276129712893421, 'recall': 0.7353855440718509, 'f1-score': 0.7314786107397333, 'support': 354512.0}\n",
      "accuracy: 0.7297814307939475\n",
      "macro avg: {'precision': 0.7298070284475336, 'recall': 0.7297759664104979, 'f1-score': 0.7297706355974555, 'support': 708334.0}\n",
      "weighted avg: {'precision': 0.7298048911797488, 'recall': 0.7297814307939475, 'f1-score': 0.7297722993646165, 'support': 708334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[254981  99470]\n",
      " [ 92165 261717]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7345065188710226, 'recall': 0.7193688267207597, 'f1-score': 0.7268588662722332, 'support': 354451.0}\n",
      "1: {'precision': 0.7246024912303045, 'recall': 0.7395600793484834, 'f1-score': 0.7320048834448144, 'support': 353882.0}\n",
      "accuracy: 0.7294563432735733\n",
      "macro avg: {'precision': 0.7295545050506635, 'recall': 0.7294644530346216, 'f1-score': 0.7294318748585238, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.7295584829761078, 'recall': 0.7294563432735733, 'f1-score': 0.7294298079748891, 'support': 708333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[253446 100381]\n",
      " [ 90335 264171]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7372309697161856, 'recall': 0.7162992083701922, 'f1-score': 0.7266143736883751, 'support': 353827.0}\n",
      "1: {'precision': 0.724645592398341, 'recall': 0.7451806175353872, 'f1-score': 0.7347696569678663, 'support': 354506.0}\n",
      "accuracy: 0.7307537556488262\n",
      "macro avg: {'precision': 0.7309382810572633, 'recall': 0.7307399129527897, 'f1-score': 0.7306920153281207, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.7309322489571078, 'recall': 0.7307537556488262, 'f1-score': 0.7306959241092638, 'support': 708333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results for each fold\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_rf[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_rf[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy RF: 0.7299971765721157\n",
      "Standard Deviation: 0.000551198329982249\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_rf = [report['accuracy'] for report in classification_reports_rf]\n",
    "average_accuracy_rf = np.mean(accuracies_rf)\n",
    "print(f\"\\nAverage Accuracy RF: {average_accuracy_rf}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_rf = np.std(accuracies_rf)\n",
    "print(f\"Standard Deviation: {std_dev_rf}\")\n",
    "\n",
    "# Calculate average f1-score\n",
    "f1s_rf_0 = [report['0']['f1-score'] for report in classification_reports_rf]\n",
    "f1s_rf_1 = [report['1']['f1-score'] for report in classification_reports_rf]\n",
    "total_f1s_rf = [f1s_rf_0[i] + f1s_rf_1[i] for i in range(k)]\n",
    "total_f1s_rf = [f1 / 2 for f1 in total_f1s_rf]\n",
    "average_f1_rf = np.mean(total_f1s_rf)\n",
    "print(f\"\\nAverage f1-score LR: {average_f1_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1: 0.7400420803185739\n"
     ]
    }
   ],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_rf = [report['1']['recall'] for report in classification_reports_rf]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_rf = np.mean(recall_class_1_rf)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=45)\n",
    "\n",
    "# choosing rbf cause not linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n",
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n",
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n"
     ]
    }
   ],
   "source": [
    "# Lists to store results\n",
    "conf_matrices_svm = []\n",
    "classification_reports_svm = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    print(\"Starting fold \" + str(count))\n",
    "    # Split the data for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    svc.fit(X_train, y_train)\n",
    "    print(\"Model fitted\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_svm = svc.predict(X_val)\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_svm.append(confusion_matrix(y_val, y_pred_svm))\n",
    "    classification_reports_svm.append(classification_report(y_val, y_pred_svm, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[33869  7839]\n",
      " [19892 21734]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6299920016368743, 'recall': 0.81205044595761, 'f1-score': 0.7095287475515613, 'support': 41708.0}\n",
      "1: {'precision': 0.7349271294762114, 'recall': 0.5221255945803104, 'f1-score': 0.6105141926150648, 'support': 41626.0}\n",
      "accuracy: 0.6672306621547027\n",
      "macro avg: {'precision': 0.6824595655565429, 'recall': 0.6670880202689602, 'f1-score': 0.660021470083313, 'support': 83334.0}\n",
      "weighted avg: {'precision': 0.6824079378866673, 'recall': 0.6672306621547027, 'f1-score': 0.6600701848546235, 'support': 83334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[33671  8098]\n",
      " [19928 21636]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6282020186943786, 'recall': 0.8061241590653355, 'f1-score': 0.7061278416240249, 'support': 41769.0}\n",
      "1: {'precision': 0.7276518463711577, 'recall': 0.5205466268886536, 'f1-score': 0.6069174450896239, 'support': 41564.0}\n",
      "accuracy: 0.663686654746619\n",
      "macro avg: {'precision': 0.6779269325327681, 'recall': 0.6633353929769945, 'f1-score': 0.6565226433568243, 'support': 83333.0}\n",
      "weighted avg: {'precision': 0.6778046087554306, 'recall': 0.663686654746619, 'f1-score': 0.6566446726326788, 'support': 83333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[33681  8025]\n",
      " [19790 21837]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6298928391090498, 'recall': 0.807581642929075, 'f1-score': 0.7077550248484403, 'support': 41706.0}\n",
      "1: {'precision': 0.7312638135422945, 'recall': 0.5245874072116655, 'f1-score': 0.6109191623886192, 'support': 41627.0}\n",
      "accuracy: 0.6662186648746595\n",
      "macro avg: {'precision': 0.6805783263256722, 'recall': 0.6660845250703702, 'f1-score': 0.6593370936185298, 'support': 83333.0}\n",
      "weighted avg: {'precision': 0.6805302762915907, 'recall': 0.6662186648746595, 'f1-score': 0.6593829940009373, 'support': 83333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results for each fold\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_svm[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_svm[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy RF: 0.6657119939253271\n",
      "Standard Deviation: 0.0014905331742503187\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_svm = [report['accuracy'] for report in classification_reports_svm]\n",
    "average_accuracy_svm = np.mean(accuracies_svm)\n",
    "print(f\"\\nAverage Accuracy SVM: {average_accuracy_svm}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_svm = np.std(accuracies_svm)\n",
    "print(f\"Standard Deviation: {std_dev_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_svm = [report['1']['recall'] for report in classification_reports_svm]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_svm = np.mean(recall_class_1_svm)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, optimizers, models, callbacks\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "initial_learning_rate = 5e-4\n",
    "decay_rate = 0.1  # Decay rate per step\n",
    "\n",
    "# Define the learning rate schedule\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=decay_rate)\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',             # Watch accuracy\n",
    "    patience=5,                         # Stop after 3 epochs with no improvement\n",
    "    restore_best_weights=True,          # Restore weights from the best epoch\n",
    "    min_delta=0.0005                    # Minimum change in accuracy to qualify as an improvement\n",
    ")\n",
    "\n",
    "# Function to build the model\n",
    "def build_model():\n",
    "    model_mlp = models.Sequential()\n",
    "    model_mlp.add(layers.Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model_mlp.add(layers.BatchNormalization())\n",
    "    model_mlp.add(layers.Dense(64, activation='relu'))\n",
    "    model_mlp.add(layers.BatchNormalization())\n",
    "    model_mlp.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model_mlp.compile(optimizer=optimizers.Adam(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=['accuracy', keras.metrics.Recall()])\n",
    "    return model_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 910us/step - accuracy: 0.6012 - loss: 0.6512 - recall: 0.5915 - val_accuracy: 0.6229 - val_loss: 0.6326 - val_recall: 0.6022\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 877us/step - accuracy: 0.6130 - loss: 0.6402 - recall: 0.5936 - val_accuracy: 0.6230 - val_loss: 0.6325 - val_recall: 0.5980\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 984us/step - accuracy: 0.6127 - loss: 0.6404 - recall: 0.5930 - val_accuracy: 0.6229 - val_loss: 0.6326 - val_recall: 0.5983\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1ms/step - accuracy: 0.6142 - loss: 0.6401 - recall: 0.5948 - val_accuracy: 0.6233 - val_loss: 0.6326 - val_recall: 0.5960\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1ms/step - accuracy: 0.6120 - loss: 0.6406 - recall: 0.5926 - val_accuracy: 0.6235 - val_loss: 0.6326 - val_recall: 0.5941\n",
      "Epoch 6/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1ms/step - accuracy: 0.6131 - loss: 0.6400 - recall: 0.5931 - val_accuracy: 0.6229 - val_loss: 0.6326 - val_recall: 0.6019\n",
      "Epoch 7/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2ms/step - accuracy: 0.6142 - loss: 0.6399 - recall: 0.5949 - val_accuracy: 0.6234 - val_loss: 0.6326 - val_recall: 0.6013\n",
      "Epoch 8/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2ms/step - accuracy: 0.6131 - loss: 0.6400 - recall: 0.5933 - val_accuracy: 0.6230 - val_loss: 0.6325 - val_recall: 0.6123\n",
      "Epoch 9/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 4ms/step - accuracy: 0.6136 - loss: 0.6400 - recall: 0.5945 - val_accuracy: 0.6235 - val_loss: 0.6326 - val_recall: 0.6020\n",
      "Epoch 10/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 5ms/step - accuracy: 0.6139 - loss: 0.6402 - recall: 0.5952 - val_accuracy: 0.6231 - val_loss: 0.6326 - val_recall: 0.6008\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 5ms/step - accuracy: 0.6011 - loss: 0.6514 - recall_1: 0.5878 - val_accuracy: 0.6244 - val_loss: 0.6317 - val_recall_1: 0.6040\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 5ms/step - accuracy: 0.6152 - loss: 0.6391 - recall_1: 0.5945 - val_accuracy: 0.6245 - val_loss: 0.6317 - val_recall_1: 0.6110\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 5ms/step - accuracy: 0.6152 - loss: 0.6392 - recall_1: 0.5945 - val_accuracy: 0.6254 - val_loss: 0.6314 - val_recall_1: 0.6046\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 5ms/step - accuracy: 0.6141 - loss: 0.6395 - recall_1: 0.5933 - val_accuracy: 0.6249 - val_loss: 0.6315 - val_recall_1: 0.6104\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 5ms/step - accuracy: 0.6147 - loss: 0.6394 - recall_1: 0.5934 - val_accuracy: 0.6249 - val_loss: 0.6315 - val_recall_1: 0.6054\n",
      "Epoch 6/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 5ms/step - accuracy: 0.6150 - loss: 0.6391 - recall_1: 0.5931 - val_accuracy: 0.6246 - val_loss: 0.6315 - val_recall_1: 0.6133\n",
      "Epoch 7/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 5ms/step - accuracy: 0.6152 - loss: 0.6394 - recall_1: 0.5938 - val_accuracy: 0.6251 - val_loss: 0.6316 - val_recall_1: 0.6016\n",
      "Epoch 8/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 5ms/step - accuracy: 0.6144 - loss: 0.6397 - recall_1: 0.5936 - val_accuracy: 0.6252 - val_loss: 0.6315 - val_recall_1: 0.6028\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 5ms/step - accuracy: 0.6025 - loss: 0.6506 - recall_2: 0.5905 - val_accuracy: 0.6236 - val_loss: 0.6324 - val_recall_2: 0.5847\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 5ms/step - accuracy: 0.6153 - loss: 0.6384 - recall_2: 0.5987 - val_accuracy: 0.6233 - val_loss: 0.6323 - val_recall_2: 0.5994\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 5ms/step - accuracy: 0.6153 - loss: 0.6386 - recall_2: 0.5990 - val_accuracy: 0.6232 - val_loss: 0.6323 - val_recall_2: 0.5926\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 5ms/step - accuracy: 0.6149 - loss: 0.6390 - recall_2: 0.5983 - val_accuracy: 0.6236 - val_loss: 0.6323 - val_recall_2: 0.5936\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2ms/step - accuracy: 0.6159 - loss: 0.6385 - recall_2: 0.6000 - val_accuracy: 0.6232 - val_loss: 0.6324 - val_recall_2: 0.5895\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 478us/step\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 893us/step - accuracy: 0.5996 - loss: 0.6510 - recall_3: 0.5911 - val_accuracy: 0.6221 - val_loss: 0.6314 - val_recall_3: 0.6161\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 912us/step - accuracy: 0.6118 - loss: 0.6397 - recall_3: 0.5953 - val_accuracy: 0.6224 - val_loss: 0.6314 - val_recall_3: 0.6045\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1ms/step - accuracy: 0.6128 - loss: 0.6397 - recall_3: 0.5966 - val_accuracy: 0.6218 - val_loss: 0.6314 - val_recall_3: 0.6012\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 885us/step - accuracy: 0.6131 - loss: 0.6394 - recall_3: 0.5968 - val_accuracy: 0.6226 - val_loss: 0.6314 - val_recall_3: 0.5985\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 903us/step - accuracy: 0.6121 - loss: 0.6398 - recall_3: 0.5963 - val_accuracy: 0.6223 - val_loss: 0.6314 - val_recall_3: 0.6054\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 493us/step\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 964us/step - accuracy: 0.5998 - loss: 0.6517 - recall_4: 0.5870 - val_accuracy: 0.6251 - val_loss: 0.6311 - val_recall_4: 0.5938\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1ms/step - accuracy: 0.6124 - loss: 0.6402 - recall_4: 0.5906 - val_accuracy: 0.6250 - val_loss: 0.6311 - val_recall_4: 0.5955\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 933us/step - accuracy: 0.6135 - loss: 0.6400 - recall_4: 0.5928 - val_accuracy: 0.6247 - val_loss: 0.6310 - val_recall_4: 0.6031\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1ms/step - accuracy: 0.6124 - loss: 0.6400 - recall_4: 0.5908 - val_accuracy: 0.6246 - val_loss: 0.6310 - val_recall_4: 0.5993\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 951us/step - accuracy: 0.6147 - loss: 0.6396 - recall_4: 0.5935 - val_accuracy: 0.6247 - val_loss: 0.6310 - val_recall_4: 0.5987\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 473us/step\n"
     ]
    }
   ],
   "source": [
    "# Convert data to float32 (required by TensorFlow)\n",
    "X_trainval = np.array(X_trainval, dtype=np.float32)\n",
    "y_trainval = np.array(y_trainval, dtype=np.float32)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_mlp = []\n",
    "classification_reports_mlp = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop over each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "    print(f\"\\nFold {count}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    X_train, X_val = X_trainval[train_index], X_trainval[test_index]\n",
    "    y_train, y_val = y_trainval[train_index], y_trainval[test_index]\n",
    "    \n",
    "    # Build and train the model\n",
    "    model_mlp = build_model()\n",
    "    model_mlp.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_mlp = model_mlp.predict(X_val)\n",
    "    y_pred_mlp = (y_pred_mlp > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_mlp.append(confusion_matrix(y_val, y_pred_mlp))\n",
    "    classification_reports_mlp.append(classification_report(y_val, y_pred_mlp, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy MLP: 0.6239199999999999\n",
      "Standard Deviation: 0.0012098062986597368\n",
      "\n",
      "Average f1-score LR: 0.6236411383236677\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_mlp = [report['accuracy'] for report in classification_reports_mlp]\n",
    "average_accuracy_mlp = np.mean(accuracies_mlp)\n",
    "print(f\"\\nAverage Accuracy MLP: {average_accuracy_mlp}\")\n",
    "\n",
    "# Caluculate average standard deviation of accuracies\n",
    "std_dev_mlp = np.std(accuracies_mlp)\n",
    "print(f\"Standard Deviation: {std_dev_mlp}\")\n",
    "\n",
    "# Calculate average f1-score\n",
    "f1s_mlp_0 = [report['0.0']['f1-score'] for report in classification_reports_mlp]\n",
    "f1s_mlp_1 = [report['1.0']['f1-score'] for report in classification_reports_mlp]\n",
    "total_f1s_mlp = [f1s_mlp_0[i] + f1s_mlp_1[i] for i in range(k)]\n",
    "total_f1s_mlp = [f1 / 2 for f1 in total_f1s_mlp]\n",
    "average_f1_mlp = np.mean(total_f1s_mlp)\n",
    "print(f\"\\nAverage f1-score LR: {average_f1_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1.0: 0.5986750405409876\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Collect the recall for the '1.0' class from each fold\n",
    "recall_class_1_mlp = [report_mlp['1.0']['recall'] for report_mlp in classification_reports_mlp]\n",
    "\n",
    "# Calculate the average recall for the '1.0' class across all folds\n",
    "average_recall_class_1_mlp = np.mean(recall_class_1_mlp)\n",
    "print(f\"\\nAverage Recall for class 1.0: {average_recall_class_1_mlp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'average_accuracy_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Collect the accuracy and recall values by calling the variables\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m [average_accuracy_lr, average_accuracy_rf, average_accuracy_mlp]\n\u001b[0;32m      6\u001b[0m recalls \u001b[38;5;241m=\u001b[39m [average_recall_class_1_lr, average_recall_class_1_rf, average_recall_class_1_mlp]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create a dictionary for the DataFrame\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'average_accuracy_lr' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of model names\n",
    "model_names = ['Logistic Regression', 'Random Forest', 'MLP']\n",
    "\n",
    "# Collect the accuracy and recall values by calling the variables\n",
    "accuracies = [average_accuracy_lr, average_accuracy_rf, average_accuracy_mlp]\n",
    "recalls = [average_recall_class_1_lr, average_recall_class_1_rf, average_recall_class_1_mlp]\n",
    "\n",
    "# Create a dictionary for the DataFrame\n",
    "data = {\n",
    "    'Model': model_names,\n",
    "    'Accuracy': accuracies,\n",
    "    'Recall': recalls\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df_results = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.563181</td>\n",
       "      <td>0.601864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.729997</td>\n",
       "      <td>0.740042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.624808</td>\n",
       "      <td>0.613513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy    Recall\n",
       "0  Logistic Regression  0.563181  0.601864\n",
       "1        Random Forest  0.729997  0.740042\n",
       "2                  MLP  0.624808  0.613513"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search on best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the df of above, it can be seen that the best model is the Random Forest model. I therefore will perform random search on this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further splitting trainval into train and validation set to tune hyperparameters on the validation set\n",
    "# Training set: 70%, Validation set: 15%, Test set: 15% (still the same test set)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=(15/85), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750000, 42)\n",
      "The percentage of the original dataset that is used for training is: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(f\"The percentage of the original dataset that is used for training is: {X_train.shape[0]/df_del.shape[0]*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint  # For defining distributions for random search\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),  # Number of trees in the forest (uniform distribution between 50 and 200)\n",
    "    'max_depth': [None] + list(randint(1, 30).rvs(10)),  # Random depth values including None\n",
    "    'min_samples_split': randint(2, 10),  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 4)  # Minimum samples required to be at a leaf node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_model_search = RandomForestClassifier(random_state=42)  # Random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 224. MiB for an array with shape (1400000, 42) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 880, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 156, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 267, in _safe_indexing\n    return _array_indexing(X, indices, indices_dtype, axis=axis)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 33, in _array_indexing\n    return array[key, ...] if axis == 0 else array[:, key]\n           ~~~~~^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\numpy\\core\\memmap.py\", line 335, in __getitem__\n    res = super().__getitem__(index)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 224. MiB for an array with shape (1400000, 42) and data type float32\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf_model_search,\n\u001b[0;32m      3\u001b[0m                            param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m      4\u001b[0m                            n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,          \u001b[38;5;66;03m# Number of parameter settings that are sampled\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m                            verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m      8\u001b[0m                            n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)          \u001b[38;5;66;03m# Use all available cores\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Fit RandomizedSearchCV\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Get the best parameters and best score\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1961\u001b[0m         ParameterSampler(\n\u001b[0;32m   1962\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1963\u001b[0m         )\n\u001b[0;32m   1964\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    966\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    967\u001b[0m         clone(base_estimator),\n\u001b[0;32m    968\u001b[0m         X,\n\u001b[0;32m    969\u001b[0m         y,\n\u001b[0;32m    970\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    971\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    972\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    973\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    974\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    975\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    976\u001b[0m     )\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    979\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    980\u001b[0m     )\n\u001b[0;32m    981\u001b[0m )\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 224. MiB for an array with shape (1400000, 42) and data type float32"
     ]
    }
   ],
   "source": [
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf_model_search,\n",
    "                           param_distributions=param_dist,\n",
    "                           n_iter=20,          # Number of parameter settings that are sampled\n",
    "                           scoring='recall',   # Use recall as the evaluation metric\n",
    "                           cv=k,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)          # Use all available cores\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Set: 0.5484586666666666\n",
      "[[ 65772 121401]\n",
      " [ 47927 139900]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.35      0.44    187173\n",
      "           1       0.54      0.74      0.62    187827\n",
      "\n",
      "    accuracy                           0.55    375000\n",
      "   macro avg       0.56      0.55      0.53    375000\n",
      "weighted avg       0.56      0.55      0.53    375000\n",
      "\n",
      "Recall on Validation Set: 0.744834342240466\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf_random = random_search.predict(X_val)\n",
    "\n",
    "print(\"Accuracy on Validation Set:\", accuracy_score(y_val, y_pred_rf_random))\n",
    "print(confusion_matrix(y_val, y_pred_rf_random))\n",
    "print(classification_report(y_val, y_pred_rf_random))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall on Validation Set:\", recall_score(y_val, y_pred_rf_random))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
