{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CzaEco_Yhcfy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bknuQkj7j2Xn"
   },
   "source": [
    "Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thundersvm\n",
      "  Obtaining dependency information for thundersvm from https://files.pythonhosted.org/packages/7d/16/281a54f6d1f70c59df242f2f93e5cc04daf01b9c9809c2b154d15ea6a346/thundersvm-0.3.12-py3-none-any.whl.metadata\n",
      "  Downloading thundersvm-0.3.12-py3-none-any.whl.metadata (601 bytes)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (from thundersvm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\anaconda\\lib\\site-packages (from thundersvm) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda\\lib\\site-packages (from thundersvm) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn->thundersvm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn->thundersvm) (3.5.0)\n",
      "Downloading thundersvm-0.3.12-py3-none-any.whl (507 kB)\n",
      "   ---------------------------------------- 0.0/507.4 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/507.4 kB ? eta -:--:--\n",
      "   - ------------------------------------- 20.5/507.4 kB 217.9 kB/s eta 0:00:03\n",
      "   --- ----------------------------------- 51.2/507.4 kB 440.4 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 153.6/507.4 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 245.8/507.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 368.6/507.4 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 481.3/507.4 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 507.4/507.4 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: thundersvm\n",
      "Successfully installed thundersvm-0.3.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install thundersvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall thundersvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/Xtra-Computing/thundersvm.git\n",
    "cd thundersvm/python\n",
    "python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl__JLfchcf0"
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "erACkKathcf2"
   },
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'ResponseID': 'category',\n",
    "    'UserID': 'int8',\n",
    "    'Intervention': 'int8',\n",
    "    'PedPed': 'int8',\n",
    "    'Barrier': 'int8',\n",
    "    'CrossingSignal': 'int8',\n",
    "    'AttributeLevel': 'category',\n",
    "    'ScenarioTypeStrict': 'category',\n",
    "    'NumberOfCharacters': 'int8',\n",
    "    'DiffNumberOFCharacters': 'int8',\n",
    "    'Saved': 'int8',\n",
    "    'Man': 'int8',\n",
    "    'Woman': 'int8',\n",
    "    'Pregnant': 'int8',\n",
    "    'Stroller': 'int8',\n",
    "    'OldMan': 'int8',\n",
    "    'OldWoman': 'int8',\n",
    "    'Boy': 'int8',\n",
    "    'Girl': 'int8',\n",
    "    'Homeless': 'int8',\n",
    "    'LargeWoman': 'int8',\n",
    "    'LargeMan': 'int8',\n",
    "    'Criminal': 'int8',\n",
    "    'MaleExecutive': 'int8',\n",
    "    'FemaleExecutive': 'int8',\n",
    "    'FemaleAthlete': 'int8',\n",
    "    'MaleAthlete': 'int8',\n",
    "    'FemaleDoctor': 'int8',\n",
    "    'MaleDoctor': 'int8',\n",
    "    'Dog': 'int8',\n",
    "    'Cat': 'int8'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JH0wppC3hcf3"
   },
   "outputs": [],
   "source": [
    "df50 = pd.read_csv('total_50_dataset.csv', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7G38VYQehcf3",
    "outputId": "3d19d95f-ba01-49e0-dd47-5d9ec31cbe3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwIWqvLJhcf4",
    "outputId": "d8a6b65f-ec16-4b0f-9755-4b1454730dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ResponseID', 'UserID', 'Intervention', 'PedPed', 'Barrier',\n",
      "       'CrossingSignal', 'NumberOfCharacters', 'DiffNumberOFCharacters',\n",
      "       'Saved', 'Man', 'Woman', 'Pregnant', 'Stroller', 'OldMan', 'OldWoman',\n",
      "       'Boy', 'Girl', 'Homeless', 'LargeWoman', 'LargeMan', 'Criminal',\n",
      "       'MaleExecutive', 'FemaleExecutive', 'FemaleAthlete', 'MaleAthlete',\n",
      "       'FemaleDoctor', 'MaleDoctor', 'Dog', 'Cat', 'AttributeLevel_Fat',\n",
      "       'AttributeLevel_Female', 'AttributeLevel_Fit', 'AttributeLevel_High',\n",
      "       'AttributeLevel_Hoomans', 'AttributeLevel_Less', 'AttributeLevel_Low',\n",
      "       'AttributeLevel_Male', 'AttributeLevel_More', 'AttributeLevel_Old',\n",
      "       'AttributeLevel_Pets', 'AttributeLevel_Young', 'ScenarioTypeStrict_Age',\n",
      "       'ScenarioTypeStrict_Fitness', 'ScenarioTypeStrict_Gender',\n",
      "       'ScenarioTypeStrict_Social Status', 'ScenarioTypeStrict_Species',\n",
      "       'ScenarioTypeStrict_Utilitarian'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# one-hot encode the AttributeLevel and ScenarioTypeStrict\n",
    "df50 = pd.get_dummies(df50, columns=['AttributeLevel', 'ScenarioTypeStrict'])\n",
    "\n",
    "print(df50.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGJurrfIhcf5",
    "outputId": "13b684fc-fd0f-497a-df96-efa7ce68cec2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 47)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJV_XST-hcf5",
    "outputId": "99589a39-5e5b-4b5e-d3fc-8269b1a06619"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df50.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yyd4qifYhcf6"
   },
   "outputs": [],
   "source": [
    "# now also dropping ResponseID\n",
    "# kept this on and pre-processed it thus far to keep track of if everything went right with the complete sessions being in the dataset (so each ResponseID has to be present twice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5ySdd_Shcf7"
   },
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9gsaJesAhcf7"
   },
   "outputs": [],
   "source": [
    "# Prepare features and target variable\n",
    "X = df50.drop(['UserID', 'ResponseID'], axis=1)     # Features\n",
    "y = df50['UserID']                                  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nMfea67jhcf8"
   },
   "outputs": [],
   "source": [
    "# Split the data into train, validation and test sets\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccGnMhhohcf8",
    "outputId": "6386d7ff-9207-4210-85ab-6ea94697a981"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2125000, 45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ES1BB3c2hcf8"
   },
   "outputs": [],
   "source": [
    "# Setting K for K-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 3\n",
    "kf = KFold(n_splits=k, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvqpSDrehcf9"
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ41qrGfhcf9"
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CdptBeNhcf9"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUyHvxD7hcf9",
    "outputId": "37b584ef-d47e-416c-a7ed-90af172d3576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing fold 1\n",
      "Done processing fold 2\n",
      "Done processing fold 3\n"
     ]
    }
   ],
   "source": [
    "# Initialize logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_lr = []\n",
    "classification_reports_lr = []\n",
    "count = 0\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    # Split data into train and test for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_lr = lr_model.predict(X_val)\n",
    "\n",
    "    # Generate confusion matrix and classification report\n",
    "    conf_matrices_lr.append(confusion_matrix(y_val, y_pred_lr))\n",
    "    classification_reports_lr.append(classification_report(y_val, y_pred_lr, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHjuMlMChcf-",
    "outputId": "391970a4-904f-4eed-b24d-a33f1ef33f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[264268  89554]\n",
      " [195688 158824]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.574550609188705, 'recall': 0.7468953315508928, 'f1-score': 0.6494842573773191, 'support': 353822.0}\n",
      "1: {'precision': 0.6394447173260112, 'recall': 0.4480074017240601, 'f1-score': 0.5268755494368791, 'support': 354512.0}\n",
      "accuracy: 0.5973057907710204\n",
      "macro avg: {'precision': 0.6069976632573582, 'recall': 0.5974513666374764, 'f1-score': 0.5881799034070991, 'support': 708334.0}\n",
      "weighted avg: {'precision': 0.6070292704755734, 'recall': 0.5973057907710204, 'f1-score': 0.5881201858102599, 'support': 708334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[265489  88962]\n",
      " [194741 159141]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5768615692153923, 'recall': 0.7490146733963228, 'f1-score': 0.6517618552537742, 'support': 354451.0}\n",
      "1: {'precision': 0.6414311797922637, 'recall': 0.44970074770686275, 'f1-score': 0.5287208153027069, 'support': 353882.0}\n",
      "accuracy: 0.5994779291660843\n",
      "macro avg: {'precision': 0.609146374503828, 'recall': 0.5993577105515928, 'f1-score': 0.5902413352782405, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.6091204402974462, 'recall': 0.5994779291660843, 'f1-score': 0.5902907543733075, 'support': 708333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[265645  88182]\n",
      " [195699 158807]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5758067732537976, 'recall': 0.7507765094240971, 'f1-score': 0.6517528224139475, 'support': 353827.0}\n",
      "1: {'precision': 0.6429719542165846, 'recall': 0.44796703017720435, 'f1-score': 0.5280409645965469, 'support': 354506.0}\n",
      "accuracy: 0.5992266349301811\n",
      "macro avg: {'precision': 0.609389363735191, 'recall': 0.5993717698006508, 'f1-score': 0.5898968935052472, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.6094215556264864, 'recall': 0.5992266349301811, 'f1-score': 0.5898375991116089, 'support': 708333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_lr[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_lr[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-gQUNYfhcf_",
    "outputId": "88910d2d-498a-4ff3-bd3e-0e4a9b32af84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy LR: 0.5986701182890953\n",
      "Standard Deviation: 0.0009701647216432922\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_lr = [report['accuracy'] for report in classification_reports_lr]\n",
    "average_accuracy_lr = np.mean(accuracies_lr)\n",
    "print(f\"\\nAverage Accuracy LR: {average_accuracy_lr}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_lr = np.std(accuracies_lr)\n",
    "print(f\"Standard Deviation: {std_dev_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzVnsaTAhcf_",
    "outputId": "60352a38-82d3-4a43-e3ed-6461d9a1fa3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1: 0.44855839320270907\n"
     ]
    }
   ],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_lr = [report['1']['recall'] for report in classification_reports_lr]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_lr = np.mean(recall_class_1_lr)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt1igotwhcgA"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5RRSDBhhcgA"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoTlMYaDhcgA",
    "outputId": "511ffae2-8b63-4cd3-b9d0-457e494f2f48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing fold1\n",
      "Done processing fold2\n",
      "Done processing fold3\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_rf = []\n",
    "classification_reports_rf = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "    # Split the data for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_rf.append(confusion_matrix(y_val, y_pred_rf))\n",
    "    classification_reports_rf.append(classification_report(y_val, y_pred_rf, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold\" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuTg8VgFhcgB",
    "outputId": "3914912b-1c47-40c8-e034-8239e58dc5ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[274572  79250]\n",
      " [101606 252906]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7298991434905816, 'recall': 0.7760173194431098, 'f1-score': 0.7522520547945205, 'support': 353822.0}\n",
      "1: {'precision': 0.7614072905502234, 'recall': 0.7133919303154759, 'f1-score': 0.7366179871495395, 'support': 354512.0}\n",
      "accuracy: 0.7446741226596493\n",
      "macro avg: {'precision': 0.7456532170204024, 'recall': 0.7447046248792928, 'f1-score': 0.7444350209720301, 'support': 708334.0}\n",
      "weighted avg: {'precision': 0.7456685633269974, 'recall': 0.7446741226596493, 'f1-score': 0.7444274062686027, 'support': 708334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[273493  80958]\n",
      " [ 99231 254651]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7337681501593672, 'recall': 0.7715960739284132, 'f1-score': 0.7522068277924846, 'support': 354451.0}\n",
      "1: {'precision': 0.7587728577004789, 'recall': 0.7195929716685223, 'f1-score': 0.7386637389030458, 'support': 353882.0}\n",
      "accuracy: 0.7456154097013693\n",
      "macro avg: {'precision': 0.7462705039299231, 'recall': 0.7455945227984677, 'f1-score': 0.7454352833477652, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.7462604608579563, 'recall': 0.7456154097013693, 'f1-score': 0.7454407228921448, 'support': 708333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[274318  79509]\n",
      " [100427 254079]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.73201243512255, 'recall': 0.7752884884420917, 'f1-score': 0.7530292133104209, 'support': 353827.0}\n",
      "1: {'precision': 0.7616550955070326, 'recall': 0.7167128341974466, 'f1-score': 0.7385008443613809, 'support': 354506.0}\n",
      "accuracy: 0.7459725863400406\n",
      "macro avg: {'precision': 0.7468337653147913, 'recall': 0.7460006613197692, 'f1-score': 0.7457650288359009, 'support': 708333.0}\n",
      "weighted avg: {'precision': 0.7468479728742308, 'recall': 0.7459725863400406, 'f1-score': 0.7457580654708478, 'support': 708333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results for each fold\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_rf[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_rf[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzKVhoBKhcgB",
    "outputId": "501355fa-165b-4fd7-ea8c-425221d43f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy RF: 0.7454207062336864\n",
      "Standard Deviation: 0.000547682427792883\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_rf = [report['accuracy'] for report in classification_reports_rf]\n",
    "average_accuracy_rf = np.mean(accuracies_rf)\n",
    "print(f\"\\nAverage Accuracy RF: {average_accuracy_rf}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_rf = np.std(accuracies_rf)\n",
    "print(f\"Standard Deviation: {std_dev_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jnj1cohUhcgB",
    "outputId": "919ffc99-e51d-41f7-bec4-69c480316ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1: 0.7165659120604816\n"
     ]
    }
   ],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_rf = [report['1']['recall'] for report in classification_reports_rf]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_rf = np.mean(recall_class_1_rf)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBAwmcFShcgB"
   },
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SRMJFTFshcgB"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Please build the library first!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthundersvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\thundersvm\\__init__.py:10\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m * Name        : __init__.py\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m * Author      : Locke <luojiahuan001@gmail.com>\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m * Version     : 0.0.1\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m * Description :\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthundersvm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthundersvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\thundersvm\\thundersvm.py:52\u001b[0m\n\u001b[0;32m     50\u001b[0m         thundersvm \u001b[38;5;241m=\u001b[39m CDLL(lib_path)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease build the library first!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m SVM_TYPE \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_svc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnu_svc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone_class\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon_svr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnu_svr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     54\u001b[0m KERNEL_TYPE \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolynomial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Please build the library first!"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from thundersvm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PcYd52YhhcgC"
   },
   "outputs": [],
   "source": [
    "# Initialize SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=45)\n",
    "\n",
    "# choosing rbf cause not linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cYy-yMkhcgC",
    "outputId": "b4f17cf7-2770-4221-d4a9-180e8a21ef26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1\n"
     ]
    }
   ],
   "source": [
    "# Lists to store results\n",
    "conf_matrices_svm = []\n",
    "classification_reports_svm = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    print(\"Starting fold \" + str(count))\n",
    "    # Split the data for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    svc.fit(X_train, y_train)\n",
    "    print(\"Model fitted\")\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_svm = svc.predict(X_val)\n",
    "\n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_svm.append(confusion_matrix(y_val, y_pred_svm))\n",
    "    classification_reports_svm.append(classification_report(y_val, y_pred_svm, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNlEmI0shcgC",
    "outputId": "d53884c0-bdb9-41d1-85e6-346a76ae36c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[33869  7839]\n",
      " [19892 21734]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6299920016368743, 'recall': 0.81205044595761, 'f1-score': 0.7095287475515613, 'support': 41708.0}\n",
      "1: {'precision': 0.7349271294762114, 'recall': 0.5221255945803104, 'f1-score': 0.6105141926150648, 'support': 41626.0}\n",
      "accuracy: 0.6672306621547027\n",
      "macro avg: {'precision': 0.6824595655565429, 'recall': 0.6670880202689602, 'f1-score': 0.660021470083313, 'support': 83334.0}\n",
      "weighted avg: {'precision': 0.6824079378866673, 'recall': 0.6672306621547027, 'f1-score': 0.6600701848546235, 'support': 83334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[33671  8098]\n",
      " [19928 21636]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6282020186943786, 'recall': 0.8061241590653355, 'f1-score': 0.7061278416240249, 'support': 41769.0}\n",
      "1: {'precision': 0.7276518463711577, 'recall': 0.5205466268886536, 'f1-score': 0.6069174450896239, 'support': 41564.0}\n",
      "accuracy: 0.663686654746619\n",
      "macro avg: {'precision': 0.6779269325327681, 'recall': 0.6633353929769945, 'f1-score': 0.6565226433568243, 'support': 83333.0}\n",
      "weighted avg: {'precision': 0.6778046087554306, 'recall': 0.663686654746619, 'f1-score': 0.6566446726326788, 'support': 83333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[33681  8025]\n",
      " [19790 21837]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6298928391090498, 'recall': 0.807581642929075, 'f1-score': 0.7077550248484403, 'support': 41706.0}\n",
      "1: {'precision': 0.7312638135422945, 'recall': 0.5245874072116655, 'f1-score': 0.6109191623886192, 'support': 41627.0}\n",
      "accuracy: 0.6662186648746595\n",
      "macro avg: {'precision': 0.6805783263256722, 'recall': 0.6660845250703702, 'f1-score': 0.6593370936185298, 'support': 83333.0}\n",
      "weighted avg: {'precision': 0.6805302762915907, 'recall': 0.6662186648746595, 'f1-score': 0.6593829940009373, 'support': 83333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results for each fold\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_svm[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_svm[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HRWqrg3hcgD",
    "outputId": "8a4f9302-f148-4919-b103-7516cae41a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy RF: 0.6657119939253271\n",
      "Standard Deviation: 0.0014905331742503187\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_svm = [report['accuracy'] for report in classification_reports_svm]\n",
    "average_accuracy_svm = np.mean(accuracies_svm)\n",
    "print(f\"\\nAverage Accuracy SVM: {average_accuracy_svm}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_svm = np.std(accuracies_svm)\n",
    "print(f\"Standard Deviation: {std_dev_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTsCdW-JhcgD"
   },
   "outputs": [],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_svm = [report['1']['recall'] for report in classification_reports_svm]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_svm = np.mean(recall_class_1_svm)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahXczXGihcgD"
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-JKszRWhcgE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, optimizers, models, callbacks\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBGUjdVUhcgE"
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "initial_learning_rate = 5e-4\n",
    "decay_rate = 0.1  # Decay rate per step (you can adjust this)\n",
    "\n",
    "# Define the learning rate schedule\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=decay_rate)\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='accuracy',                 # Watch validation loss\n",
    "    patience=3,                         # Stop after 3 epochs with no improvement\n",
    "    restore_best_weights=True,          # Restore weights from the best epoch\n",
    "    min_delta=0.001                     # Minimum change in accuracy to qualify as an improvement\n",
    ")\n",
    "\n",
    "# Function to build the model\n",
    "def build_model():\n",
    "    model_mlp = models.Sequential()\n",
    "    model_mlp.add(layers.Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model_mlp.add(layers.BatchNormalization())\n",
    "    model_mlp.add(layers.Dense(64, activation='relu'))\n",
    "    model_mlp.add(layers.BatchNormalization())\n",
    "    model_mlp.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model_mlp.compile(optimizer=optimizers.Adam(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KImtedh3hcgE",
    "outputId": "b84231d1-2bd6-4484-d5dc-8dd337c6e3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1ms/step - accuracy: 0.6306 - loss: 0.6169\n",
      "Epoch 2/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1ms/step - accuracy: 0.6441 - loss: 0.6020\n",
      "Epoch 3/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1ms/step - accuracy: 0.6429 - loss: 0.6023\n",
      "Epoch 4/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1ms/step - accuracy: 0.6438 - loss: 0.6022\n",
      "Epoch 5/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1ms/step - accuracy: 0.6440 - loss: 0.6018\n",
      "\u001b[1m22136/22136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 823us/step\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1ms/step - accuracy: 0.6293 - loss: 0.6174\n",
      "Epoch 2/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1ms/step - accuracy: 0.6432 - loss: 0.6023\n",
      "Epoch 3/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1ms/step - accuracy: 0.6429 - loss: 0.6027\n",
      "\u001b[1m22136/22136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 844us/step\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1ms/step - accuracy: 0.6265 - loss: 0.6183\n",
      "Epoch 2/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1ms/step - accuracy: 0.6411 - loss: 0.6033\n",
      "Epoch 3/20\n",
      "\u001b[1m44271/44271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1ms/step - accuracy: 0.6409 - loss: 0.6038\n",
      "\u001b[1m22136/22136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 893us/step\n"
     ]
    }
   ],
   "source": [
    "# Convert data to float32 (required by TensorFlow)\n",
    "X_trainval = np.array(X_trainval, dtype=np.float32)\n",
    "y_trainval = np.array(y_trainval, dtype=np.float32)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_mlp = []\n",
    "classification_reports_mlp = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop over each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "    print(f\"\\nFold {count}\")\n",
    "\n",
    "    # Split data for this fold\n",
    "    X_train, X_val = X_trainval[train_index], X_trainval[test_index]\n",
    "    y_train, y_val = y_trainval[train_index], y_trainval[test_index]\n",
    "\n",
    "    # Build and train the model\n",
    "    model_mlp = build_model()\n",
    "    model_mlp.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_mlp = model_mlp.predict(X_val)\n",
    "    y_pred_mlp = (y_pred_mlp > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "\n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_mlp.append(confusion_matrix(y_val, y_pred_mlp))\n",
    "    classification_reports_mlp.append(classification_report(y_val, y_pred_mlp, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6fkCdGEhcgE",
    "outputId": "738e6e31-7cf7-473c-85ea-9f7eed2dbf38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy: 0.6544847063445941\n",
      "Standard Deviation: 0.0007639610847939577\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_mlp = [report['accuracy'] for report in classification_reports_mlp]\n",
    "average_accuracy_mlp = np.mean(accuracies_mlp)\n",
    "print(f\"\\nAverage Accuracy: {average_accuracy_mlp}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_mlp= np.std(accuracies_mlp)\n",
    "print(f\"Standard Deviation: {std_dev_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ia06p-xdhcgE",
    "outputId": "48dab420-c84f-475f-88ab-df60742e6458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1.0: 0.5632927499334602\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Collect the recall for the '1.0' class from each fold\n",
    "recall_class_1_mlp = [report_mlp['1.0']['recall'] for report_mlp in classification_reports_mlp]\n",
    "\n",
    "# Calculate the average recall for the '1.0' class across all folds\n",
    "average_recall_class_1_mlp = np.mean(recall_class_1_mlp)\n",
    "print(f\"\\nAverage Recall for class 1.0: {average_recall_class_1_mlp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7sDt8QfhcgF"
   },
   "source": [
    "## Dataframe with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvKsx8xThcgF"
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of model names\n",
    "model_names = ['Logistic Regression', 'Random Forest', 'MLP']\n",
    "\n",
    "# Collect the accuracy and recall values by calling the variables\n",
    "accuracies = [average_accuracy_lr, average_accuracy_rf, average_accuracy_mlp]\n",
    "recalls = [average_recall_class_1_lr, average_recall_class_1_rf, average_recall_class_1_mlp]\n",
    "\n",
    "# Create a dictionary for the DataFrame\n",
    "data = {\n",
    "    'Model': model_names,\n",
    "    'Accuracy': accuracies,\n",
    "    'Recall': recalls\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df_results = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06QIx12khcgF",
    "outputId": "8dec8a2e-6ade-4957-cca1-48e718452ad5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.598670</td>\n",
       "      <td>0.448558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.745421</td>\n",
       "      <td>0.716566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.654485</td>\n",
       "      <td>0.563293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy    Recall\n",
       "0  Logistic Regression  0.598670  0.448558\n",
       "1        Random Forest  0.745421  0.716566\n",
       "2                  MLP  0.654485  0.563293"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_klJg5LhcgF"
   },
   "source": [
    "## Random search on best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwC-7UcdhcgF"
   },
   "source": [
    "After looking at the df of above, it can be seen that the best model is the Random Forest model. I therefore will perform random search on this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-lyJ9PDhcgF"
   },
   "outputs": [],
   "source": [
    "# Further splitting trainval into train and validation set to tune hyperparameters on the validation set\n",
    "# Training set: 70%, Validation set: 15%, Test set: 15% (still the same test set)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=(15/85), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0i29x1KahcgF",
    "outputId": "2d044e58-c2b9-4599-9820-64409edcebd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750000, 45)\n",
      "The percentage of the original dataset that is used for training is: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(f\"The percentage of the original dataset that is used for training is: {X_train.shape[0]/df50.shape[0]*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dL3HOPihcgG"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint  # For defining distributions for random search\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),  # Number of trees in the forest (uniform distribution between 50 and 200)\n",
    "    'max_depth': [None] + list(randint(1, 30).rvs(10)),  # Random depth values including None\n",
    "    'min_samples_split': randint(2, 10),  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 4)  # Minimum samples required to be at a leaf node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCL11MlvhcgG"
   },
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_model_search = RandomForestClassifier(random_state=42)  # Random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtpBkgY9hcgG",
    "outputId": "7164e603-a951-4703-bebf-8cb7c19d8d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'max_depth': 27, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 53}\n",
      "Best Cross-Validation Score: 0.6859427727743856\n"
     ]
    }
   ],
   "source": [
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf_model_search,\n",
    "                           param_distributions=param_dist,\n",
    "                           n_iter=20,          # Number of parameter settings that are sampled\n",
    "                           scoring='recall',   # Use recall as the evaluation metric\n",
    "                           cv=k,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)          # Use all available cores\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9HXAa7rhcgH",
    "outputId": "dd6a9f9a-8d35-4923-8d33-733c15d1ebf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Set: 0.7395093333333334\n",
      "[[147891  39282]\n",
      " [ 58402 129425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75    187173\n",
      "           1       0.77      0.69      0.73    187827\n",
      "\n",
      "    accuracy                           0.74    375000\n",
      "   macro avg       0.74      0.74      0.74    375000\n",
      "weighted avg       0.74      0.74      0.74    375000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf_random = random_search.predict(X_val)\n",
    "\n",
    "print(\"Accuracy on Validation Set:\", accuracy_score(y_val, y_pred_rf_random))\n",
    "print(confusion_matrix(y_val, y_pred_rf_random))\n",
    "print(classification_report(y_val, y_pred_rf_random))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qvqpSDrehcf9",
    "O7sDt8QfhcgF",
    "N_klJg5LhcgF"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
