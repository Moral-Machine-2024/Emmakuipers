{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'ResponseID': 'category',\n",
    "    'UserID': 'int8',\n",
    "    'Intervention': 'int8',\n",
    "    'PedPed': 'int8',\n",
    "    'Barrier': 'int8',\n",
    "    'CrossingSignal': 'int8',\n",
    "    'AttributeLevel': 'category',\n",
    "    'ScenarioTypeStrict': 'category',\n",
    "    'NumberOfCharacters': 'int8',\n",
    "    'DiffNumberOFCharacters': 'int8',\n",
    "    'Saved': 'int8',\n",
    "    'Man': 'int8',\n",
    "    'Woman': 'int8',\n",
    "    'Pregnant': 'int8',\n",
    "    'Stroller': 'int8',\n",
    "    'OldMan': 'int8',\n",
    "    'OldWoman': 'int8',\n",
    "    'Boy': 'int8',\n",
    "    'Girl': 'int8',\n",
    "    'Homeless': 'int8',\n",
    "    'LargeWoman': 'int8',\n",
    "    'LargeMan': 'int8',\n",
    "    'Criminal': 'int8',\n",
    "    'MaleExecutive': 'int8',\n",
    "    'FemaleExecutive': 'int8',\n",
    "    'FemaleAthlete': 'int8',\n",
    "    'MaleAthlete': 'int8',\n",
    "    'FemaleDoctor': 'int8',\n",
    "    'MaleDoctor': 'int8',\n",
    "    'Dog': 'int8',\n",
    "    'Cat': 'int8'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df50 = pd.read_csv('total_50_dataset.csv', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ResponseID', 'UserID', 'Intervention', 'PedPed', 'Barrier',\n",
      "       'CrossingSignal', 'NumberOfCharacters', 'DiffNumberOFCharacters',\n",
      "       'Saved', 'Man', 'Woman', 'Pregnant', 'Stroller', 'OldMan', 'OldWoman',\n",
      "       'Boy', 'Girl', 'Homeless', 'LargeWoman', 'LargeMan', 'Criminal',\n",
      "       'MaleExecutive', 'FemaleExecutive', 'FemaleAthlete', 'MaleAthlete',\n",
      "       'FemaleDoctor', 'MaleDoctor', 'Dog', 'Cat', 'AttributeLevel_Fat',\n",
      "       'AttributeLevel_Female', 'AttributeLevel_Fit', 'AttributeLevel_High',\n",
      "       'AttributeLevel_Hoomans', 'AttributeLevel_Less', 'AttributeLevel_Low',\n",
      "       'AttributeLevel_Male', 'AttributeLevel_More', 'AttributeLevel_Old',\n",
      "       'AttributeLevel_Pets', 'AttributeLevel_Young', 'ScenarioTypeStrict_Age',\n",
      "       'ScenarioTypeStrict_Fitness', 'ScenarioTypeStrict_Gender',\n",
      "       'ScenarioTypeStrict_Social Status', 'ScenarioTypeStrict_Species',\n",
      "       'ScenarioTypeStrict_Utilitarian'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# one-hot encode the AttributeLevel and ScenarioTypeStrict\n",
    "df50 = pd.get_dummies(df50, columns=['AttributeLevel', 'ScenarioTypeStrict'])\n",
    "\n",
    "print(df50.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 47)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df50.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now also dropping ResponseID\n",
    "# kept this on and pre-processed it thus far to keep track of if everything went right with the complete sessions being in the dataset (so each ResponseID has to be present twice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variable\n",
    "X = df50.drop(['UserID', 'ResponseID'], axis=1)     # Features\n",
    "y = df50['UserID']                                  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation and test sets\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting K for K-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing fold 1\n",
      "Done processing fold 2\n",
      "Done processing fold 3\n",
      "Done processing fold 4\n",
      "Done processing fold 5\n"
     ]
    }
   ],
   "source": [
    "# Initialize logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_lr = []\n",
    "classification_reports_lr = []\n",
    "count = 0\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    # Split data into train and test for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_lr = lr_model.predict(X_val)\n",
    "    \n",
    "    # Generate confusion matrix and classification report\n",
    "    conf_matrices_lr.append(confusion_matrix(y_val, y_pred_lr))\n",
    "    classification_reports_lr.append(classification_report(y_val, y_pred_lr, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[158939  53145]\n",
      " [117745  95171]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5744423240953579, 'recall': 0.7494153260029045, 'f1-score': 0.6503658177294749, 'support': 212084.0}\n",
      "1: {'precision': 0.6416772296987513, 'recall': 0.44698848372127975, 'f1-score': 0.5269245249590291, 'support': 212916.0}\n",
      "accuracy: 0.5979058823529412\n",
      "macro avg: {'precision': 0.6080597768970546, 'recall': 0.5982019048620921, 'f1-score': 0.588645171344252, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.608125588004657, 'recall': 0.5979058823529412, 'f1-score': 0.5885243441023873, 'support': 425000.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[158238  54301]\n",
      " [116947  95514]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5750240747133747, 'recall': 0.7445127717736509, 'f1-score': 0.6488833848652107, 'support': 212539.0}\n",
      "1: {'precision': 0.6375463071121049, 'recall': 0.4495601545695445, 'f1-score': 0.5272996279080039, 'support': 212461.0}\n",
      "accuracy: 0.5970635294117647\n",
      "macro avg: {'precision': 0.6062851909127398, 'recall': 0.5970364631715978, 'f1-score': 0.5880915063866072, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.6062794535784726, 'recall': 0.5970635294117647, 'f1-score': 0.5881026634843045, 'support': 425000.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[159607  53127]\n",
      " [117030  95236]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.576954637304482, 'recall': 0.7502655898916017, 'f1-score': 0.652294475970174, 'support': 212734.0}\n",
      "1: {'precision': 0.6419120670247973, 'recall': 0.44866346942044416, 'f1-score': 0.5281660654023942, 'support': 212266.0}\n",
      "accuracy: 0.5996305882352941\n",
      "macro avg: {'precision': 0.6094333521646397, 'recall': 0.5994645296560229, 'f1-score': 0.5902302706862841, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.6093975873680407, 'recall': 0.5996305882352941, 'f1-score': 0.5902986143288085, 'support': 425000.0}\n",
      "\n",
      "Fold 4\n",
      "Confusion Matrix:\n",
      "[[159376  53555]\n",
      " [116285  95784]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5781594059370023, 'recall': 0.7484865989451982, 'f1-score': 0.6523889052624685, 'support': 212931.0}\n",
      "1: {'precision': 0.6413863759634121, 'recall': 0.4516643168025501, 'f1-score': 0.53006020896051, 'support': 212069.0}\n",
      "accuracy: 0.6003764705882353\n",
      "macro avg: {'precision': 0.6097728909502071, 'recall': 0.6000754578738742, 'f1-score': 0.5912245571114892, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.6097087713641334, 'recall': 0.6003764705882353, 'f1-score': 0.5913486128011507, 'support': 425000.0}\n",
      "\n",
      "Fold 5\n",
      "Confusion Matrix:\n",
      "[[159178  52634]\n",
      " [118053  95135]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5741709981928428, 'recall': 0.7515060525371556, 'f1-score': 0.6509775214040483, 'support': 211812.0}\n",
      "1: {'precision': 0.6438089179733232, 'recall': 0.44624931984914723, 'f1-score': 0.52712649983239, 'support': 213188.0}\n",
      "accuracy: 0.5983835294117648\n",
      "macro avg: {'precision': 0.608989958083083, 'recall': 0.5988776861931514, 'f1-score': 0.5890520106182191, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.6091026895861629, 'recall': 0.5983835294117648, 'f1-score': 0.5888515176703573, 'support': 425000.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_lr[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_lr[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy LR: 0.598672\n",
      "Standard Deviation: 0.0011900790354958243\n",
      "\n",
      "Average f1-score LR: 0.5894487032293704\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_lr = [report['accuracy'] for report in classification_reports_lr]\n",
    "average_accuracy_lr = np.mean(accuracies_lr)\n",
    "print(f\"\\nAverage Accuracy LR: {average_accuracy_lr}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_lr = np.std(accuracies_lr)\n",
    "print(f\"Standard Deviation: {std_dev_lr}\")\n",
    "\n",
    "# Calculate average f1-score\n",
    "f1s_lr_0 = [report['0']['f1-score'] for report in classification_reports_lr]\n",
    "f1s_lr_1 = [report['1']['f1-score'] for report in classification_reports_lr]\n",
    "total_f1s_lr = [f1s_lr_0[i] + f1s_lr_1[i] for i in range(k)]\n",
    "total_f1s_lr = [f1 / 2 for f1 in total_f1s_lr]\n",
    "average_f1_lr = np.mean(total_f1s_lr)\n",
    "print(f\"\\nAverage f1-score LR: {average_f1_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1: 0.4486251488725931\n"
     ]
    }
   ],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_lr = [report['1']['recall'] for report in classification_reports_lr]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_lr = np.mean(recall_class_1_lr)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing fold 1\n",
      "Done processing fold 1\n",
      "Start processing fold 2\n",
      "Done processing fold 2\n",
      "Start processing fold 3\n",
      "Done processing fold 3\n",
      "Start processing fold 4\n",
      "Done processing fold 4\n",
      "Start processing fold 5\n",
      "Done processing fold 5\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_rf = []\n",
    "classification_reports_rf = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "    print(\"Start processing fold \" + str(count))\n",
    "\n",
    "    # Split the data for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_rf = rf_model.predict(X_val)\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_rf.append(confusion_matrix(y_val, y_pred_rf))\n",
    "    classification_reports_rf.append(classification_report(y_val, y_pred_rf, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[164858  47226]\n",
      " [ 60135 152781]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7327250181116746, 'recall': 0.7773240791384546, 'f1-score': 0.7543659355216586, 'support': 212084.0}\n",
      "1: {'precision': 0.7638782642607509, 'recall': 0.7175646733923238, 'f1-score': 0.7399975298057991, 'support': 212916.0}\n",
      "accuracy: 0.7473858823529411\n",
      "macro avg: {'precision': 0.7483016411862127, 'recall': 0.7474443762653892, 'f1-score': 0.7471817326637289, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.748332134716561, 'recall': 0.7473858823529411, 'f1-score': 0.747167668530134, 'support': 425000.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[165012  47527]\n",
      " [ 59992 152469]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7333736289132637, 'recall': 0.7763845694202005, 'f1-score': 0.7542664378129692, 'support': 212539.0}\n",
      "1: {'precision': 0.7623602472049441, 'recall': 0.7176328832115071, 'f1-score': 0.7393207049462126, 'support': 212461.0}\n",
      "accuracy: 0.7470141176470588\n",
      "macro avg: {'precision': 0.7478669380591039, 'recall': 0.7470087263158538, 'f1-score': 0.7467935713795909, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.7478642781106019, 'recall': 0.7470141176470588, 'f1-score': 0.7467949428703716, 'support': 425000.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[164749  47985]\n",
      " [ 58859 153407]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7367759650817503, 'recall': 0.7744366203803811, 'f1-score': 0.7551370255441833, 'support': 212734.0}\n",
      "1: {'precision': 0.7617333359815683, 'recall': 0.7227111266052971, 'f1-score': 0.7417093347644673, 'support': 212266.0}\n",
      "accuracy: 0.7486023529411765\n",
      "macro avg: {'precision': 0.7492546505316593, 'recall': 0.7485738734928391, 'f1-score': 0.7484231801543253, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.7492409092968579, 'recall': 0.7486023529411765, 'f1-score': 0.7484305732828956, 'support': 425000.0}\n",
      "\n",
      "Fold 4\n",
      "Confusion Matrix:\n",
      "[[164812  48119]\n",
      " [ 59027 153042]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7362970706623957, 'recall': 0.7740159957920641, 'f1-score': 0.7546855324312567, 'support': 212931.0}\n",
      "1: {'precision': 0.7607935931915232, 'recall': 0.7216613460713258, 'f1-score': 0.7407109841976623, 'support': 212069.0}\n",
      "accuracy: 0.7478917647058824\n",
      "macro avg: {'precision': 0.7485453319269595, 'recall': 0.747838670931695, 'f1-score': 0.7476982583144596, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.7485204895711711, 'recall': 0.7478917647058824, 'f1-score': 0.7477124301504329, 'support': 425000.0}\n",
      "\n",
      "Fold 5\n",
      "Confusion Matrix:\n",
      "[[164851  46961]\n",
      " [ 59770 153418]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7339073372480757, 'recall': 0.7782892376258191, 'f1-score': 0.7554469987374923, 'support': 211812.0}\n",
      "1: {'precision': 0.7656391138791989, 'recall': 0.7196371277933092, 'f1-score': 0.741925733919776, 'support': 213188.0}\n",
      "accuracy: 0.7488682352941176\n",
      "macro avg: {'precision': 0.7497732255636373, 'recall': 0.7489631827095642, 'f1-score': 0.7486863663286342, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.7498245937102779, 'recall': 0.7488682352941176, 'f1-score': 0.7486644777869997, 'support': 425000.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results for each fold\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_rf[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_rf[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy RF: 0.7479524705882353\n",
      "Standard Deviation: 0.0007023084427720712\n",
      "\n",
      "Average f1-score LR: 0.7477566217681477\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_rf = [report['accuracy'] for report in classification_reports_rf]\n",
    "average_accuracy_rf = np.mean(accuracies_rf)\n",
    "print(f\"\\nAverage Accuracy RF: {average_accuracy_rf}\")\n",
    "\n",
    "# Caluculate average standard deviation of accuracies\n",
    "std_dev_rf = np.std(accuracies_rf)\n",
    "print(f\"Standard Deviation: {std_dev_rf}\")\n",
    "\n",
    "# Calculate average f1-score\n",
    "f1s_rf_0 = [report['0']['f1-score'] for report in classification_reports_rf]\n",
    "f1s_rf_1 = [report['1']['f1-score'] for report in classification_reports_rf]\n",
    "total_f1s_rf = [f1s_rf_0[i] + f1s_rf_1[i] for i in range(k)]\n",
    "total_f1s_rf = [f1 / 2 for f1 in total_f1s_rf]\n",
    "average_f1_rf = np.mean(total_f1s_rf)\n",
    "print(f\"\\nAverage f1-score LR: {average_f1_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1: 0.7198414314147527\n"
     ]
    }
   ],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_rf = [report['1']['recall'] for report in classification_reports_rf]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_rf = np.mean(recall_class_1_rf)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=45)\n",
    "\n",
    "# choosing rbf cause not linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n",
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n",
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n"
     ]
    }
   ],
   "source": [
    "# Lists to store results\n",
    "conf_matrices_svm = []\n",
    "classification_reports_svm = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    print(\"Starting fold \" + str(count))\n",
    "    # Split the data for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    svc.fit(X_train, y_train)\n",
    "    print(\"Model fitted\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_svm = svc.predict(X_val)\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_svm.append(confusion_matrix(y_val, y_pred_svm))\n",
    "    classification_reports_svm.append(classification_report(y_val, y_pred_svm, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[33869  7839]\n",
      " [19892 21734]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6299920016368743, 'recall': 0.81205044595761, 'f1-score': 0.7095287475515613, 'support': 41708.0}\n",
      "1: {'precision': 0.7349271294762114, 'recall': 0.5221255945803104, 'f1-score': 0.6105141926150648, 'support': 41626.0}\n",
      "accuracy: 0.6672306621547027\n",
      "macro avg: {'precision': 0.6824595655565429, 'recall': 0.6670880202689602, 'f1-score': 0.660021470083313, 'support': 83334.0}\n",
      "weighted avg: {'precision': 0.6824079378866673, 'recall': 0.6672306621547027, 'f1-score': 0.6600701848546235, 'support': 83334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[33671  8098]\n",
      " [19928 21636]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6282020186943786, 'recall': 0.8061241590653355, 'f1-score': 0.7061278416240249, 'support': 41769.0}\n",
      "1: {'precision': 0.7276518463711577, 'recall': 0.5205466268886536, 'f1-score': 0.6069174450896239, 'support': 41564.0}\n",
      "accuracy: 0.663686654746619\n",
      "macro avg: {'precision': 0.6779269325327681, 'recall': 0.6633353929769945, 'f1-score': 0.6565226433568243, 'support': 83333.0}\n",
      "weighted avg: {'precision': 0.6778046087554306, 'recall': 0.663686654746619, 'f1-score': 0.6566446726326788, 'support': 83333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[33681  8025]\n",
      " [19790 21837]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6298928391090498, 'recall': 0.807581642929075, 'f1-score': 0.7077550248484403, 'support': 41706.0}\n",
      "1: {'precision': 0.7312638135422945, 'recall': 0.5245874072116655, 'f1-score': 0.6109191623886192, 'support': 41627.0}\n",
      "accuracy: 0.6662186648746595\n",
      "macro avg: {'precision': 0.6805783263256722, 'recall': 0.6660845250703702, 'f1-score': 0.6593370936185298, 'support': 83333.0}\n",
      "weighted avg: {'precision': 0.6805302762915907, 'recall': 0.6662186648746595, 'f1-score': 0.6593829940009373, 'support': 83333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results for each fold\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_svm[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_svm[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy RF: 0.6657119939253271\n",
      "Standard Deviation: 0.0014905331742503187\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_svm = [report['accuracy'] for report in classification_reports_svm]\n",
    "average_accuracy_svm = np.mean(accuracies_svm)\n",
    "print(f\"\\nAverage Accuracy SVM: {average_accuracy_svm}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_svm = np.std(accuracies_svm)\n",
    "print(f\"Standard Deviation: {std_dev_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_svm = [report['1']['recall'] for report in classification_reports_svm]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_svm = np.mean(recall_class_1_svm)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, optimizers, models, callbacks\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "initial_learning_rate = 5e-4\n",
    "decay_rate = 0.1  # Decay rate per step\n",
    "\n",
    "# Define the learning rate schedule\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=decay_rate)\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',             # Watch accuracy\n",
    "    patience=5,                         # Stop after 3 epochs with no improvement\n",
    "    restore_best_weights=True,          # Restore weights from the best epoch\n",
    "    min_delta=0.0005                    # Minimum change in accuracy to qualify as an improvement\n",
    ")\n",
    "\n",
    "# Function to build the model\n",
    "def build_model():\n",
    "    model_mlp = models.Sequential()\n",
    "    model_mlp.add(layers.Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model_mlp.add(layers.BatchNormalization())\n",
    "    model_mlp.add(layers.Dense(64, activation='relu'))\n",
    "    model_mlp.add(layers.BatchNormalization())\n",
    "    model_mlp.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model_mlp.compile(optimizer=optimizers.Adam(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=['accuracy', keras.metrics.Recall()])\n",
    "    return model_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.6318 - loss: 0.6137 - recall: 0.5688 - val_accuracy: 0.6546 - val_loss: 0.5923 - val_recall: 0.5556\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 5ms/step - accuracy: 0.6440 - loss: 0.6024 - recall: 0.5718 - val_accuracy: 0.6544 - val_loss: 0.5924 - val_recall: 0.5444\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 964us/step - accuracy: 0.6443 - loss: 0.6021 - recall: 0.5714 - val_accuracy: 0.6548 - val_loss: 0.5925 - val_recall: 0.5511\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 952us/step - accuracy: 0.6437 - loss: 0.6026 - recall: 0.5706 - val_accuracy: 0.6545 - val_loss: 0.5923 - val_recall: 0.5570\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 990us/step - accuracy: 0.6442 - loss: 0.6022 - recall: 0.5709 - val_accuracy: 0.6546 - val_loss: 0.5923 - val_recall: 0.5585\n",
      "Epoch 6/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1ms/step - accuracy: 0.6439 - loss: 0.6023 - recall: 0.5709 - val_accuracy: 0.6546 - val_loss: 0.5923 - val_recall: 0.5605\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 586us/step\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1ms/step - accuracy: 0.6315 - loss: 0.6165 - recall_1: 0.5711 - val_accuracy: 0.6539 - val_loss: 0.5936 - val_recall_1: 0.5707\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1ms/step - accuracy: 0.6436 - loss: 0.6030 - recall_1: 0.5754 - val_accuracy: 0.6540 - val_loss: 0.5936 - val_recall_1: 0.5726\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1ms/step - accuracy: 0.6431 - loss: 0.6034 - recall_1: 0.5758 - val_accuracy: 0.6540 - val_loss: 0.5936 - val_recall_1: 0.5595\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1ms/step - accuracy: 0.6432 - loss: 0.6032 - recall_1: 0.5758 - val_accuracy: 0.6542 - val_loss: 0.5936 - val_recall_1: 0.5617\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2ms/step - accuracy: 0.6429 - loss: 0.6033 - recall_1: 0.5758 - val_accuracy: 0.6543 - val_loss: 0.5935 - val_recall_1: 0.5729\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 792us/step\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 874us/step - accuracy: 0.6309 - loss: 0.6174 - recall_2: 0.5770 - val_accuracy: 0.6563 - val_loss: 0.5917 - val_recall_2: 0.5705\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3ms/step - accuracy: 0.6423 - loss: 0.6043 - recall_2: 0.5786 - val_accuracy: 0.6566 - val_loss: 0.5918 - val_recall_2: 0.5592\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.6420 - loss: 0.6041 - recall_2: 0.5780 - val_accuracy: 0.6564 - val_loss: 0.5919 - val_recall_2: 0.5581\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 3ms/step - accuracy: 0.6417 - loss: 0.6043 - recall_2: 0.5784 - val_accuracy: 0.6567 - val_loss: 0.5917 - val_recall_2: 0.5835\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.6417 - loss: 0.6041 - recall_2: 0.5778 - val_accuracy: 0.6557 - val_loss: 0.5918 - val_recall_2: 0.5831\n",
      "Epoch 6/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2ms/step - accuracy: 0.6424 - loss: 0.6039 - recall_2: 0.5790 - val_accuracy: 0.6564 - val_loss: 0.5917 - val_recall_2: 0.5680\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 4ms/step - accuracy: 0.6304 - loss: 0.6136 - recall_3: 0.5628 - val_accuracy: 0.6557 - val_loss: 0.5904 - val_recall_3: 0.5562\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 4ms/step - accuracy: 0.6431 - loss: 0.6013 - recall_3: 0.5670 - val_accuracy: 0.6557 - val_loss: 0.5907 - val_recall_3: 0.5507\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 5ms/step - accuracy: 0.6432 - loss: 0.6011 - recall_3: 0.5680 - val_accuracy: 0.6561 - val_loss: 0.5905 - val_recall_3: 0.5447\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 5ms/step - accuracy: 0.6431 - loss: 0.6013 - recall_3: 0.5672 - val_accuracy: 0.6563 - val_loss: 0.5906 - val_recall_3: 0.5410\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 4ms/step - accuracy: 0.6434 - loss: 0.6013 - recall_3: 0.5677 - val_accuracy: 0.6554 - val_loss: 0.5904 - val_recall_3: 0.5642\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 533us/step\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.6312 - loss: 0.6149 - recall_4: 0.5645 - val_accuracy: 0.6564 - val_loss: 0.5902 - val_recall_4: 0.5528\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 917us/step - accuracy: 0.6427 - loss: 0.6019 - recall_4: 0.5705 - val_accuracy: 0.6559 - val_loss: 0.5900 - val_recall_4: 0.5681\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1ms/step - accuracy: 0.6430 - loss: 0.6023 - recall_4: 0.5703 - val_accuracy: 0.6562 - val_loss: 0.5901 - val_recall_4: 0.5601\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 5ms/step - accuracy: 0.6427 - loss: 0.6016 - recall_4: 0.5710 - val_accuracy: 0.6561 - val_loss: 0.5903 - val_recall_4: 0.5555\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 5ms/step - accuracy: 0.6426 - loss: 0.6019 - recall_4: 0.5707 - val_accuracy: 0.6565 - val_loss: 0.5902 - val_recall_4: 0.5607\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Convert data to float32 (required by TensorFlow)\n",
    "X_trainval = np.array(X_trainval, dtype=np.float32)\n",
    "y_trainval = np.array(y_trainval, dtype=np.float32)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_mlp = []\n",
    "classification_reports_mlp = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop over each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "    print(f\"\\nFold {count}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    X_train, X_val = X_trainval[train_index], X_trainval[test_index]\n",
    "    y_train, y_val = y_trainval[train_index], y_trainval[test_index]\n",
    "    \n",
    "    # Build and train the model\n",
    "    model_mlp = build_model()\n",
    "    model_mlp.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_mlp = model_mlp.predict(X_val)\n",
    "    y_pred_mlp = (y_pred_mlp > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_mlp.append(confusion_matrix(y_val, y_pred_mlp))\n",
    "    classification_reports_mlp.append(classification_report(y_val, y_pred_mlp, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy MLP: 0.6553778823529411\n",
      "Standard Deviation: 0.0009673130909467366\n",
      "\n",
      "Average f1-score LR: 0.6522851098830483\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_mlp = [report['accuracy'] for report in classification_reports_mlp]\n",
    "average_accuracy_mlp = np.mean(accuracies_mlp)\n",
    "print(f\"\\nAverage Accuracy MLP: {average_accuracy_mlp}\")\n",
    "\n",
    "# Caluculate average standard deviation of accuracies\n",
    "std_dev_mlp = np.std(accuracies_mlp)\n",
    "print(f\"Standard Deviation: {std_dev_mlp}\")\n",
    "\n",
    "# Calculate average f1-score\n",
    "f1s_mlp_0 = [report['0.0']['f1-score'] for report in classification_reports_mlp]\n",
    "f1s_mlp_1 = [report['1.0']['f1-score'] for report in classification_reports_mlp]\n",
    "total_f1s_mlp = [f1s_mlp_0[i] + f1s_mlp_1[i] for i in range(k)]\n",
    "total_f1s_mlp = [f1 / 2 for f1 in total_f1s_mlp]\n",
    "average_f1_mlp = np.mean(total_f1s_mlp)\n",
    "print(f\"\\nAverage f1-score LR: {average_f1_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1.0: 0.5611755634601688\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Collect the recall for the '1.0' class from each fold\n",
    "recall_class_1_mlp = [report_mlp['1.0']['recall'] for report_mlp in classification_reports_mlp]\n",
    "\n",
    "# Calculate the average recall for the '1.0' class across all folds\n",
    "average_recall_class_1_mlp = np.mean(recall_class_1_mlp)\n",
    "print(f\"\\nAverage Recall for class 1.0: {average_recall_class_1_mlp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'average_accuracy_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Collect the accuracy and recall values by calling the variables\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m [average_accuracy_lr, average_accuracy_rf, average_accuracy_mlp]\n\u001b[0;32m      6\u001b[0m recalls \u001b[38;5;241m=\u001b[39m [average_recall_class_1_lr, average_recall_class_1_rf, average_recall_class_1_mlp]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create a dictionary for the DataFrame\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'average_accuracy_lr' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of model names\n",
    "model_names = ['Logistic Regression', 'Random Forest', 'MLP']\n",
    "\n",
    "# Collect the accuracy and recall values by calling the variables\n",
    "accuracies = [average_accuracy_lr, average_accuracy_rf, average_accuracy_mlp]\n",
    "recalls = [average_recall_class_1_lr, average_recall_class_1_rf, average_recall_class_1_mlp]\n",
    "\n",
    "# Create a dictionary for the DataFrame\n",
    "data = {\n",
    "    'Model': model_names,\n",
    "    'Accuracy': accuracies,\n",
    "    'Recall': recalls\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df_results = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.598670</td>\n",
       "      <td>0.448558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.745421</td>\n",
       "      <td>0.716566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.654485</td>\n",
       "      <td>0.563293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy    Recall\n",
       "0  Logistic Regression  0.598670  0.448558\n",
       "1        Random Forest  0.745421  0.716566\n",
       "2                  MLP  0.654485  0.563293"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search on best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the df of above, it can be seen that the best model is the Random Forest model. I therefore will perform random search on this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further splitting trainval into train and validation set to tune hyperparameters on the validation set\n",
    "# Training set: 70%, Validation set: 15%, Test set: 15% (still the same test set)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=(15/85), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750000, 45)\n",
      "The percentage of the original dataset that is used for training is: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(f\"The percentage of the original dataset that is used for training is: {X_train.shape[0]/df50.shape[0]*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint  # For defining distributions for random search\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 300),                       # Number of trees in the forest (uniform distribution between 50 and 200)\n",
    "    'max_depth': [None] + list(randint(1, 30).rvs(10)),     # Random depth values including None\n",
    "    'min_samples_split': randint(2, 10),                    # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 4)                       # Minimum samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_model_search = RandomForestClassifier(random_state=42)  # Random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf_model_search,\n",
    "                           param_distributions=param_dist,\n",
    "                           n_iter=20,          # Number of parameter settings that are sampled\n",
    "                           scoring='recall',   # Use recall as the evaluation metric (but recall on 0 or on 1???)\n",
    "                           cv=k,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)          # Use all available cores\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Set: 0.7395093333333334\n",
      "[[147891  39282]\n",
      " [ 58402 129425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75    187173\n",
      "           1       0.77      0.69      0.73    187827\n",
      "\n",
      "    accuracy                           0.74    375000\n",
      "   macro avg       0.74      0.74      0.74    375000\n",
      "weighted avg       0.74      0.74      0.74    375000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf_random = random_search.predict(X_val)\n",
    "\n",
    "print(\"Accuracy on Validation Set:\", accuracy_score(y_val, y_pred_rf_random))\n",
    "print(confusion_matrix(y_val, y_pred_rf_random))\n",
    "print(classification_report(y_val, y_pred_rf_random))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall on Validation Set:\", recall_score(y_val, y_pred_rf_random))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
