{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'ResponseID': 'category',\n",
    "    'UserID': 'int8',\n",
    "    'Intervention': 'int8',\n",
    "    'PedPed': 'int8',\n",
    "    'Barrier': 'int8',\n",
    "    'CrossingSignal': 'int8',\n",
    "    'AttributeLevel': 'category',\n",
    "    'ScenarioTypeStrict': 'category',\n",
    "    'NumberOfCharacters': 'int8',\n",
    "    'DiffNumberOFCharacters': 'int8',\n",
    "    'Saved': 'int8',\n",
    "    'Man': 'int8',\n",
    "    'Woman': 'int8',\n",
    "    'Pregnant': 'int8',\n",
    "    'Stroller': 'int8',\n",
    "    'OldMan': 'int8',\n",
    "    'OldWoman': 'int8',\n",
    "    'Boy': 'int8',\n",
    "    'Girl': 'int8',\n",
    "    'Homeless': 'int8',\n",
    "    'LargeWoman': 'int8',\n",
    "    'LargeMan': 'int8',\n",
    "    'Criminal': 'int8',\n",
    "    'MaleExecutive': 'int8',\n",
    "    'FemaleExecutive': 'int8',\n",
    "    'FemaleAthlete': 'int8',\n",
    "    'MaleAthlete': 'int8',\n",
    "    'FemaleDoctor': 'int8',\n",
    "    'MaleDoctor': 'int8',\n",
    "    'Dog': 'int8',\n",
    "    'Cat': 'int8'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nw = pd.read_csv('total_nw_50_dataset.csv', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ResponseID', 'UserID', 'Intervention', 'PedPed', 'Barrier',\n",
      "       'CrossingSignal', 'NumberOfCharacters', 'DiffNumberOFCharacters',\n",
      "       'Saved', 'Man', 'Woman', 'Pregnant', 'Stroller', 'OldMan', 'OldWoman',\n",
      "       'Boy', 'Girl', 'Homeless', 'LargeWoman', 'LargeMan', 'Criminal',\n",
      "       'MaleExecutive', 'FemaleExecutive', 'FemaleAthlete', 'MaleAthlete',\n",
      "       'FemaleDoctor', 'MaleDoctor', 'Dog', 'Cat', 'AttributeLevel_Fat',\n",
      "       'AttributeLevel_Female', 'AttributeLevel_Fit', 'AttributeLevel_High',\n",
      "       'AttributeLevel_Hoomans', 'AttributeLevel_Less', 'AttributeLevel_Low',\n",
      "       'AttributeLevel_Male', 'AttributeLevel_More', 'AttributeLevel_Old',\n",
      "       'AttributeLevel_Pets', 'AttributeLevel_Young', 'ScenarioTypeStrict_Age',\n",
      "       'ScenarioTypeStrict_Fitness', 'ScenarioTypeStrict_Gender',\n",
      "       'ScenarioTypeStrict_Social Status', 'ScenarioTypeStrict_Species',\n",
      "       'ScenarioTypeStrict_Utilitarian'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# one-hot encode the AttributeLevel and ScenarioTypeStrict\n",
    "df_nw = pd.get_dummies(df_nw, columns=['AttributeLevel', 'ScenarioTypeStrict'])\n",
    "\n",
    "print(df_nw.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500000, 47)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nw.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now also dropping ResponseID\n",
    "# kept this on and pre-processed it thus far to keep track of if everything went right with the complete sessions being in the dataset (so each ResponseID has to be present twice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variable\n",
    "X = df_nw.drop(['UserID', 'ResponseID'], axis=1)     # Features\n",
    "y = df_nw['UserID']                                  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation and test sets\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2125000, 45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting K for K-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing fold 1\n",
      "Done processing fold 2\n",
      "Done processing fold 3\n",
      "Done processing fold 4\n",
      "Done processing fold 5\n"
     ]
    }
   ],
   "source": [
    "# Initialize logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_lr = []\n",
    "classification_reports_lr = []\n",
    "count = 0\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    # Split data into train and test for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_lr = lr_model.predict(X_val)\n",
    "    \n",
    "    # Generate confusion matrix and classification report\n",
    "    conf_matrices_lr.append(confusion_matrix(y_val, y_pred_lr))\n",
    "    classification_reports_lr.append(classification_report(y_val, y_pred_lr, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[160310  51774]\n",
      " [118510  94406]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5749587547521698, 'recall': 0.7558797457611135, 'f1-score': 0.6531215879275785, 'support': 212084.0}\n",
      "1: {'precision': 0.6458202216445478, 'recall': 0.44339551748107237, 'f1-score': 0.5257981152672266, 'support': 212916.0}\n",
      "accuracy: 0.5993317647058823\n",
      "macro avg: {'precision': 0.6103894881983588, 'recall': 0.599637631621093, 'f1-score': 0.5894598515974026, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.6104588490694818, 'recall': 0.5993317647058823, 'f1-score': 0.5893352243865162, 'support': 425000.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[159592  52947]\n",
      " [117944  94517]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5750317075982936, 'recall': 0.750883367287886, 'f1-score': 0.6512962301688517, 'support': 212539.0}\n",
      "1: {'precision': 0.6409496555091412, 'recall': 0.44486752862878365, 'f1-score': 0.5252038619156769, 'support': 212461.0}\n",
      "accuracy: 0.5979035294117647\n",
      "macro avg: {'precision': 0.6079906815537174, 'recall': 0.5978754479583348, 'f1-score': 0.5882500460422644, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.607984632612615, 'recall': 0.5979035294117647, 'f1-score': 0.588261616871351, 'support': 425000.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[159477  53257]\n",
      " [117090  95176]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5766306175357147, 'recall': 0.7496544981056155, 'f1-score': 0.6518564237555207, 'support': 212734.0}\n",
      "1: {'precision': 0.64120512285004, 'recall': 0.4483808052160968, 'f1-score': 0.527730878100577, 'support': 212266.0}\n",
      "accuracy: 0.5991835294117647\n",
      "macro avg: {'precision': 0.6089178701928774, 'recall': 0.5990176516608561, 'f1-score': 0.5897936509280488, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.6088823162299514, 'recall': 0.5991835294117647, 'f1-score': 0.589861992993186, 'support': 425000.0}\n",
      "\n",
      "Fold 4\n",
      "Confusion Matrix:\n",
      "[[159779  53152]\n",
      " [116833  95236]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.5776285916735355, 'recall': 0.7503792308306446, 'f1-score': 0.6527679897373673, 'support': 212931.0}\n",
      "1: {'precision': 0.6418039194544033, 'recall': 0.4490802521820728, 'f1-score': 0.5284180914783178, 'support': 212069.0}\n",
      "accuracy: 0.6000352941176471\n",
      "macro avg: {'precision': 0.6097162555639695, 'recall': 0.5997297415063587, 'f1-score': 0.5905930406078426, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.609651174231561, 'recall': 0.6000352941176471, 'f1-score': 0.590719146034077, 'support': 425000.0}\n",
      "\n",
      "Fold 5\n",
      "Confusion Matrix:\n",
      "[[159633  52179]\n",
      " [118555  94633]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.573831365838929, 'recall': 0.7536541838989292, 'f1-score': 0.6515632653061224, 'support': 211812.0}\n",
      "1: {'precision': 0.6445862736016129, 'recall': 0.4438945906899075, 'f1-score': 0.5257388888888889, 'support': 213188.0}\n",
      "accuracy: 0.5982729411764706\n",
      "macro avg: {'precision': 0.609208819720271, 'recall': 0.5987743872944183, 'f1-score': 0.5886510770975056, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.6093233594297787, 'recall': 0.5982729411764706, 'f1-score': 0.5884473896363879, 'support': 425000.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_lr[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_lr[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy LR: 0.598945411764706\n",
      "Standard Deviation: 0.0007657085191717521\n",
      "\n",
      "Average f1-score LR: 0.5893495332546128\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_lr = [report['accuracy'] for report in classification_reports_lr]\n",
    "average_accuracy_lr = np.mean(accuracies_lr)\n",
    "print(f\"\\nAverage Accuracy LR: {average_accuracy_lr}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_lr = np.std(accuracies_lr)\n",
    "print(f\"Standard Deviation: {std_dev_lr}\")\n",
    "\n",
    "# Calculate average f1-score\n",
    "f1s_lr_0 = [report['0']['f1-score'] for report in classification_reports_lr]\n",
    "f1s_lr_1 = [report['1']['f1-score'] for report in classification_reports_lr]\n",
    "total_f1s_lr = [f1s_lr_0[i] + f1s_lr_1[i] for i in range(k)]\n",
    "total_f1s_lr = [f1 / 2 for f1 in total_f1s_lr]\n",
    "average_f1_lr = np.mean(total_f1s_lr)\n",
    "print(f\"\\nAverage f1-score LR: {average_f1_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1: 0.44592373883958664\n"
     ]
    }
   ],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_lr = [report['1']['recall'] for report in classification_reports_lr]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_lr = np.mean(recall_class_1_lr)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 1\n",
      "Done processing fold 1\n",
      "Processing fold 2\n",
      "Done processing fold 2\n",
      "Processing fold 3\n",
      "Done processing fold 3\n",
      "Processing fold 4\n",
      "Done processing fold 4\n",
      "Processing fold 5\n",
      "Done processing fold 5\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_rf = []\n",
    "classification_reports_rf = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    print(\"Processing fold \" + str(count))\n",
    "    \n",
    "    # Split the data for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_rf = rf_model.predict(X_val)\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_rf.append(confusion_matrix(y_val, y_pred_rf))\n",
    "    classification_reports_rf.append(classification_report(y_val, y_pred_rf, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[163499  48585]\n",
      " [ 59334 153582]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7337288462660378, 'recall': 0.7709162407348031, 'f1-score': 0.7518629991469636, 'support': 212084.0}\n",
      "1: {'precision': 0.7596788793423259, 'recall': 0.7213267203967761, 'f1-score': 0.740006215624345, 'support': 212916.0}\n",
      "accuracy: 0.7460729411764706\n",
      "macro avg: {'precision': 0.7467038628041819, 'recall': 0.7461214805657896, 'f1-score': 0.7459346073856543, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.746729263307146, 'recall': 0.7460729411764706, 'f1-score': 0.7459230016869591, 'support': 425000.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[164125  48414]\n",
      " [ 59378 153083]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7343301879616828, 'recall': 0.7722112177059269, 'f1-score': 0.752794455579967, 'support': 212539.0}\n",
      "1: {'precision': 0.7597284326813799, 'recall': 0.7205228253655965, 'f1-score': 0.7396064335029158, 'support': 212461.0}\n",
      "accuracy: 0.7463717647058824\n",
      "macro avg: {'precision': 0.7470293103215313, 'recall': 0.7463670215357617, 'f1-score': 0.7462004445414414, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.7470269796590747, 'recall': 0.7463717647058824, 'f1-score': 0.7462016547364084, 'support': 425000.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[164247  48487]\n",
      " [ 59204 153062]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.735047057296678, 'recall': 0.772076865945265, 'f1-score': 0.7531070531999037, 'support': 212734.0}\n",
      "1: {'precision': 0.7594282283712646, 'recall': 0.7210858074302997, 'f1-score': 0.7397605210057634, 'support': 212266.0}\n",
      "accuracy: 0.7466094117647059\n",
      "macro avg: {'precision': 0.7472376428339713, 'recall': 0.7465813366877824, 'f1-score': 0.7464337871028335, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.7472242188480148, 'recall': 0.7466094117647059, 'f1-score': 0.7464411355464416, 'support': 425000.0}\n",
      "\n",
      "Fold 4\n",
      "Confusion Matrix:\n",
      "[[164154  48777]\n",
      " [ 58467 153602]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7373697899120029, 'recall': 0.7709257928624765, 'f1-score': 0.7537745206083315, 'support': 212931.0}\n",
      "1: {'precision': 0.7589819101784276, 'recall': 0.7243019960484559, 'f1-score': 0.7412365363085357, 'support': 212069.0}\n",
      "accuracy: 0.7476611764705883\n",
      "macro avg: {'precision': 0.7481758500452153, 'recall': 0.7476138944554662, 'f1-score': 0.7475055284584335, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.7481539328126627, 'recall': 0.7476611764705883, 'f1-score': 0.7475182434495705, 'support': 425000.0}\n",
      "\n",
      "Fold 5\n",
      "Confusion Matrix:\n",
      "[[163288  48524]\n",
      " [ 58897 154291]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.7349190989490739, 'recall': 0.7709100523105396, 'f1-score': 0.7524844641783238, 'support': 211812.0}\n",
      "1: {'precision': 0.76074747922984, 'recall': 0.7237321049965288, 'f1-score': 0.7417783044833811, 'support': 213188.0}\n",
      "accuracy: 0.7472447058823529\n",
      "macro avg: {'precision': 0.747833289089457, 'recall': 0.7473210786535343, 'f1-score': 0.7471313843308525, 'support': 425000.0}\n",
      "weighted avg: {'precision': 0.7478751006791821, 'recall': 0.7472447058823529, 'f1-score': 0.7471140529476287, 'support': 425000.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results for each fold\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_rf[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_rf[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy RF: 0.7467919999999999\n",
      "Standard Deviation: 0.000580928930373869\n",
      "\n",
      "Average f1-score LR: 0.746641150363843\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_rf = [report['accuracy'] for report in classification_reports_rf]\n",
    "average_accuracy_rf = np.mean(accuracies_rf)\n",
    "print(f\"\\nAverage Accuracy RF: {average_accuracy_rf}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_rf = np.std(accuracies_rf)\n",
    "print(f\"Standard Deviation: {std_dev_rf}\")\n",
    "\n",
    "# Calculate average f1-score\n",
    "f1s_rf_0 = [report['0']['f1-score'] for report in classification_reports_rf]\n",
    "f1s_rf_1 = [report['1']['f1-score'] for report in classification_reports_rf]\n",
    "total_f1s_rf = [f1s_rf_0[i] + f1s_rf_1[i] for i in range(k)]\n",
    "total_f1s_rf = [f1 / 2 for f1 in total_f1s_rf]\n",
    "average_f1_rf = np.mean(total_f1s_rf)\n",
    "print(f\"\\nAverage f1-score LR: {average_f1_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1: 0.7221938908475314\n"
     ]
    }
   ],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_rf = [report['1']['recall'] for report in classification_reports_rf]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_rf = np.mean(recall_class_1_rf)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=45)\n",
    "\n",
    "# choosing rbf cause not linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n",
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n",
      "Starting a fold\n",
      "Model fitted\n",
      "Done processing a fold\n"
     ]
    }
   ],
   "source": [
    "# Lists to store results\n",
    "conf_matrices_svm = []\n",
    "classification_reports_svm = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop through each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "\n",
    "    print(\"Starting fold \" + str(count))\n",
    "    # Split the data for this fold\n",
    "    X_train, X_val = X_trainval.iloc[train_index], X_trainval.iloc[test_index]\n",
    "    y_train, y_val = y_trainval.iloc[train_index], y_trainval.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    svc.fit(X_train, y_train)\n",
    "    print(\"Model fitted\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_svm = svc.predict(X_val)\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_svm.append(confusion_matrix(y_val, y_pred_svm))\n",
    "    classification_reports_svm.append(classification_report(y_val, y_pred_svm, output_dict=True))\n",
    "\n",
    "    print(\"Done processing fold \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Confusion Matrix:\n",
      "[[33869  7839]\n",
      " [19892 21734]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6299920016368743, 'recall': 0.81205044595761, 'f1-score': 0.7095287475515613, 'support': 41708.0}\n",
      "1: {'precision': 0.7349271294762114, 'recall': 0.5221255945803104, 'f1-score': 0.6105141926150648, 'support': 41626.0}\n",
      "accuracy: 0.6672306621547027\n",
      "macro avg: {'precision': 0.6824595655565429, 'recall': 0.6670880202689602, 'f1-score': 0.660021470083313, 'support': 83334.0}\n",
      "weighted avg: {'precision': 0.6824079378866673, 'recall': 0.6672306621547027, 'f1-score': 0.6600701848546235, 'support': 83334.0}\n",
      "\n",
      "Fold 2\n",
      "Confusion Matrix:\n",
      "[[33671  8098]\n",
      " [19928 21636]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6282020186943786, 'recall': 0.8061241590653355, 'f1-score': 0.7061278416240249, 'support': 41769.0}\n",
      "1: {'precision': 0.7276518463711577, 'recall': 0.5205466268886536, 'f1-score': 0.6069174450896239, 'support': 41564.0}\n",
      "accuracy: 0.663686654746619\n",
      "macro avg: {'precision': 0.6779269325327681, 'recall': 0.6633353929769945, 'f1-score': 0.6565226433568243, 'support': 83333.0}\n",
      "weighted avg: {'precision': 0.6778046087554306, 'recall': 0.663686654746619, 'f1-score': 0.6566446726326788, 'support': 83333.0}\n",
      "\n",
      "Fold 3\n",
      "Confusion Matrix:\n",
      "[[33681  8025]\n",
      " [19790 21837]]\n",
      "\n",
      "Classification Report:\n",
      "0: {'precision': 0.6298928391090498, 'recall': 0.807581642929075, 'f1-score': 0.7077550248484403, 'support': 41706.0}\n",
      "1: {'precision': 0.7312638135422945, 'recall': 0.5245874072116655, 'f1-score': 0.6109191623886192, 'support': 41627.0}\n",
      "accuracy: 0.6662186648746595\n",
      "macro avg: {'precision': 0.6805783263256722, 'recall': 0.6660845250703702, 'f1-score': 0.6593370936185298, 'support': 83333.0}\n",
      "weighted avg: {'precision': 0.6805302762915907, 'recall': 0.6662186648746595, 'f1-score': 0.6593829940009373, 'support': 83333.0}\n"
     ]
    }
   ],
   "source": [
    "# Display results for each fold\n",
    "for i in range(k):\n",
    "    print(f\"\\nFold {i+1}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrices_svm[i])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in classification_reports_svm[i].items():\n",
    "        print(f\"{label}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy RF: 0.6657119939253271\n",
      "Standard Deviation: 0.0014905331742503187\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_svm = [report['accuracy'] for report in classification_reports_svm]\n",
    "average_accuracy_svm = np.mean(accuracies_svm)\n",
    "print(f\"\\nAverage Accuracy SVM: {average_accuracy_svm}\")\n",
    "\n",
    "# Caluculate average standard deviation\n",
    "std_dev_svm = np.std(accuracies_svm)\n",
    "print(f\"Standard Deviation: {std_dev_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the recall for the '1' class from each fold\n",
    "recall_class_1_svm = [report['1']['recall'] for report in classification_reports_svm]\n",
    "\n",
    "# Calculate the average recall for the '1' class across all folds\n",
    "average_recall_class_1_svm = np.mean(recall_class_1_svm)\n",
    "print(f\"\\nAverage Recall for class 1: {average_recall_class_1_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, optimizers, models, callbacks\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "initial_learning_rate = 5e-4\n",
    "decay_rate = 0.1  # Decay rate per step\n",
    "\n",
    "# Define the learning rate schedule\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=decay_rate)\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',             # Watch accuracy\n",
    "    patience=5,                         # Stop after 3 epochs with no improvement\n",
    "    restore_best_weights=True,          # Restore weights from the best epoch\n",
    "    min_delta=0.0005                    # Minimum change in accuracy to qualify as an improvement\n",
    ")\n",
    "\n",
    "# Function to build the model\n",
    "def build_model():\n",
    "    model_mlp = models.Sequential()\n",
    "    model_mlp.add(layers.Dense(64, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model_mlp.add(layers.BatchNormalization())\n",
    "    model_mlp.add(layers.Dense(64, activation='relu'))\n",
    "    model_mlp.add(layers.BatchNormalization())\n",
    "    model_mlp.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model_mlp.compile(optimizer=optimizers.Adam(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=['accuracy', keras.metrics.Recall()])\n",
    "    return model_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 5ms/step - accuracy: 0.6282 - loss: 0.6167 - recall: 0.5616 - val_accuracy: 0.6512 - val_loss: 0.5938 - val_recall: 0.5622\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 5ms/step - accuracy: 0.6398 - loss: 0.6042 - recall: 0.5639 - val_accuracy: 0.6519 - val_loss: 0.5938 - val_recall: 0.5366\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1ms/step - accuracy: 0.6407 - loss: 0.6036 - recall: 0.5650 - val_accuracy: 0.6520 - val_loss: 0.5941 - val_recall: 0.5276\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 885us/step - accuracy: 0.6404 - loss: 0.6038 - recall: 0.5638 - val_accuracy: 0.6515 - val_loss: 0.5936 - val_recall: 0.5725\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 906us/step - accuracy: 0.6397 - loss: 0.6042 - recall: 0.5638 - val_accuracy: 0.6513 - val_loss: 0.5937 - val_recall: 0.5501\n",
      "Epoch 6/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1ms/step - accuracy: 0.6391 - loss: 0.6046 - recall: 0.5625 - val_accuracy: 0.6516 - val_loss: 0.5938 - val_recall: 0.5503\n",
      "Epoch 7/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 904us/step - accuracy: 0.6404 - loss: 0.6040 - recall: 0.5641 - val_accuracy: 0.6516 - val_loss: 0.5937 - val_recall: 0.5562\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 492us/step\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 885us/step - accuracy: 0.6298 - loss: 0.6160 - recall_1: 0.5676 - val_accuracy: 0.6549 - val_loss: 0.5933 - val_recall_1: 0.5605\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 959us/step - accuracy: 0.6421 - loss: 0.6026 - recall_1: 0.5705 - val_accuracy: 0.6546 - val_loss: 0.5932 - val_recall_1: 0.5608\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1ms/step - accuracy: 0.6410 - loss: 0.6037 - recall_1: 0.5708 - val_accuracy: 0.6542 - val_loss: 0.5932 - val_recall_1: 0.5714\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 937us/step - accuracy: 0.6417 - loss: 0.6031 - recall_1: 0.5709 - val_accuracy: 0.6543 - val_loss: 0.5933 - val_recall_1: 0.5563\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1ms/step - accuracy: 0.6401 - loss: 0.6036 - recall_1: 0.5691 - val_accuracy: 0.6543 - val_loss: 0.5934 - val_recall_1: 0.5503\n",
      "Epoch 6/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 962us/step - accuracy: 0.6415 - loss: 0.6033 - recall_1: 0.5702 - val_accuracy: 0.6544 - val_loss: 0.5934 - val_recall_1: 0.5493\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 467us/step\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 909us/step - accuracy: 0.6275 - loss: 0.6180 - recall_2: 0.5658 - val_accuracy: 0.6512 - val_loss: 0.5949 - val_recall_2: 0.5589\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 832us/step - accuracy: 0.6398 - loss: 0.6046 - recall_2: 0.5691 - val_accuracy: 0.6520 - val_loss: 0.5952 - val_recall_2: 0.5422\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 801us/step - accuracy: 0.6401 - loss: 0.6050 - recall_2: 0.5695 - val_accuracy: 0.6518 - val_loss: 0.5949 - val_recall_2: 0.5483\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 795us/step - accuracy: 0.6398 - loss: 0.6046 - recall_2: 0.5686 - val_accuracy: 0.6521 - val_loss: 0.5949 - val_recall_2: 0.5547\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 804us/step - accuracy: 0.6401 - loss: 0.6042 - recall_2: 0.5692 - val_accuracy: 0.6517 - val_loss: 0.5948 - val_recall_2: 0.5662\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 421us/step\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 804us/step - accuracy: 0.6261 - loss: 0.6183 - recall_3: 0.5641 - val_accuracy: 0.6525 - val_loss: 0.5945 - val_recall_3: 0.5550\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 801us/step - accuracy: 0.6373 - loss: 0.6058 - recall_3: 0.5660 - val_accuracy: 0.6526 - val_loss: 0.5945 - val_recall_3: 0.5417\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 802us/step - accuracy: 0.6374 - loss: 0.6060 - recall_3: 0.5661 - val_accuracy: 0.6524 - val_loss: 0.5945 - val_recall_3: 0.5521\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 797us/step - accuracy: 0.6386 - loss: 0.6055 - recall_3: 0.5673 - val_accuracy: 0.6527 - val_loss: 0.5946 - val_recall_3: 0.5417\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 795us/step - accuracy: 0.6386 - loss: 0.6054 - recall_3: 0.5668 - val_accuracy: 0.6530 - val_loss: 0.5947 - val_recall_3: 0.5367\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 430us/step\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 799us/step - accuracy: 0.6295 - loss: 0.6156 - recall_4: 0.5597 - val_accuracy: 0.6513 - val_loss: 0.5938 - val_recall_4: 0.5242\n",
      "Epoch 2/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 797us/step - accuracy: 0.6390 - loss: 0.6039 - recall_4: 0.5620 - val_accuracy: 0.6512 - val_loss: 0.5932 - val_recall_4: 0.5509\n",
      "Epoch 3/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 804us/step - accuracy: 0.6396 - loss: 0.6035 - recall_4: 0.5627 - val_accuracy: 0.6511 - val_loss: 0.5931 - val_recall_4: 0.5412\n",
      "Epoch 4/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 806us/step - accuracy: 0.6405 - loss: 0.6034 - recall_4: 0.5638 - val_accuracy: 0.6512 - val_loss: 0.5929 - val_recall_4: 0.5481\n",
      "Epoch 5/20\n",
      "\u001b[1m53125/53125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 807us/step - accuracy: 0.6395 - loss: 0.6039 - recall_4: 0.5634 - val_accuracy: 0.6512 - val_loss: 0.5934 - val_recall_4: 0.5396\n",
      "\u001b[1m13282/13282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 429us/step\n"
     ]
    }
   ],
   "source": [
    "# Convert data to float32 (required by TensorFlow)\n",
    "X_trainval = np.array(X_trainval, dtype=np.float32)\n",
    "y_trainval = np.array(y_trainval, dtype=np.float32)\n",
    "\n",
    "# Lists to store results\n",
    "conf_matrices_mlp = []\n",
    "classification_reports_mlp = []\n",
    "count = 0\n",
    "\n",
    "# Manually loop over each fold\n",
    "for train_index, test_index in kf.split(X_trainval):\n",
    "    count += 1\n",
    "    print(f\"\\nFold {count}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    X_train, X_val = X_trainval[train_index], X_trainval[test_index]\n",
    "    y_train, y_val = y_trainval[train_index], y_trainval[test_index]\n",
    "    \n",
    "    # Build and train the model\n",
    "    model_mlp = build_model()\n",
    "    model_mlp.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_mlp = model_mlp.predict(X_val)\n",
    "    y_pred_mlp = (y_pred_mlp > 0.5).astype(int)  # Convert probabilities to binary class predictions\n",
    "    \n",
    "    # Store confusion matrix and classification report for each fold\n",
    "    conf_matrices_mlp.append(confusion_matrix(y_val, y_pred_mlp))\n",
    "    classification_reports_mlp.append(classification_report(y_val, y_pred_mlp, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy MLP: 0.6523350588235294\n",
      "Standard Deviation: 0.0013461321035241718\n",
      "\n",
      "Average f1-score LR: 0.6483899183028696\n"
     ]
    }
   ],
   "source": [
    "# Calculate average accuracy\n",
    "accuracies_mlp = [report['accuracy'] for report in classification_reports_mlp]\n",
    "average_accuracy_mlp = np.mean(accuracies_mlp)\n",
    "print(f\"\\nAverage Accuracy MLP: {average_accuracy_mlp}\")\n",
    "\n",
    "# Caluculate average standard deviation of accuracies\n",
    "std_dev_mlp = np.std(accuracies_mlp)\n",
    "print(f\"Standard Deviation: {std_dev_mlp}\")\n",
    "\n",
    "# Calculate average f1-score\n",
    "f1s_mlp_0 = [report['0.0']['f1-score'] for report in classification_reports_mlp]\n",
    "f1s_mlp_1 = [report['1.0']['f1-score'] for report in classification_reports_mlp]\n",
    "total_f1s_mlp = [f1s_mlp_0[i] + f1s_mlp_1[i] for i in range(k)]\n",
    "total_f1s_mlp = [f1 / 2 for f1 in total_f1s_mlp]\n",
    "average_f1_mlp = np.mean(total_f1s_mlp)\n",
    "print(f\"\\nAverage f1-score LR: {average_f1_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Recall for class 1.0: 0.547043728529927\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Collect the recall for the '1.0' class from each fold\n",
    "recall_class_1_mlp = [report_mlp['1.0']['recall'] for report_mlp in classification_reports_mlp]\n",
    "\n",
    "# Calculate the average recall for the '1.0' class across all folds\n",
    "average_recall_class_1_mlp = np.mean(recall_class_1_mlp)\n",
    "print(f\"\\nAverage Recall for class 1.0: {average_recall_class_1_mlp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of model names\n",
    "model_names = ['Logistic Regression', 'Random Forest', 'MLP']\n",
    "\n",
    "# Collect the accuracy and recall values by calling the variables\n",
    "accuracies = [average_accuracy_lr, average_accuracy_rf, average_accuracy_mlp]\n",
    "recalls = [average_recall_class_1_lr, average_recall_class_1_rf, average_recall_class_1_mlp]\n",
    "\n",
    "# Create a dictionary for the DataFrame\n",
    "data = {\n",
    "    'Model': model_names,\n",
    "    'Accuracy': accuracies,\n",
    "    'Recall': recalls\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df_results = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.598945</td>\n",
       "      <td>0.445924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.746792</td>\n",
       "      <td>0.722194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.652335</td>\n",
       "      <td>0.547044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy    Recall\n",
       "0  Logistic Regression  0.598945  0.445924\n",
       "1        Random Forest  0.746792  0.722194\n",
       "2                  MLP  0.652335  0.547044"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search on best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the df of above, it can be seen that the best model is the Random Forest model. I therefore will perform random search on this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further splitting trainval into train and validation set to tune hyperparameters on the validation set\n",
    "# Training set: 70%, Validation set: 15%, Test set: 15% (still the same test set)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=(15/85), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750000, 45)\n",
      "The percentage of the original dataset that is used for training is: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(f\"The percentage of the original dataset that is used for training is: {X_train.shape[0]/df_nw.shape[0]*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint  # For defining distributions for random search\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),  # Number of trees in the forest (uniform distribution between 50 and 200)\n",
    "    'max_depth': [None] + list(randint(1, 30).rvs(10)),  # Random depth values including None\n",
    "    'min_samples_split': randint(2, 10),  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': randint(1, 4)  # Minimum samples required to be at a leaf node\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_model_search = RandomForestClassifier(random_state=42)  # Random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 240. MiB for an array with shape (1400000, 45) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 880, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 156, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 267, in _safe_indexing\n    return _array_indexing(X, indices, indices_dtype, axis=axis)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 33, in _array_indexing\n    return array[key, ...] if axis == 0 else array[:, key]\n           ~~~~~^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\numpy\\core\\memmap.py\", line 335, in __getitem__\n    res = super().__getitem__(index)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 240. MiB for an array with shape (1400000, 45) and data type float32\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf_model_search,\n\u001b[0;32m      3\u001b[0m                            param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m      4\u001b[0m                            n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,          \u001b[38;5;66;03m# Number of parameter settings that are sampled\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m                            verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m      8\u001b[0m                            n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)          \u001b[38;5;66;03m# Use all available cores\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Fit RandomizedSearchCV\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Get the best parameters and best score\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1961\u001b[0m         ParameterSampler(\n\u001b[0;32m   1962\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1963\u001b[0m         )\n\u001b[0;32m   1964\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    966\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    967\u001b[0m         clone(base_estimator),\n\u001b[0;32m    968\u001b[0m         X,\n\u001b[0;32m    969\u001b[0m         y,\n\u001b[0;32m    970\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    971\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    972\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    973\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    974\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    975\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    976\u001b[0m     )\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    979\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    980\u001b[0m     )\n\u001b[0;32m    981\u001b[0m )\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 240. MiB for an array with shape (1400000, 45) and data type float32"
     ]
    }
   ],
   "source": [
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf_model_search,\n",
    "                           param_distributions=param_dist,\n",
    "                           n_iter=20,          # Number of parameter settings that are sampled\n",
    "                           scoring='recall',   # Use recall as the evaluation metric\n",
    "                           cv=k,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)          # Use all available cores\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Set: 0.7413466666666667\n",
      "[[144404  42769]\n",
      " [ 54226 133601]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75    187173\n",
      "           1       0.76      0.71      0.73    187827\n",
      "\n",
      "    accuracy                           0.74    375000\n",
      "   macro avg       0.74      0.74      0.74    375000\n",
      "weighted avg       0.74      0.74      0.74    375000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf_random = random_search.predict(X_val)\n",
    "\n",
    "print(\"Accuracy on Validation Set:\", accuracy_score(y_val, y_pred_rf_random))\n",
    "print(confusion_matrix(y_val, y_pred_rf_random))\n",
    "print(classification_report(y_val, y_pred_rf_random))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Recall on Validation Set:\", recall_score(y_val, y_pred_rf_random))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
